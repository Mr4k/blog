<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>peterstefek.me</title><link href="/" rel="alternate"></link><link href="/feeds/all.atom.xml" rel="self"></link><id>/</id><updated>2023-01-10T00:00:00-08:00</updated><entry><title>Learn You a NeRF</title><link href="/nerf.html" rel="alternate"></link><published>2023-01-10T00:00:00-08:00</published><updated>2022-01-10T00:00:00-08:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2023-01-10:/nerf.html</id><summary type="html">&lt;p&gt;Radical Radiance&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;My NeRF Implementation which generated all the renderings for this post is on &lt;a href="https://github.com/Mr4k/NeRFImpl"&gt;github&lt;/a&gt; and you can play with it in a minimal &lt;a href="https://colab.research.google.com/drive/1Z5QlXSBfYhF1VNBP1uUA5RTuTqqngxvq?usp=sharing"&gt;colab&lt;/a&gt;&lt;/em&gt;    &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/excavator.png" width="100%"&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A Computer Vision Problem&lt;/strong&gt;&lt;br&gt;
Over the years computer graphics has gotten really good at rendering virtual worlds. This is known as forward rendering&lt;sup id="sf-nerf-1-back"&gt;&lt;a href="#sf-nerf-1" class="simple-footnote" title="Forward rendering has a different meaning in realtime graphics for video games. This definition has nothing to do with that"&gt;1&lt;/a&gt;&lt;/sup&gt;. Forward rendering means taking some description of a 3d world stored in a computer and turning it into a realistic looking 2d image captured from a particular perspective inside that world.  &lt;/p&gt;
&lt;p&gt;The inverse problem, turning an image or collection of images into a 3d scene, is also very interesting. Up until recently these problems were solved in unrelated ways but new techniques called inverse graphics have tied the two problems together. &lt;a href="https://www.matthewtancik.com/nerf"&gt;NeRF&lt;/a&gt; (Neural Radiance Fields) is a wildly popular&lt;sup id="sf-nerf-2-back"&gt;&lt;a href="#sf-nerf-2" class="simple-footnote" title="Over 50 papers derived from NeRF were submitted to CVPR in 2022. This number is courtesy of Frank Dellart "&gt;2&lt;/a&gt;&lt;/sup&gt; inverse graphics technique which beautifully formulates the problem in terms of forward rendering.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Forward Rendering via Ray Tracing&lt;/strong&gt;&lt;br&gt;
Before we talk about NeRF, I want to quickly go over the basic ideas of ray tracing, a forward rendering technique. NeRF relies on a very simplified version of ray tracing so understanding the basic ideas behind ray tracing is useful for understanding NeRF. If you already are familiar with ray tracing feel free to skip ahead! For a more comprehensive explanation please see the wonderful &lt;a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-ray-tracing/how-does-it-work.html"&gt;Scratchapixel&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;The basic idea behind ray tracing is to use a virtual pinhole camera to capture imaginary light rays and turn them into an image. This approximates how cameras work in real life. Below is a diagram of an ideal pinhole camera:  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/camdiagram1.png" width="70%"&gt; 
&lt;/p&gt;
&lt;p&gt;Light from the sun or other light source bounces off of an object and into the pinhole of the camera projecting the object upside down. In our virtual pinhole camera we usually assume the pinhole is infinitely small and has sufficient light exposure so there is no need for a lens and therefore no depth of field effects.  &lt;/p&gt;
&lt;p&gt;An important notational point is that graphics programmers prefer to talk about rendering in terms of an "eye" placed at the pinhole and an "image plane" placed in front of the camera one focal length unit away. This has no real life analog but is the right side up version of the image captured by the pinhole camera so it is easier to work with. Here is a diagram of the image plane:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/camdiagram2.png" width="70%"&gt; 
&lt;/p&gt;
&lt;p&gt;One way you might try to render an image would be to sample rays of light from the light sources in the scene (the imaginary sun or other lights) and bounce them around until you have accumulated enough inside the pinhole camera to see a finished image. However given the fact that our virtual pinhole is infinitely tiny this would take forever. Even if it wasn't this would be super inefficient as most samples would miss the camera and therefore be useless. &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/camdiagram3.png" width="50%"&gt; 
&lt;/p&gt;
&lt;p&gt;Instead of casting rays from the light source to the camera, we can be more efficient by casting "reverse" rays out from the camera. We can do this because we know that the color of each point&lt;sup id="sf-nerf-3-back"&gt;&lt;a href="#sf-nerf-3" class="simple-footnote" title="I maintain this is technically true for a single point. However in ray tracing we are estimating the color for an entire pixel which is a rectangle, therefore serious ray tracers use techniques such as Monte Carlo sampling to sample many points inside each pixel's rectangle and merge them together to get a final color"&gt;3&lt;/a&gt;&lt;/sup&gt; on the image plane is uniquely determined by the light coming into the camera's pinhole from a certain direction. These reverse rays will bounce around the scene until they hit a light source. By the time they have done that they will have followed the exact paths that the incoming light ray from that source would follow and therefore we can determine how much energy is left when that ray of light finally hits our sensor&lt;sup id="sf-nerf-4-back"&gt;&lt;a href="#sf-nerf-4" class="simple-footnote" title="If you are scratching your head at how this is accomplished you are absolutely correct. In fact I'd be a little worried if you weren't confused. The answer to this question is incredibly complex and a good chunk of the subfield of computer graphics called Physically Based Rendering is dedicated to creating more and more accurate approximations. A great place to start is the Pbr book"&gt;4&lt;/a&gt;&lt;/sup&gt;.  &lt;/p&gt;
&lt;p&gt;One important property of this version of ray tracing I want to highlight is that we can terminate "reverse" rays early and make an approximation of the amount of light coming from the remainder of the tracing process instead of continuing to trace. All ray tracers I'm aware of do this to some extent. Usually there is a max bounce depth before early termination.  &lt;/p&gt;
&lt;p&gt;The simplest form of this is to terminate immediately when hitting the first object instead of doing any bouncing and make a guess as to the amount of light hitting that object at that particular angle. This is the type of ray tracing NeRF relies on.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So what is NeRF anyway?&lt;/strong&gt;&lt;br&gt;
Neural Radiance Fields (NeRF) takes in a set of cameras with the following known parameters: position, orientation and field of view as well as the corresponding ground truth photographs taken from each of those cameras. It then learns a 3d representation of the underlying scene. This 3d representation can be used to render the scene from novel viewpoints or turned into a mesh.  &lt;/p&gt;
&lt;p&gt;NeRF represents the 3d scene with a so-called radiance field. A radiance field can be viewed as two different functions &lt;span class="math"&gt;\(\mathbf{\sigma(pos)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mathbf{c(pos, dir)}\)&lt;/span&gt; which together represent a volume.  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathbf{\sigma(pos)}\)&lt;/span&gt; is a function which takes a position in 3d space and returns the probability density of encountering a particle at that location. This quantity is sometimes called the attenuation but the NeRF authors refer to it as the volume density.  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathbf{c(pos, dir)}\)&lt;/span&gt; is a function which takes a position in 3d space and a direction then returns the color of light reflecting off that particle. The return type of &lt;span class="math"&gt;\(\mathbf{c(pos, dir)}\)&lt;/span&gt; is a 3 component RGB vector with components from &lt;span class="math"&gt;\([0, 1]\)&lt;/span&gt;.  &lt;/p&gt;
&lt;p&gt;One thing you might notice is that &lt;span class="math"&gt;\(\mathbf{\sigma(pos)}\)&lt;/span&gt; does not depend on the direction of the ray while the color function does. This is an explicit choice by the NeRF authors, who say that the angle at which you look at an object should not determine whether or not it is there. In contrast the author's acknowledge that the color of the object can be influenced by the ray direction especially if its surface is reflective. For example, consider a mirror, you can look at the same part of it from different angles and you will see different images.  &lt;/p&gt;
&lt;p&gt;To create a 2d view from this radiance field the authors use a forward rendering technique from an area of computer graphics called volume rendering&lt;sup id="sf-nerf-5-back"&gt;&lt;a href="#sf-nerf-5" class="simple-footnote" title="I'm not going to go into detail about volume rendering here (mostly due to my own ignorance). Please look at Scratchapixel's volume rendering section or this chapter of the pbr book for a great introduction"&gt;5&lt;/a&gt;&lt;/sup&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tracing Rays&lt;/strong&gt;  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/eye-tracing2.png" width="70%"&gt; 
&lt;/p&gt;
&lt;p&gt;To determine the color of a given pixel in the image plane we take its associated "reverse" ray and trace it through the radiance field.   &lt;/p&gt;
&lt;p&gt;The main difference between rendering the radiance field and the simple ray tracing we talked about previously is that unlike the simple ray tracing where objects are solid, here we are dealing with objects made of many tiny particles. In this case collisions at any particular point in space are approximated by a probability that they will occur instead of actually computing an intersection test.   &lt;/p&gt;
&lt;p&gt;Each of the rays we trace passes through the field until it hits a particle (decided by weighted coin flip based on the probability of intersection at each point along the ray) and finally terminates, returning the color reflecting off of that particle towards the camera. Notice there are no light bounces modeled here. As mentioned in the Forward Rendering section the color of the radiance field is serving as an approximation of the light reflected off the particle after the first collision.   &lt;/p&gt;
&lt;p&gt;Because collisions with the radiance field are probabilistic, casting the same ray over and over again in the same direction will give different colors each time. So instead of casting just one ray per point in the image plane to find its color, we compute the expected color over all possible rays shot from the eye in that particular direction. Since authors don't need to deal with bounces the expected color is fairly simple to compute.  &lt;/p&gt;
&lt;p&gt;Given the radiance field function, &lt;span class="math"&gt;\(\mathbf{\sigma(pos)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mathbf{c(pos, dir)}\)&lt;/span&gt;, the expected color for a particular point on the image plane is given by the following equation: &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/math-eqn-1.png" width="90%"&gt; 
&lt;/p&gt;
&lt;p&gt;When you understand all the notation this integral is not as scary as it first appears. We are simply computing the expected color of a ray starting from initial position o and direction d going through the radiance field given by &lt;span class="math"&gt;\(\mathbf{\sigma(pos)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mathbf{c(pos, dir)}\)&lt;/span&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\mathit{T(t)}\)&lt;/span&gt; is the probability that the ray has not terminated earlier before point &lt;span class="math"&gt;\(\mathbf{r(t)}\)&lt;/span&gt;. &lt;span class="math"&gt;\(\mathit{T(t)}\)&lt;/span&gt; is calculated using Beer's law. Scratchapixel has a derivation of Beer's law using differential equations in their volume rendering section.  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(t_n\)&lt;/span&gt; is the location along the ray of the near plane (the image plane)&lt;br&gt;
&lt;span class="math"&gt;\(t_f\)&lt;/span&gt; is the location of the far plane which is the furthest a ray will go before automatically terminating into the background.  &lt;/p&gt;
&lt;p&gt;Of course we cannot perfectly calculate the above integral so the NeRF authors choose to approximate it by breaking it up into a sum of a finite number of bins described as follows:  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/math-eqn-2.png" width="90%"&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Learning the radiance field&lt;/strong&gt;&lt;br&gt;
The "neural" part of Neural radiance fields means that the radiance field function will be a neural network. The goal of NeRF is to learn a neural network based radiance field that matches a set of known "training" camera views.  &lt;/p&gt;
&lt;p&gt;Knowing this let's look again at our radiance field functions &lt;span class="math"&gt;\(\mathbf{\sigma(pos)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mathbf{c(pos, dir)}\)&lt;/span&gt;. We're going to now refer to them as &lt;span class="math"&gt;\(\mathbf{\sigma(pos; W)}\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mathbf{c(pos, dir; W)}\)&lt;/span&gt;. Where &lt;span class="math"&gt;\(W\)&lt;/span&gt; represents the parameters of the underlying neural network approximating the radiance field.   &lt;/p&gt;
&lt;p&gt;Now let's consider the expected color along a ray &lt;span class="math"&gt;\(\hat{C}(r)\)&lt;/span&gt;, from the previous section, which we will now denote &lt;span class="math"&gt;\(\hat{C}(r; W)\)&lt;/span&gt; to explicitly show its dependence on the neural network parameters &lt;span class="math"&gt;\(W\)&lt;/span&gt;. Suppose we also know the true color along that particular ray (from a ground truth photograph) denoted by &lt;span class="math"&gt;\(ground\_truth\_color(r)\)&lt;/span&gt;.   &lt;/p&gt;
&lt;p&gt;We can create a loss function between the two values:&lt;br&gt;
&lt;/p&gt;
&lt;div class="math"&gt;$$L(r; W) = (\hat{C}(r; W) - ground\_truth\_color(r))^2$$&lt;/div&gt;
&lt;p&gt;
Notice that this loss function is differentiable with respect to &lt;span class="math"&gt;\(W\)&lt;/span&gt;&lt;sup id="sf-nerf-6-back"&gt;&lt;a href="#sf-nerf-6" class="simple-footnote" title="This is a lie for some parts of the function because the neural network in the original paper contains ReLUs but gradient descent still works in practice"&gt;6&lt;/a&gt;&lt;/sup&gt;, the parameters of the neural network. This means that we can use gradient descent to minimize this loss function. If we minimize the sum of the loss over all rays for all known views we can learn a radiance field that faithfully represents the underlying 3d scene. This is the core idea behind NeRF.&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/traindiagram.png" width="90%"&gt; 
&lt;/p&gt;
&lt;p&gt;The training process for nerf is pictured above. The basic idea is that for each of our known cameras we can render an image using our current network as the radiance field and then compare the rendered image to the ground truth reference image from the camera. We then take the derivative of the loss with respect to the network parameters and perform gradient descent to update the network for the next iteration.  &lt;/p&gt;
&lt;p&gt;In practice rendering an entire image per iteration can be expensive. Instead the authors sample a subset of rays and corresponding pixel colors from each known camera image and roll them all up into a batch. The batch size in the original NeRF paper is 4096 rays. This type of batching is a common technique in deep learning.  &lt;/p&gt;
&lt;p&gt;It's also important to realize that in the NeRF paper, the neural network learned is tailored to a single scene only.  &lt;/p&gt;
&lt;p&gt;Here are some validation views during the learning process. Note that none of these images are fed into the network at train time, it has never seen the scene from these orientations before:  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;/p&gt;&lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;img src="/images/nerf/lego_view1_truth.png"&gt;
        &lt;img src="/images/nerf/lego_view1.gif"&gt;
        &lt;img src="/images/nerf/lego_view1_depth.gif"&gt;
    &lt;/div&gt; 
&lt;p&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;/p&gt;&lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;img src="/images/nerf/ficus_truth.png"&gt;
        &lt;img src="/images/nerf/ficus.gif"&gt;
        &lt;img src="/images/nerf/ficus_depth.gif"&gt;
    &lt;/div&gt; 
&lt;p&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;/p&gt;&lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;p align="center"&gt; ground truth &lt;/p&gt;
        &lt;p align="center"&gt; color prediction &lt;/p&gt;
        &lt;p align="center"&gt; depth prediction &lt;/p&gt;
    &lt;/div&gt; 
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Network Architecture&lt;/strong&gt;&lt;br&gt;
Now let's talk about the actual architecture of the neural network which computes the radiance field.   &lt;/p&gt;
&lt;p&gt;The network described in the original NeRF paper is a simple feedforward architecture.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/networkdiagram.png" width="90%"&gt; 
&lt;/p&gt;
&lt;p&gt;As described in the paper, each black arrow in this diagram represents a connection between layers with a ReLU in between. The dashed arrow is an element wise sigmoid activation and the orange arrow indicates no activation function.   &lt;/p&gt;
&lt;p&gt;The inputs to the network are the green boxes and the outputs are red boxes.  &lt;/p&gt;
&lt;p&gt;Initially the position (a vector embedding of size 60) is input at the very beginning of the network and then added in again at layer 5 by concatenating it with the output of layer 4. The idea behind this is that it helps the network "remember" the position in later layers. This is inspired by the skip connections in architectures such as &lt;a href="https://arxiv.org/pdf/1512.03385.pdf"&gt;ResNet&lt;/a&gt;.   &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/layer9_closeup3.png" width="70%"&gt; 
&lt;/p&gt;

&lt;p&gt;At layer 9 the scalar volume density value &lt;span class="math"&gt;\(\sigma(pos)\)&lt;/span&gt; is output and a ReLU is applied to it to make it non negative&lt;sup id="sf-nerf-7-back"&gt;&lt;a href="#sf-nerf-7" class="simple-footnote" title="One problem with rectifying the volume density with ReLU is that sometimes when training the network the ReLU will start &amp;quot;dead&amp;quot; (with a \(value \le 0\)) at which point the gradient is 0. The network will then make no progress producing all black images. The NeRF authors somewhat solve this problem by adding gaussian noise to the ReLU on their &amp;quot;real world&amp;quot; images but I'm not sure it's addressed fully."&gt;7&lt;/a&gt;&lt;/sup&gt;. Afterwards the direction embedding (a vector of size 24) is concatenated with the output of layer 9 minus the volume density and input into layer 10 which eventually outputs a 3 element vector representing the r, g and b pieces of the output color at that point looking at that direction.  &lt;/p&gt;
&lt;p&gt;Very importantly the volume density is output before the direction is added into the network so the volume density remains independent of direction.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;High frequency embeddings&lt;/strong&gt;&lt;br&gt;
When we just talked about the position and direction inputs to the network, I said they had dimensions 60 and 24 respectively. You might be thinking, "That doesn't make any sense. The position and direction are both just 3 dimensional vectors!" So far you would be correct but importantly the authors are not really giving the network just the position and direction vectors. They are giving the network those vectors embedded in a higher dimensional space using a frequency based encoding. &lt;/p&gt;
&lt;p&gt;The embedding the authors choose to use for single number p to a point in space of dimension &lt;span class="math"&gt;\(2L\)&lt;/span&gt; is:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/embedding.png" width="90%"&gt; 
&lt;/p&gt;
&lt;p&gt;The authors apply this embedding function to each of the 3 dimensions of the input vector separately and concatenate the result. They do this for position with &lt;span class="math"&gt;\(L=10\)&lt;/span&gt; and direction with &lt;span class="math"&gt;\(L=4\)&lt;/span&gt;.  &lt;/p&gt;
&lt;p&gt;Importantly when the position is input into this embedding function it has been scaled to be in &lt;span class="math"&gt;\([-1, 1]\)&lt;/span&gt;.  &lt;/p&gt;
&lt;p&gt;The reason for this embedding is that according to the nerf authors, neural networks are prone to learn low frequency functions. They cite &lt;a href="https://arxiv.org/abs/1806.08734"&gt;Rahaman et al&lt;/a&gt; to back up their claim who also proposes this frequency embedding to remedy the problem. An alternative reason to use frequency embeddings is that the structure of neural networks with only ReLU non-linearities limits the resolution by dividing the scene into polytopes which individually cannot represent non linear details&lt;sup id="sf-nerf-8-back"&gt;&lt;a href="#sf-nerf-8" class="simple-footnote" title="Pure ReLU networks are just the piecewise linear functions over the input space. In the original NeRF paper, the volume density calculated without embeddings is represented by a pure ReLU network. Without any embeddings all the network does to determine the volume density is divide the space into polytopes and do a polytope specific linear prediction based on the x, y and z coordinates to determine the depth. This means non linear details cannot be captured inside a polytope, limiting the resolution. Adding sin and cos makes the network non piecewise linear."&gt;8&lt;/a&gt;&lt;/sup&gt;.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hierarchical Sampling&lt;/strong&gt;&lt;br&gt;
Another problem with NeRF in practice is many of the samples we take will likely hit empty space. If we could more efficiently allocate our samples around actual changes in density we could get better resolution allowing us to capture finer details.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/nerf/inverse_transform_sampling.png" width="90%"&gt; 
&lt;/p&gt;
&lt;p&gt;The original paper does this by training two different networks. One "coarse" network and one "fine" network. The coarse network allocates samples using the original bin strategy from our &lt;strong&gt;Tracing Rays&lt;/strong&gt; section. Then the fine network allocates its samples to the same bins based on the relative likelihood of hitting a particle in each bin. The NeRF authors call this inverse transform sampling.  &lt;/p&gt;
&lt;p&gt;Here's an example of the images rendered using each of the two networks:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;/p&gt;&lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;img src="/images/nerf/coarse_lego_view1.png"&gt;
        &lt;img src="/images/nerf/fine_lego_view1.png"&gt;
    &lt;/div&gt; 
    &lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;img src="/images/nerf/coarse_lego_view2.png"&gt;
        &lt;img src="/images/nerf/fine_lego_view2.png"&gt;
    &lt;/div&gt; 
    &lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;img src="/images/nerf/coarse_lego_view3.png"&gt;
        &lt;img src="/images/nerf/fine_lego_view3.png"&gt;
    &lt;/div&gt; 
    &lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;img src="/images/nerf/coarse_ficus_view1.png"&gt;
        &lt;img src="/images/nerf/fine_ficus_view1.png"&gt;
    &lt;/div&gt; 
&lt;p&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;/p&gt;&lt;div style="display: flex; justify-content: space-around;"&gt;
        &lt;p align="center"&gt; 64 coarse network samples &lt;br&gt; sampled naively &lt;/p&gt;
        &lt;p align="center"&gt; 64 fine network samples &lt;br&gt; from inverse transform sampling &lt;/p&gt;
    &lt;/div&gt; 
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;Notice how the coarse network boundaries (left) are fuzzier than the fine network boundaries (right). This is because we are sampling more points around the boundaries from the fine network.  &lt;/p&gt;
&lt;p&gt;An important implementation detail is the loss from both networks are summed together into the objective function.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limitations of the original NeRF Paper&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Train time&lt;/strong&gt;&lt;br&gt;
The biggest limitation of the original NeRF paper is the time it takes to render rays. The authors claim an 800x800 image takes 30 seconds to render on a V100 and 1-2 days to train a high resolution radiance field&lt;sup id="sf-nerf-9-back"&gt;&lt;a href="#sf-nerf-9" class="simple-footnote" title="For my renders, I use about 6000 iterations and render at 200x200 resolution which is much faster"&gt;9&lt;/a&gt;&lt;/sup&gt;. Many people have since researched and made enormous progress on this topic. Recently Nvidia's &lt;a href="https://github.com/NVlabs/instant-ngp"&gt;Instant NeRF&lt;/a&gt; reduced rendering to 10s of milliseconds and training to mere minutes which is wild given that NeRF is only a few years old.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rigidity assumption&lt;/strong&gt;&lt;br&gt;
Another huge assumption the original NeRF paper makes is that the scene it's capturing is static.   &lt;/p&gt;
&lt;p&gt;One scenario which clearly violates this assumption is reconstructing a moving subject such as a person walking in a video. Works such as &lt;a href="https://video-nerf.github.io/"&gt;Video NeRF&lt;/a&gt; try to tackle this problem.  &lt;/p&gt;
&lt;p&gt;Another slightly more subtle scenario where violations of the rigidity assumption causes problems is when trying to reconstruct static real world objects (such as famous buildings or statues) from crowd sourced pictures. Some violations here include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The subject of the photo will be different colors during different times of day.&lt;/li&gt;
&lt;li&gt;Different cameras have different color ranges and tone mapping&lt;/li&gt;
&lt;li&gt;People, cars or other dynamic objects will occlude different part of the object in different photos  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Researchers from Google address these problems in &lt;a href="https://nerf-w.github.io/"&gt;NeRF in the Wild&lt;/a&gt;. The basic idea is that they learn different networks representing the static details (things that don't change between photos) and transient details in each photo.  &lt;/p&gt;
&lt;p&gt;By explicitly separating out the static and transient details they can reconstruct objects much more accurately. They also are able to do neat things like arbitrarily change the position of the sun while rendering.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Structural Camera Errors&lt;/strong&gt;&lt;br&gt;
As we discussed earlier NeRF is based on a pinhole camera model which comes with a host of unrealistic assumptions about the structure of the camera used to take the input photos. It seems like a classic NeRF research project is rebuild NeRF based on a more accurate camera model.  &lt;/p&gt;
&lt;p&gt;One big assumption is to totally disregard depth of field. It's very possible that depth of field error can be modeled as per camera noise and disregarded by the techniques used in NeRF in the Wild (discussed above) but DoF information could also provide useful clues to estimate the scene. Wu et al build a &lt;a href="https://github.com/zijinwuzijin/DoF-NeRF"&gt;NeRF which incorporates DoF&lt;/a&gt;. They seem to find that it produces sharper radiance fields than vanilla NeRF when used on images with shallow depth of field. However I don't see them comparing their technique to &lt;em&gt;NeRF in the Wild&lt;/em&gt; which would be nice. Other papers do similar types of camera corrections such as &lt;a href="http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/ar-nerf/"&gt;AR NeRF&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href="https://limacv.github.io/deblurnerf/"&gt;Deblur NeRF&lt;/a&gt; models a camera with non instantaneous shutter speed to reconstruct radiance fields from motion blurred images more accurately.  &lt;/p&gt;
&lt;p&gt;&lt;a href="https://jonbarron.info/mipnerf/"&gt;MIP NeRF&lt;/a&gt; integrates the radiance field over cones instead of rays (it uses multiple samples per pixel) to more accurately capture the underlying field radiance.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limits of the radiance field&lt;/strong&gt;&lt;br&gt;
Unlike some differential rendering methods NeRF only predicts depth and color at first bounce in a scene. This means it does not learn deeper structures such as the position of light sources in the scene or unlit object textures. Many followup methods including &lt;em&gt;NeRF in the Wild&lt;/em&gt; make strides to learn more of the underlying scene structure.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My Own Journey Implementing NeRF&lt;/strong&gt;&lt;br&gt;
To further my knowledge of NeRF I didn't just read the paper, I also implemented it in pytorch. As a testament to how good the original paper was, I was able to do it without looking at any of the code. After I finished I was surprised by how structurally different&lt;sup id="sf-nerf-10-back"&gt;&lt;a href="#sf-nerf-10" class="simple-footnote" title='Read as "worse"'&gt;10&lt;/a&gt;&lt;/sup&gt; my implementation was from the official repository.  &lt;/p&gt;
&lt;p&gt;Coding NeRF was an interesting experience. I suspect some of the differences in implementation stemmed from the fact I approach the problem as a programmer trying to break a known algorithm into independent testable pieces rather than a researcher discovering something for the first time (also I am not as good at pytorch so my code is less concise but that's way less fun to say).  &lt;/p&gt;
&lt;p&gt;Here's a quick summary of what I did:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Created a simple test scene in Blender, a cube with different colored sides&lt;sup id="sf-nerf-11-back"&gt;&lt;a href="#sf-nerf-11" class="simple-footnote" title="Fun Fact: I used ChatGPT to help me write this Blender script because I have never used Blender and it was not a focus of this project"&gt;11&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Created basic sampling and ray tracing functions, adding many simple tests.&lt;/li&gt;
&lt;li&gt;Made some more complex tests where I rendered a full scene with coarse sampling. For these tests I mocked out the neural network with a hand crafted radiance field representing the same cube I had made in Blender earlier and compared the images my code rendered with the "ground truth" Blender images&lt;/li&gt;
&lt;li&gt;Created the neural network and made sure all the tensor dimensions were correct&lt;/li&gt;
&lt;li&gt;Tried to learn the cube. This did not work&lt;/li&gt;
&lt;li&gt;Did a simple test to see if I could learn a field of all one solid color. That worked&lt;/li&gt;
&lt;li&gt;Tried to learn an unlit sphere and found my bug&lt;/li&gt;
&lt;li&gt;Rendered the cube successfully on my laptop&lt;/li&gt;
&lt;li&gt;Experimented using colab to render on a gpu and realized I hadn't added any gpu support&lt;/li&gt;
&lt;li&gt;Added gpu support&lt;/li&gt;
&lt;li&gt;Rendered the lego excavator (resized to 200x200) model on a colab gpu&lt;/li&gt;
&lt;li&gt;Implemented the hierarchical network to get better image quality&lt;/li&gt;
&lt;li&gt;Rendered the lego model again&lt;/li&gt;
&lt;li&gt;Profiled and sped up my implementation&lt;sup id="sf-nerf-12-back"&gt;&lt;a href="#sf-nerf-12" class="simple-footnote" title="Just enough to run at about the same speed as the original paper, speed wasn't a priority for this project."&gt;12&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Ran a longer run on the lego excavator (again resized to 200x200) on Lambda A100 GPU ($1.10 an hour) for 3 hours&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;My goal was to build the simplest and most testable parts first, slowly piece them together and finally build and add the neural network itself. The nice thing about rigorously testing each piece was that when I could not learn a sphere in step 7 I knew that the bug had to be in the neural network not in my ray tracing code.   &lt;/p&gt;
&lt;p&gt;I also got a lot of mileage out of just testing on my laptop before moving to the more complex world of gpus and colab. This allowed me not to worry about the complexities of gpus up front.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;br&gt;
I had a great time learning about and implementing the original NeRF paper and will probably try some of the follow up work in the future (especially the real time version). In a world of huge deep inscrutable models with little structure, NeRF is a ray of sunshine. If you've read this far you might also want to consider implementing NeRF yourself! It's not as intimidating as it might seem and it's a great way to practice neural networks and computer graphics.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to &lt;a href="https://www.afox.land"&gt;Alex Fox&lt;/a&gt;, Laura Lindzey as well as several others for amazing feedback&lt;/em&gt;  &lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;  &lt;/p&gt;
&lt;hr&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;&lt;ol class="simple-footnotes"&gt;&lt;li id="sf-nerf-1"&gt;Forward rendering has a different meaning in realtime graphics for video games. This definition has nothing to do with that &lt;a href="#sf-nerf-1-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-2"&gt;Over 50 papers derived from NeRF were submitted to CVPR in 2022. This number is courtesy of &lt;a href="https://dellaert.github.io/NeRF22/"&gt;Frank Dellart&lt;/a&gt;  &lt;a href="#sf-nerf-2-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-3"&gt;I maintain this is technically true for a single point. However in ray tracing we are estimating the color for an entire pixel which is a rectangle, therefore serious ray tracers use techniques such as Monte Carlo sampling to sample many points inside each pixel's rectangle and merge them together to get a final color &lt;a href="#sf-nerf-3-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-4"&gt;If you are scratching your head at how this is accomplished you are absolutely correct. In fact I'd be a little worried if you weren't confused. The answer to this question is incredibly complex and a good chunk of the subfield of computer graphics called Physically Based Rendering is dedicated to creating more and more accurate approximations. A great place to start is the &lt;a href="https://www.pbr-book.org/3ed-2018/contents"&gt;Pbr book&lt;/a&gt; &lt;a href="#sf-nerf-4-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-5"&gt;I'm not going to go into detail about volume rendering here (mostly due to my own ignorance). Please look at &lt;a href="https://www.scratchapixel.com/lessons/3d-basic-rendering/volume-rendering-for-developers/volume-rendering-summary-equations"&gt;Scratchapixel's volume rendering section&lt;/a&gt; or &lt;a href="https://www.pbr-book.org/3ed-2018/Volume_Scattering"&gt;this chapter of the pbr book&lt;/a&gt; for a great introduction &lt;a href="#sf-nerf-5-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-6"&gt;This is a lie for some parts of the function because the neural network in the original paper contains &lt;a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)"&gt;ReLUs&lt;/a&gt; but gradient descent still works in practice &lt;a href="#sf-nerf-6-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-7"&gt;One problem with rectifying the volume density with ReLU is that sometimes when training the network the ReLU will start "dead" (with a &lt;span class="math"&gt;\(value \le 0\)&lt;/span&gt;) at which point the gradient is 0. The network will then make no progress producing all black images. The NeRF authors somewhat solve this problem by adding gaussian noise to the ReLU on their "real world" images but I'm not sure it's addressed fully. &lt;a href="#sf-nerf-7-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-8"&gt;Pure ReLU networks are just the piecewise linear functions over the input space. In the original NeRF paper, the volume density calculated without embeddings is represented by a pure ReLU network. Without any embeddings all the network does to determine the volume density is divide the space into polytopes and do a polytope specific linear prediction based on the x, y and z coordinates to determine the depth. This means non linear details cannot be captured inside a polytope, limiting the resolution. Adding sin and cos makes the network non piecewise linear. &lt;a href="#sf-nerf-8-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-9"&gt;For my renders, I use about 6000 iterations and render at 200x200 resolution which is much faster &lt;a href="#sf-nerf-9-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-10"&gt;Read as "worse" &lt;a href="#sf-nerf-10-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-11"&gt;Fun Fact: I used ChatGPT to help me write this Blender script because I have never used Blender and it was not a focus of this project &lt;a href="#sf-nerf-11-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;li id="sf-nerf-12"&gt;Just enough to run at about the same speed as the original paper, speed wasn't a priority for this project. &lt;a href="#sf-nerf-12-back" class="simple-footnote-back"&gt;↩&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;</content><category term="graphics, pytorch, deep learning"></category><category term="graphics"></category><category term="pytorch"></category><category term="deep learning"></category></entry><entry><title>A Linear Time Solution To Advent of Code Day 8</title><link href="/advent.html" rel="alternate"></link><published>2021-01-05T00:00:00-08:00</published><updated>2021-01-05T00:00:00-08:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2021-01-05:/advent.html</id><summary type="html">&lt;p&gt;Cutting loopy loops&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago I tried to go through Advent of Code 2020 (spoiler I didn't finish). Advent of Code is a set of 25 coding challenges each with two parts. The challenges are unveiled one at a time from the beginning of December until Christmas day.   &lt;/p&gt;
&lt;p&gt;One fun thing about Advent of Code is that everyone does it differently. People write solutions in every language out there (and some new ones they've invented) using many different techniques (I'm sure there's someone who tries to do the whole thing in regex).  &lt;/p&gt;
&lt;p&gt;I found part 2 of &lt;a href="https://adventofcode.com/2020/day/8"&gt;problem 8&lt;/a&gt; to be very interesting and wanted to write up my solution.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A Quick Summary of the Problem&lt;/strong&gt;&lt;br&gt;
Part 2 of day 8 basically boils down to the following:&lt;br&gt;
We have a very simple machine. Initially there is a program counter, which starts at the beginning of the program, and a single global counter, which starts at 0. At each step, the instruction that the counter is pointing to is executed. There are 3 different instruction types each taking an integer parameter:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;jmp arg, increments the program counter by arg  &lt;/li&gt;
&lt;li&gt;add arg, adds arg to a global counter and increments the program counter by 1&lt;/li&gt;
&lt;li&gt;nop arg, increments the program counter by 1. It does not use its argument but it still takes one  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the counter ends up pointing one index past the last instruction, the program ends and returns the global counter value.  &lt;/p&gt;
&lt;p&gt;Here's an example program:&lt;br&gt;
0: nop +0&lt;br&gt;
1: acc +1&lt;br&gt;
2: jmp +2&lt;br&gt;
3: acc +5&lt;br&gt;
4: acc +2    &lt;/p&gt;
&lt;p&gt;This program returns 3.   &lt;/p&gt;
&lt;p&gt;What about this program?&lt;br&gt;
0: nop +0&lt;br&gt;
1: acc +1&lt;br&gt;
2: jmp +4&lt;br&gt;
3: acc +3&lt;br&gt;
4: jmp -3 &lt;br&gt;
5: acc -99&lt;br&gt;
6: acc +1&lt;br&gt;
7: jmp -4&lt;br&gt;
8: acc +6    &lt;/p&gt;
&lt;p&gt;It never ends! If we trace the execution of this program, we will find out we are actually stuck in an infinite loop!  &lt;/p&gt;
&lt;p&gt;In this problem, we can assume any looping program we encounter can be fixed by changing either a nop to a jmp or a jmp to a nop in exactly one place. Importantly the argument to the flipped jmp / nop does not change. In the above program changing instruction 7 to a nop will fix the program, allowing it to terminate with a value of 8.  &lt;/p&gt;
&lt;p&gt;Our task is to take in a looping program, find the one flipped instruction, change it and get the return value of the terminating program.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Simple Solution:&lt;/strong&gt;&lt;br&gt;
One simple thing we could do to find the solution is to try to flip each jmp and nop instruction, one at a time, and rerun the entire program after each flip. One of the flips is guaranteed to make the program stop looping and we will just return the result from that run. This solution is both straightforward and solves the problem which makes it a great solution. Algorithmically it runs in O(number of instructions^2) because we must run the entire program once for every instruction we flip.  &lt;/p&gt;
&lt;p&gt;However in the spirit of doing each challenge in different ways I wondered if this problem could be done faster?  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;An Edgy Approach&lt;/strong&gt;&lt;br&gt;
Another way to think of these programs is as directed graphs. Each node represents an instruction and has an edge pointing towards the next executed instruction.   &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/advent/graph.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;I've now marked every instruction in the initial loop as red.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/advent/red-graph.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;A quick but important fact is that the instruction that we need to flip must be in the initial loop. So it must be one of these original red instructions.   &lt;/p&gt;
&lt;p&gt;Now we are going to try to flip each of the red jmp / nop these instructions one by one and check each time to see if the modified program terminates.  &lt;/p&gt;
&lt;p&gt;What?! Isn't that exactly what we did in the N^2 solution above? It turns out the difference will be not in the number of instructions we try to flip, but how we check for program termination.  &lt;/p&gt;
&lt;p&gt;Before we start our algorithm, let's create a set called cyclic_nodes. This is a subset of all the nodes which are guaranteed to connect to a cycle in the unmodified graph. Initially this set will contain all the red nodes in the first loop.   &lt;/p&gt;
&lt;p&gt;Now let's try flipping one of our red jmp / nop nodes (call it Node A). That node's edge now points somewhere else in the graph (Node B). There are two cases here:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Node B is already in cyclic_nodes. This means that we are guaranteed to get stuck in a cycle so we can know Node A isn't the correct node to flip. To see why consider these two sub cases: &lt;ul&gt;
&lt;li&gt;There is a path from Node B to Node A. In this case we know we are still in a cycle. We know this because even though the graph has been modified, the only modification is to the edge leaving Node A so none of the nodes on the path from B to A will have been changed.  &lt;/li&gt;
&lt;li&gt;There is a path from Node B to a different cycle. By similar logic to the first part, since no node on that path or in that cycle has been modified the program will loop.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Node A points to a node not yet in cyclic nodes. In this case we follow the path until we either hit a node in cyclic nodes, loop in a never before seen cycle, or hit the end of the program.&lt;ul&gt;
&lt;li&gt;If we hit the end of the program we have found the instruction to flip and we are done&lt;/li&gt;
&lt;li&gt;In the other two cases we have entered a cycle. Add all nodes we walked over to the cyclic_nodes set and move to the next instruction. &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What is the runtime of this algorithm? Well we only go over each potential switch once. However unlike the simple algorithm, we also know during the check for cycle step each node is only added to the cyclic_nodes set once. Therefore the runtime is linear with respect to the number of instructions.&lt;/p&gt;</content><category term="algorithms"></category><category term="algorithms"></category></entry><entry><title>Dynamically Deducing Data Dependencies</title><link href="/dependency-tracking.html" rel="alternate"></link><published>2020-12-14T00:00:00-08:00</published><updated>2020-12-14T00:00:00-08:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-12-14:/dependency-tracking.html</id><summary type="html">&lt;p&gt;Also an amazing alliteration&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;br&gt;
A few weeks ago, I was talking to &lt;a href="https://jemma.dev/"&gt;Jemma Issroff&lt;/a&gt;, a fellow &lt;a href="https://www.recurse.com/"&gt;Recurser&lt;/a&gt;, about a toy programming language she was building. We ended up thinking about automatically memoizing pure functions based on their parameters. As we thought about this problem more and more, we decided it would be interesting to be able to tell which parameters of function were actually required to compute its result at runtime. The idea at the time was that we could cache just based on those parameters. It turned out that just figuring out how to compute those dependencies was an interesting question in itself.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem Statement&lt;/strong&gt;&lt;br&gt;
Let's say we have a function &lt;span class="math"&gt;\(f\)&lt;/span&gt; that takes arguments &lt;span class="math"&gt;\(x_1,...,x_n\)&lt;/span&gt; and outputs some result &lt;span class="math"&gt;\(res\)&lt;/span&gt;. We want to check at runtime which of those arguments are really necessary to compute &lt;span class="math"&gt;\(res\)&lt;/span&gt;. Let's take a very simple example:  &lt;/p&gt;
&lt;pre&gt;
let f = fn(x, y, z) {
  return y
}
&lt;/pre&gt;
&lt;p&gt;Now if we call 
&lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(x%2C%20y%2C%20z)%20%7B%0A%20%20return%20y%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependency%20of%20it%27s%20arguments%20as%20a%20graph%0Adep_diagraph(f(1%2C%202%2C%203))%0A"&gt;&lt;span class="math"&gt;\(f(1,2,3)\)&lt;/span&gt;&lt;/a&gt;
, it's pretty clear that the result &lt;span class="math"&gt;\(2\)&lt;/span&gt; only depends on &lt;span class="math"&gt;\(2\)&lt;/span&gt;, the value of the second argument. Of course we could have figured that out at compile time (and in fact most compilers will yell at you to tell you &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(z\)&lt;/span&gt; are unused).
But now let's take a slightly more interesting case:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;}&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;}&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Unlike the first example, clearly all the variables are used here. However, if we evaluate
 &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(x%2C%20y%2C%20z)%20%7B%0A%20%20if%20(x%20%3E%200)%20%7B%0A%20%20%20%20return%20y%0A%20%20%7D%20else%20%7B%0A%20%20%20%20return%20z%0A%20%20%7D%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(1%2C2%2C3)%0Adep_diagraph(f(1%2C%202%2C%203))%0A"&gt;&lt;span class="math"&gt;\(f(1,2,3)\)&lt;/span&gt;&lt;/a&gt;
  the output &lt;span class="math"&gt;\(2\)&lt;/span&gt; only depends on the values of &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt;.   &lt;/p&gt;
&lt;p&gt;Let's stop here for a second and unpack that statement a little. Why am I saying the return value of &lt;span class="math"&gt;\(f(1,2,3)\)&lt;/span&gt; depends on both &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(y\)&lt;/span&gt; even though the return value is exactly equal to the just value of &lt;span class="math"&gt;\(y\)&lt;/span&gt;?  &lt;/p&gt;
&lt;p&gt;The answer is because if the value of x were to change in a certain way (for example from &lt;span class="math"&gt;\(1\)&lt;/span&gt; to &lt;span class="math"&gt;\(-1\)&lt;/span&gt;), our return value would change.   &lt;/p&gt;
&lt;p&gt;On the other hand, the return value of 
&lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(x%2C%20y%2C%20z)%20%7B%0A%20%20if%20(x%20%3E%200)%20%7B%0A%20%20%20%20return%20y%0A%20%20%7D%20else%20%7B%0A%20%20%20%20return%20z%0A%20%20%7D%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(1%2C2%2C3)%0Adep_diagraph(f(-1%2C%202%2C%203))%0A"&gt;&lt;span class="math"&gt;\(f(-1,2,3)\)&lt;/span&gt;&lt;/a&gt;
 depends on &lt;span class="math"&gt;\(x\)&lt;/span&gt; and &lt;span class="math"&gt;\(z\)&lt;/span&gt;.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Definition of Dependency&lt;/strong&gt;&lt;br&gt;
So far, we've been talking about what dependence means informally. For all the &lt;a href="https://www.google.com/search?q=mathematicians"&gt;sticklers out there&lt;/a&gt;, I'm going to give a more concrete definition. We can say that expression &lt;span class="math"&gt;\(a\)&lt;/span&gt; depends on expression &lt;span class="math"&gt;\(b\)&lt;/span&gt; iff in order to compute the value of &lt;span class="math"&gt;\(a\)&lt;/span&gt; the value of &lt;span class="math"&gt;\(b\)&lt;/span&gt; must first be computed.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Rules of Dependency Propagation&lt;/strong&gt;&lt;br&gt;
Now that we have an intuitive understanding of how to determine which dependencies a function needs, let's try to make this intuition into a concrete algorithm.  &lt;/p&gt;
&lt;p&gt;First we're going to quickly introduce one more operator &lt;span class="math"&gt;\(+\)&lt;/span&gt;.   &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;,&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The dependencies of any call to this function, for example &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(x%2C%20y)%20%7B%0A%20%20return%20x%20%2B%20y%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(1%2C2%2C3)%0Adep_diagraph(f(1%2C%202))%0A"&gt;&lt;span class="math"&gt;\(f(1,2)\)&lt;/span&gt;&lt;/a&gt;, are simply x and y.
But now let's look at a more complicated example:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;Let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;}&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;}&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This example isn't too much more complicated than any of the previous ones. A quick look will tell us 
&lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(x%2C%20y%2C%20z)%20%7B%0A%20%20let%20s%20%3D%20z%20%2B%20y%0A%20%20if%20(s%20%3C%200)%20%7B%0A%20%20%20%20return%20x%0A%20%20%7D%20else%20%7B%0A%20%20%20%20return%20s%0A%20%20%7D%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(1%2C2%2C3)%0Adep_diagraph(f(1%2C%202%2C%203))%0A"&gt;&lt;span class="math"&gt;\(f(1,2,3)\)&lt;/span&gt;&lt;/a&gt;
 will give a result of &lt;span class="math"&gt;\(5\)&lt;/span&gt; and will depend on &lt;span class="math"&gt;\(y\)&lt;/span&gt; and &lt;span class="math"&gt;\(z\)&lt;/span&gt;. It will also allow us to determine, 
 &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(x%2C%20y%2C%20z)%20%7B%0A%20%20let%20s%20%3D%20z%20%2B%20y%0A%20%20if%20(s%20%3C%200)%20%7B%0A%20%20%20%20return%20x%0A%20%20%7D%20else%20%7B%0A%20%20%20%20return%20s%0A%20%20%7D%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(1%2C2%2C3)%0Adep_diagraph(f(1%2C%202%2C%20-3))%0A"&gt;&lt;span class="math"&gt;\(f(1, 2, -3)\)&lt;/span&gt;&lt;/a&gt;
  will give a result of &lt;span class="math"&gt;\(1\)&lt;/span&gt; and depend on &lt;span class="math"&gt;\(x\)&lt;/span&gt;, &lt;span class="math"&gt;\(y\)&lt;/span&gt; and &lt;span class="math"&gt;\(z\)&lt;/span&gt;. However, there is a more systematic way we can evaluate the dependencies (you're probably even using it in your head).   &lt;/p&gt;
&lt;p&gt;Let's create two rules, one for "+" and one for "if". Let's pretend x, y, z are generic expressions and deps(e) of an expression &lt;span class="math"&gt;\(e\)&lt;/span&gt; gives the set of all of its dependencies.&lt;br&gt;
Here are our two rules:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(let\,res = x + y;\)&lt;/span&gt; &lt;span class="math"&gt;\(deps(res) = deps(x) \cup deps(y)\)&lt;/span&gt; (where &lt;span class="math"&gt;\(\cup\)&lt;/span&gt; is the union of two sets)  &lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(let\,res = if\,(x)\,\{ y \}\,else\,\{ z \};\)&lt;/span&gt; if x is true then &lt;span class="math"&gt;\(deps(res) = deps(x) \cup deps(y)\)&lt;/span&gt; else &lt;span class="math"&gt;\(deps(res) = deps(x) \cup deps(z)\)&lt;/span&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Combining these two rules we can trace the dependencies of any function made up of only additions and if statements! While that's not really mind blowing, I found it kind of interesting.  &lt;/p&gt;
&lt;p&gt;Now if you are a battle hardened senior software engineer, you probably know that some of the most advanced programs powering cutting edge tech companies like Google and Facebook will occasionally use more operators than just "+" and "if".  &lt;/p&gt;
&lt;p&gt;So how do we handle other operations? Simple! Create more rules!    &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Arithmetic&lt;/strong&gt;&lt;br&gt;
Unlike in grade school, here arithmetic is simple. Almost all arithmetic operators follow the exact same rules as "+" (except multiplication).  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Short Circuit Operators&lt;/strong&gt;&lt;br&gt;
Okay now let's do multiplication. Imagine you have the following statement:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;g&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;m&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;g&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;s&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A call like &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(m%2C%20a%2C%20n%2C%20y%2C%20a%2C%20r%2C%20g%2C%20s)%20%7B%0A%20%20return%20m%20*%20a%20*%20n%20*%20y%20*%20a%20*%20r%20*%20g%20*%20s%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(1%2C2%2C3%2C4%2C5%2C6%2C7%2C8)%0Adep_diagraph(f(1%2C%202%2C%203%2C%204%2C%205%2C%206%2C%207%2C%208))%0A"&gt;&lt;span class="math"&gt;\(f(1, 2, 3, 4, 5, 6, 7, 8)\)&lt;/span&gt;&lt;/a&gt; depends on every argument passed to f. However, what about this call &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(m%2C%20a%2C%20n%2C%20y%2C%20a%2C%20r%2C%20g%2C%20s)%20%7B%0A%20%20return%20m%20*%20a%20*%20n%20*%20y%20*%20a%20*%20r%20*%20g%20*%20s%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(0%2C2%2C3%2C4%2C5%2C6%2C7%2C8)%0Adep_diagraph(f(0%2C%202%2C%203%2C%204%2C%205%2C%206%2C%207%2C%208))%0A"&gt;&lt;span class="math"&gt;\(f(0, 2, 3, 4, 5, 6, 7, 8)\)&lt;/span&gt;&lt;/a&gt;? Notice that the only variable which really affects the output of the product is &lt;span class="math"&gt;\(m\)&lt;/span&gt; with value 0. As long as the value of &lt;span class="math"&gt;\(m\)&lt;/span&gt; remains 0, the value of the result will be 0 no matter what value any other variable takes. This idea is conceptually similar to &lt;a href="https://en.wikipedia.org/wiki/Short-circuit_evaluation"&gt;short circuit evaluation for boolean values&lt;/a&gt;.   &lt;/p&gt;
&lt;p&gt;Now you might ask what if there are multiple values that are all zero &lt;span class="math"&gt;\(f(0, 2, 3, 0, 5, 6, 7, 0)\)&lt;/span&gt;? Which one should we choose to depend on? &lt;br&gt;
There are a couple options here:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose the first available zero. This matches up with classic short circuit evaluation.&lt;/li&gt;
&lt;li&gt;Choose the zero with the fewest dependencies. Choosing this option is less efficient but will ensure that our deps function returns the smallest set of dependencies possible.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This optimization can also be applied to boolean functions such as &amp;amp;&amp;amp; and ||.   &lt;/p&gt;
&lt;p&gt;Short Circuit Rules (for the Classic Short Circuit Strategy):  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(let\,res = x_0\,*... *\,x_n;\)&lt;/span&gt; If no expression &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; is zero, &lt;span class="math"&gt;\(deps(res) = \bigcup_{i=0} deps(x_i)\)&lt;/span&gt;.        Otherwise &lt;span class="math"&gt;\(let\,i =argmin_{i}\{x_i == 0\},\)&lt;/span&gt; &lt;span class="math"&gt;\(deps(res) = deps(x_i)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(let\,res = x_0\,\&amp;amp;\&amp;amp;\,...\,\&amp;amp;\&amp;amp;\,x_n;\)&lt;/span&gt; If no expression &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; is false, &lt;span class="math"&gt;\(deps(res) = \bigcup_{i=0}\,deps(x_i)\)&lt;/span&gt;. &lt;br&gt;
Otherwise &lt;span class="math"&gt;\(let\,i = argmin_{i}\{x_i == false\},\)&lt;/span&gt; &lt;span class="math"&gt;\(deps(res) = deps(x_i)\)&lt;/span&gt; &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(let\,res = x_0\,||... ||\,x_n;\)&lt;/span&gt; If no expression &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; is true, &lt;span class="math"&gt;\(deps(res) = \bigcup_{i=0} deps(x_i)\)&lt;/span&gt;. Otherwise &lt;span class="math"&gt;\(let\,i = argmin_{i}\{x_i == true\},\)&lt;/span&gt; &lt;span class="math"&gt;\(deps(res) = deps(x_i)\)&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Functions Calls&lt;/strong&gt;&lt;br&gt;
Here's a slightly trickier case:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;g&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;}&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;}&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;x&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;y&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;g&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;z&lt;/span&gt;,&lt;span class="nv"&gt;x&lt;/span&gt;,&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The above example represents a function call within a function call. In order to define this rule we need a few quick definitions:&lt;/p&gt;
&lt;p&gt;Let's define a function called &lt;span class="math"&gt;\(argdeps(f, a_0, a_1,...,a_n)\)&lt;/span&gt;. &lt;span class="math"&gt;\(argdeps\)&lt;/span&gt; takes a function &lt;span class="math"&gt;\(f\)&lt;/span&gt; and its arguments &lt;span class="math"&gt;\(a_0,...,a_n\)&lt;/span&gt; and returns indices of the arguments which are needed to compute the corresponding value of &lt;span class="math"&gt;\(f\)&lt;/span&gt;. Under the hood, this function is computed in the exact same way that we have been computing deps.&lt;/p&gt;
&lt;p&gt;Let's define f to be a function with n arguments, and x_0,...,x_n to be n expressions. Now we can make our rule:&lt;br&gt;
&lt;span class="math"&gt;\(let\,res = f(x_0,...,x_n);\)&lt;/span&gt;  &lt;span class="math"&gt;\(deps(f) = U_{i = argdeps(f,\,x_0,...,\,x_n)} deps(x_i)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lists&lt;/strong&gt;&lt;br&gt;
Now that we're feeling warmed up we can tackle one of the more complex rules sets.  &lt;/p&gt;
&lt;p&gt;Let's take a quick look at a function involving lists.  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;[&lt;span class="mi"&gt;2&lt;/span&gt;]&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now fellow travellers, we have come to a fork in the road. To one side, lies the simple path on which we treat the entire list &lt;span class="math"&gt;\(a\)&lt;/span&gt; as a single unit. We would then say that the output of &lt;span class="math"&gt;\(f\)&lt;/span&gt; merely depends on a. To the other side lies the difficult path, to treat each element of &lt;span class="math"&gt;\(a\)&lt;/span&gt; as its own unit. &lt;/p&gt;
&lt;p&gt;Many would say, we can choose the best route to take based on tradeoffs and product requirements. Normally, I would agree that taking the simple path is a totally reasonable option. However on this particular journey, I believe we don't really have a choice, we have a responsibility.&lt;/p&gt;
&lt;p&gt;Let's look back at our example from above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;[&lt;span class="mi"&gt;0&lt;/span&gt;]&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;[&lt;span class="mi"&gt;2&lt;/span&gt;]&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The dependencies of this function are &lt;span class="math"&gt;\(a[0]\)&lt;/span&gt; and &lt;span class="math"&gt;\(a[2]\)&lt;/span&gt;. This new notation is very simple but important, especially when talking about multi dimensional arrays. One subtle note is that this notation allows us to specify different levels of granularity. &lt;span class="math"&gt;\(a[0]\)&lt;/span&gt; for example, could be a single element or an entire array. I have also not actually defined what the set &lt;span class="math"&gt;\(deps(a[0])\)&lt;/span&gt; is yet. Before we actually get there, it will be useful to look at a few more examples.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This example is incredibly simple but important to look at. Let's look at &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(a)%20%7B%0A%20%20return%20a%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(%5B1%2C2%2C3%5D)%0Adep_diagraph(f(%5B1%2C2%2C3%5D))%0A"&gt;&lt;span class="math"&gt;\(f([1,2,3])\)&lt;/span&gt;&lt;/a&gt;. So it might seem like &lt;span class="math"&gt;\(f([1,2,3])\)&lt;/span&gt; just depends on the expressions at &lt;span class="math"&gt;\(a[0], a[1], a[2]\)&lt;/span&gt;, but is that really correct?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Recomputablity Test&lt;/strong&gt;&lt;br&gt;
Here's a way to test our intuition:&lt;/p&gt;
&lt;p&gt;Say we call a function &lt;span class="math"&gt;\(f\)&lt;/span&gt; once with args &lt;span class="math"&gt;\(x_0,...,x_n\)&lt;/span&gt; giving us the resulting value &lt;span class="math"&gt;\(r_0\)&lt;/span&gt; and the resulting set of dependencies &lt;span class="math"&gt;\(D_0\)&lt;/span&gt;. Then we call it again with arguments &lt;span class="math"&gt;\(y_0,...y_n\)&lt;/span&gt; and get the result &lt;span class="math"&gt;\(r_1\)&lt;/span&gt;. If all of the values of the dependencies given by &lt;span class="math"&gt;\(D_0\)&lt;/span&gt; are the same between the two calls, the results &lt;span class="math"&gt;\(r_0\)&lt;/span&gt; and &lt;span class="math"&gt;\(r_1\)&lt;/span&gt; should be the same. (Note this test only tells us if a set of dependencies is not valid, not that it's valid)&lt;/p&gt;
&lt;p&gt;Let's try using this test. &lt;span class="math"&gt;\(f([1,2,3])\)&lt;/span&gt; gives is the resulting array &lt;span class="math"&gt;\([1,2,3]\)&lt;/span&gt; and prospective dependency set &lt;span class="math"&gt;\(D_0\)&lt;/span&gt; = &lt;span class="math"&gt;\(a[0], a[1], a[2]\)&lt;/span&gt; with corresponding values &lt;span class="math"&gt;\(1,2,3\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now what if we call &lt;span class="math"&gt;\(f([1,2,3,4])\)&lt;/span&gt;? All of the values corresponding to &lt;span class="math"&gt;\(D_0\)&lt;/span&gt; remain unchanged so the value of &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(a)%20%7B%0A%20%20return%20a%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(%5B1%2C2%2C3%2C4%5D)%0Adep_diagraph(f(%5B1%2C2%2C3%2C4%5D))%0A"&gt;&lt;span class="math"&gt;\(f([1,2,3,4])\)&lt;/span&gt;&lt;/a&gt; must be &lt;span class="math"&gt;\([1,2,3]\)&lt;/span&gt; right? It's easy to see that this is wrong, so &lt;span class="math"&gt;\(a[0], a[1], a[2]\)&lt;/span&gt; cannot be our only dependencies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Length Dependencies&lt;/strong&gt;&lt;br&gt;
One way to fix our problem is to take an additional dependency on the length of a. We will use &lt;span class="math"&gt;\(lendeps(a)\)&lt;/span&gt; to denote the set of the expressions which the length of a depends on.&lt;/p&gt;
&lt;p&gt;So one rule which sums up what we've been saying is:&lt;br&gt;
&lt;span class="math"&gt;\(let\,res = a;\)&lt;/span&gt; (where a is a list) &lt;span class="math"&gt;\(deps(res) = \big(\bigcup_{i=0} deps(x_i)\big) \cup {lendeps(a)}\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;Since res is also an array we must also define its length dependencies with a second rule.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(lendeps(res) = lendeps(a)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;List Concatenation&lt;/strong&gt; &lt;br&gt;
Now let's talk about concatenation:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If a and b are two lists, the resulting third list depends on both a, b, and their lengths. Let's define &lt;span class="math"&gt;\(res = a + b\)&lt;/span&gt;. The rules for computing deps(res) and lendeps(res) are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class="math"&gt;\(deps(a+b) =\)&lt;/span&gt; &lt;span class="math"&gt;\(deps(a) \cup deps(b) \cup lendeps(a) \cup lendeps(b)\)&lt;/span&gt;  &lt;/li&gt;
&lt;li&gt;&lt;span class="math"&gt;\(lendeps(res) = lendeps(a) \cup lendeps(b)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But we are not actually quite done yet. Check out the function below:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;f&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;fn&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nv"&gt;let&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;c&lt;/span&gt;[&lt;span class="mi"&gt;3&lt;/span&gt;]&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function returns the 4th element of the concatenated list &lt;span class="math"&gt;\(a + b\)&lt;/span&gt;. So
 &lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(a%2C%20b)%20%7B%0A%20%20let%20c%20%3D%20b%20%2B%20a%0A%20%20return%20c%5B3%5D%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(%5B1%2C2%5D%2C%20%5B3%2C4%2C5%5D)%0Adep_diagraph(f(%5B1%2C2%5D%2C%5B3%2C4%2C5%5D))%0A"&gt;&lt;span class="math"&gt;\(f([1,2], [3,4,5])\)&lt;/span&gt;&lt;/a&gt;
would return 1 and 
&lt;a href="https://mr4k.github.io/konsole/?program=let%20f%20%3D%20fn(a%2C%20b)%20%7B%0A%20%20let%20c%20%3D%20b%20%2B%20a%0A%20%20return%20c%5B3%5D%0A%7D%0A%2F%2F%20this%20is%20a%20special%20builtin%20which%20renders%20the%20dependencies%20of%20its%20argument%20as%20a%20graph%0A%2F%2F%20to%20just%20get%20the%20normal%20output%20of%20f%20use%20the%20following%20instead%0A%2F%2F%20f(%5B1%2C2%5D%2C%20%5B3%2C4%2C5%2C6%5D)%0Adep_diagraph(f(%5B1%2C2%5D%2C%5B3%2C4%2C5%2C6%5D))%0A"&gt;&lt;span class="math"&gt;\(f([1,2],[3,4,5,6])\)&lt;/span&gt;&lt;/a&gt;
 would return &lt;span class="math"&gt;\(6\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Right now let's focus on the case of &lt;span class="math"&gt;\(f([1,2],[3,4,5,6])\)&lt;/span&gt;. The result depends on the 4th element of &lt;span class="math"&gt;\(c\)&lt;/span&gt; which is the 4th element of &lt;span class="math"&gt;\(a\)&lt;/span&gt;. Luckily the dependency set is simple here. It's just the 4th element of a. &lt;/p&gt;
&lt;p&gt;However if we look at the next case &lt;span class="math"&gt;\(f([1,2], [3,4,5])\)&lt;/span&gt;, the dependencies are a little more complicated. The result of this function does not just depend on a[0]. Can you see why? &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/dependency-tracking/array-concat.png" width="65%" &gt; 
&lt;/p&gt;

&lt;p&gt;What happens if we increase the size of b, for example by calling &lt;span class="math"&gt;\(f([1,2], [3,4,5,6])\)&lt;/span&gt;? The answer is definitely no longer 1 so using the Recomputablity Test from before we can tell that the dependencies of &lt;span class="math"&gt;\(f([1,2], [3,4,5])\)&lt;/span&gt; cannot just be &lt;span class="math"&gt;\(a[0]\)&lt;/span&gt;. You may already see where this is going, &lt;span class="math"&gt;\(f([1,2], [3,4,5])\)&lt;/span&gt; must depend on both &lt;span class="math"&gt;\(a[0]\)&lt;/span&gt; and &lt;span class="math"&gt;\(len(b)\)&lt;/span&gt;. &lt;/p&gt;
&lt;p&gt;Here we are again faced with a choice. We can either say that all elements in a list depend on their value and the length of the list or we can break it down more granularly. Granularity costs time and memory so it's a legitimate tradeoff. I choose to go down the more granular road (in the interest of keeping the dependency set smaller) but I will write out the rules for both versions:  &lt;/p&gt;
&lt;p&gt;Recall above we defined &lt;span class="math"&gt;\(res = a + b\)&lt;/span&gt; with two lists &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt;, then made a rule to define deps(res) and lendeps(res). So here's a third rule which is recursively applied to all elements e of &lt;span class="math"&gt;\(res\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(non granular version, larger dependency set) let &lt;span class="math"&gt;\(x\)&lt;/span&gt; be the child of &lt;span class="math"&gt;\(a\)&lt;/span&gt; or &lt;span class="math"&gt;\(b\)&lt;/span&gt; which corresponds to &lt;span class="math"&gt;\(e\)&lt;/span&gt;, &lt;span class="math"&gt;\(deps(e) = deps(x) \cup lendeps(a)\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;(granular version) 
let &lt;span class="math"&gt;\(x\)&lt;/span&gt; be a child of &lt;span class="math"&gt;\(a\)&lt;/span&gt; which corresponds to &lt;span class="math"&gt;\(e\)&lt;/span&gt;, &lt;span class="math"&gt;\(deps(e) = deps(x)\)&lt;/span&gt;.&lt;br&gt;
On the other hand, let &lt;span class="math"&gt;\(x\)&lt;/span&gt; be a child of &lt;span class="math"&gt;\(b\)&lt;/span&gt; which corresponds to &lt;span class="math"&gt;\(e\)&lt;/span&gt;, &lt;span class="math"&gt;\(deps(e) = deps(x) \cup lendeps(a)\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A quick note about the computation feasibility of this rule. This rule as is applied recursively to every element in a and b so it is very computational intensive when you have large multidimensional arrays. I'd recommend using some kind of lazy evaluation for this rule in practice to avoid having to compute it for every element when unnecessary. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Can I try this out?&lt;/strong&gt;&lt;br&gt;
You may have noticed that all the code in this article looked a little strange. That's because it is all written the &lt;a href="https://github.com/jemmaissroff/koko"&gt;custom programming language&lt;/a&gt; Jemma has been building. The language supports all of the dependency tracking operations I talked about above and you can &lt;a href="https://mr4k.github.io/konsole/"&gt;play around with it yourself&lt;/a&gt;! If you need inspiration, every linked function in this blog post is a working example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where would stuff like this every come up?&lt;/strong&gt;
So I guess it's kind of cool that we can granularly track data dependencies, but more importantly why would we every want to? The answer is I'm not totally sure! But here are some quick ideas:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Priviledged Access to Data and Derived Computations. Give every piece of data a security level. In order to access the output of a computation involving the data your security clearance must be greater than or equal to the maximum security clearance of all the dependencies.&lt;/li&gt;
&lt;li&gt;JITs which compile at only statements which are used.&lt;/li&gt;
&lt;li&gt;Constructing minimal auto differentiation graphs.&lt;/li&gt;
&lt;li&gt;Determining trace purity at runtime.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks to Jemma Issroff and Robert Lord for providing feedback on this post.&lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="programming languages"></category><category term="programming languages"></category></entry><entry><title>A Note on Branching Within a Shader</title><link href="/shader-branch.html" rel="alternate"></link><published>2020-10-26T00:00:00-07:00</published><updated>2020-10-26T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-10-26:/shader-branch.html</id><summary type="html">&lt;p&gt;A gpu picks up the fork in the road&lt;/p&gt;</summary><content type="html">&lt;p&gt;An &lt;a href="https://www.google.com/search?q=three+weeks&amp;amp;oq=three+weeks"&gt;eternity&lt;/a&gt; ago, I published a &lt;a href="https://www.peterstefek.me/focused-render.html"&gt;blog post&lt;/a&gt; about a shader I wrote. In that post, I casually repeated a piece of gpu folklore I picked up as a wee opengl enthusiast almost a decade ago,   &lt;/p&gt;
&lt;p align="center"&gt;
"Using if statements inside a shader will cause performance degradation."  
&lt;/p&gt;

&lt;p&gt;People on the internet seemed a little skeptical about this statement, and I realized my advice might be outdated. So this post is a quick follow up about the cost of branching on more modern gpus.  &lt;/p&gt;
&lt;p&gt;Before we talk about branching, what is a gpu? A GPU or graphics processing unit, is a special piece of hardware initially developed to crunch numbers for graphics calculations. It accomplishes this goal quickly through a large amount of parallelization.   &lt;/p&gt;
&lt;p&gt;GPUs can run many threads at the same time in parallel. These threads are generally executed in groups called warps (CUDA), invocations (Vulkan) and waves (I will use the term warp, but they are all interchangeable). On recent Nvidia hardware (Ampere/ Volta / Pascal) these warps contain 32 threads. Pascal for example can theoretically run up to four independent instructions per warp over 56 warps of 32 threads which comes out to a mind blowing 7168 instructions per cycle. &lt;/p&gt;
&lt;p&gt;Each warp can only execute one instruction at a time. However that instruction can be executed for each of the threads in the warp. This means the GPU can execute 32 copies of the same instruction in parallel for each thread in the warp at once.   &lt;/p&gt;
&lt;p&gt;However, taking both sides of a branch will cause the threads inside a warp to "diverge". This means some threads will need to execute one side of the branch and some will need to execute the other. Unfortunately, both instructions can not be executed simultaneously for threads in the same warp. So these divergent instructions must be executed sequentially.   &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/shader-branch/pascal-divergence.png" width="65%" &gt; 
&lt;/p&gt;

&lt;p&gt;The above image is taken from the Volta whitepaper.  &lt;/p&gt;
&lt;p&gt;Consider the &lt;a href="https://www.shadertoy.com/view/WdyyWV"&gt;following fragment shader&lt;/a&gt;:&lt;br&gt;
&lt;code&gt;
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{  &lt;br&gt;
&lt;br&gt;
&lt;div style='margin-left: 5%;'&gt;
  // TUNE THIS AMOUNT TO YOUR GPU STRENGTH  
  int workAmount = 2000;  
  float incr = 1. / float(workAmount);  
  float outColor = 0.0;  

  // USE THIS VARIABLE TO TOGGLE BRANCHING  
  bool branch = true;  

  if (mod(fragCoord.x, 2.) &lt; 1. &amp;&amp; branch) {
    &lt;div style='margin-left: 5%;'&gt;
      for (int i = 0; i &lt; workAmount; i++) {
        &lt;div style='margin-left: 5%;'&gt;
          outColor += incr;
          &lt;/div&gt;
      }  
      fragColor = vec4(0.0,outColor,0.0,1.0);
      &lt;/div&gt;
  } else {
    &lt;div style='margin-left: 5%;'&gt;
      for (int i = 0; i &lt; workAmount; i++) {
        &lt;div style='margin-left: 5%;'&gt;
          outColor += incr;
          &lt;/div&gt;
      }  
      fragColor = vec4(outColor,0.0,0.0,1.0);
      &lt;/div&gt;
  }
  &lt;/div&gt;&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In fragment shaders like the one above, each warp is composed of a set of spatially close pixels. Each warp in this shader should diverge because each horizontally adjacent pixel takes a different side of the branch. Let's say the cost of each inner loop is n cycles. Since each side of the branch is executed in series, each warp must take at least 2n cycles, even though each thread uses only one side of the branch. These effects scale with the number of threads in the distinct divergent paths taken (up to 32x in Nvidia hardware). Here's another shader which should have roughly four branches per warp. &lt;a href="https://www.shadertoy.com/view/wsVyzG"&gt;This shader&lt;/a&gt; will take at least 4n cycles.  &lt;/p&gt;
&lt;p&gt;However, let's look a &lt;a href="https://www.shadertoy.com/view/tsVyzG"&gt;second shader&lt;/a&gt;:   &lt;/p&gt;
&lt;p&gt;&lt;code&gt;
void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
&lt;br&gt;
&lt;div style='margin-left: 5%;'&gt;
  // USE THIS VARIABLE TO TOGGLE BRANCHING  
  int workAmount = 2000;  
  float incr = 1. / float(workAmount);  
  float outColor = 0.0;  

  // USE THIS VARIABLE TO TOGGLE BRANCHING  
  bool branch = true;  

  if (fragCoord.x &lt; iResolution.x / 2.0 &amp;&amp; branch) {
    &lt;div style='margin-left: 5%;'&gt;
      for (int i = 0; i &lt; workAmount; i++) {
        &lt;div style='margin-left: 5%;'&gt;
          outColor += incr;
          &lt;/div&gt;
      }  
      fragColor = vec4(0.0,outColor,0.0,1.0);
    &lt;/div&gt;
  } else {
    &lt;div style='margin-left: 5%;'&gt;
        for (int i = 0; i &lt; workAmount; i++) {
          &lt;div style='margin-left: 5%;'&gt;
          outColor += incr;
          &lt;/div&gt;
      }  
      fragColor = vec4(outColor,0.0,0.0,1.0);
      &lt;/div&gt;
  }
  &lt;/div&gt;&lt;/p&gt;
&lt;p&gt;}
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This shader should run roughly twice as fast as the other shader even though roughly the same number of pixels take each branch. This is because most of the warps do not diverge (with the exception of a few around half way across the screen).   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nvidia Specifics&lt;/strong&gt;&lt;br&gt;
As far as I can tell, there are roughly two different ways of nvidia graphics cards handle divergence with in a warp.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thread Masking (Pre Volta)&lt;/strong&gt;&lt;br&gt;
On pre volta Nvidia card, divergence was handled by something called thread masking.   &lt;/p&gt;
&lt;p&gt;Basically when a conditional is hit, a thread mask is generated.  We can think of this mask as a 32 entry array. Each entry specifies whether the corresponding thread takes the first side of the branch or not. The first side is then executed for each of those threads. After the first side of the branch is then executed, the mask is reversed and the other side of the branch is executed.   &lt;/p&gt;
&lt;p&gt;This thread mask strategy exists in part because there is only one program counter per warp on pre volta gpus. So essential every thread in the warp must be at the same place in the program. The only way we know which threads to execute, is by using the mask.&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/shader-branch/pascal-divergence.png" width="65%" &gt; 
&lt;/p&gt;
&lt;p&gt;The above image is taken from the Volta whitepaper.&lt;/p&gt;
&lt;p&gt;It's worth noting that only the threads which need to execute the branch actually are assigned to computational cores. So if no threads execute one side of the branch, no work is done.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Independent Thread Scheduling (Volta and Beyond)&lt;/strong&gt;&lt;br&gt;
One big change in the Volta architecture and beyond is the introduction of "Independent Thread Scheduling".   &lt;/p&gt;
&lt;p&gt;In Independent thread scheduling, each thread has its own program counter. This allows each warp to track the execution of every thread at a fine grain level. However, we can still only execute only one instruction at a time. So the actual runtime of a branch does not change.  &lt;/p&gt;
&lt;p&gt;So if Independent Thread Scheduling does not speed up branching, what does it do? Independent Thread Scheduling enables both sides of a branch to execute concurrently but not in parallel.   &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/shader-branch/volta-divergence.png" width="65%" &gt; 
&lt;/p&gt;

&lt;p&gt;The above image is taken from the Volta whitepaper.&lt;/p&gt;
&lt;p&gt;The reason for this shift is because before Volta, branches were places where deceptive deadlocks could occur. &lt;br&gt;
&lt;code&gt;
leader_id = 0&lt;br&gt;
If (threadIdx.x == leader_id) {&lt;br&gt;
&lt;br&gt;
&lt;div style='margin-left: 5%;'&gt;
    // Do some inital work
  &lt;/div&gt;&lt;/p&gt;
&lt;p&gt;} else {&lt;br&gt;
&lt;br&gt;
&lt;div style='margin-left: 5%;'&gt;
    // Wait for leader to finish it's work  
    // then do my work
  &lt;/div&gt;&lt;/p&gt;
&lt;p&gt;}&lt;br&gt;
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;In the above compute shader pseudo code, we have 31 "follower" threads waiting for the "leader thread" to finish (using in-warp shared local memory) before executing their own instructions. &lt;/p&gt;
&lt;p&gt;On a Pascal GPU or below, if the else side of the branch is executed first, a deadlock will occur. The leader will never get a chance to start it's work because its followers will be waiting for it. &lt;/p&gt;
&lt;p&gt;Independent Thread Scheduling gets around these locking problems by interlacing the two diverging paths. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Article TLDR&lt;/strong&gt;&lt;br&gt;
Branch divergence in warp makes all parts of the branch execute in sequence which slows down the shader. Branching divergence between warps does not affect runtime.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further Reading&lt;/strong&gt;&lt;br&gt;
Branch execution on gpus is surprisingly deep, and there are many edge cases I didn't address and I also didn't touch gpu vendors other than Nvidia. Here are some good sources if you want to learn more:  &lt;/p&gt;
&lt;p&gt;&lt;a href="https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf"&gt;The Volta Whitepaper&lt;/a&gt; (Most of this post can be found between figures 20 and 22)&lt;br&gt;
&lt;a href="http://taylorlloyd.ca/gpu,/pascal,/cuda/2017/01/07/gpu-pipelines.html"&gt;Understanding the Pascal GPU Instruction Pipeline&lt;/a&gt;&lt;br&gt;
&lt;a href="https://aschrein.github.io/jekyll/update/2019/06/13/whatsup-with-my-branches-on-gpu.html#figure-8-divergent-threads-execution-time"&gt;What's up with My Branch on GPU&lt;/a&gt; (this post covers some diabolical edge cases, including some around texture sampling)  &lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;</content><category term="gpu, parallel computation"></category><category term="gpu"></category><category term="parallel computation"></category></entry><entry><title>Slightly Incremental Ray Tracing In One Weekend</title><link href="/incr-ray-tracer.html" rel="alternate"></link><published>2020-10-18T00:00:00-07:00</published><updated>2020-10-18T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-10-18:/incr-ray-tracer.html</id><summary type="html">&lt;p&gt;Reflecting on a cursed cross over&lt;/p&gt;</summary><content type="html">&lt;p&gt;Code for this post can be found &lt;a href="https://github.com/Mr4k/incremental-ray-tracer"&gt;here&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Incremental Computation&lt;/strong&gt;&lt;br&gt;
Incremental computation is a programming abstraction which gives users a way of writing calculations such that, when some of the inputs change, only a relevant subset of the calculation has to be recomputed. &lt;/p&gt;
&lt;p&gt;The above definition is kind of vague and honestly it's best to start with an example. Let's take a look at the following mathematical expression.  &lt;/p&gt;
&lt;div class="math"&gt;$$ (a+b)*c $$&lt;/div&gt;
&lt;p&gt;We can evaluate this expression in two steps. First by adding a and b together, and then by multiplying the result by c. We can even write this computation out as a dependency graph:&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/comp-dag.png" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;
&lt;p&gt;Here the variables a, b, c are referred to as leaves because they have no dependencies. Now what if after we do our initial computation, the value of c changes?&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/comp-dag-2.png" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;
&lt;p&gt;We can see from this graph that since (a+b) does not depend on c, we do not need to recompute it. Now imagine scaling this idea up to larger, more complex expressions. If you are familiar with spreadsheet software, you might have flashbacks to the huge interlinked computations created there. This brings us to a second, more intuitive definition of incremental computation: Microsoft Excel on steroids.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/excel-on-steroids.png" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;
&lt;p&gt;There are several different frameworks and projects for incremental computation. These include &lt;a href="https://github.com/salsa-rs/salsa"&gt;several&lt;/a&gt; &lt;a href="http://adapton.org/"&gt;rust&lt;/a&gt; &lt;a href="https://github.com/lord/anchors"&gt;libraries&lt;/a&gt;, &lt;a href="http://skiplang.com/"&gt;Facebook's Skip Lang&lt;/a&gt; and an OCaml library called &lt;a href="https://github.com/janestreet/incremental"&gt;Incremental&lt;/a&gt;. I chose to play around with Incremental for my experiments, because it seems to be the most battle tested option.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pros/Cons&lt;/strong&gt;&lt;br&gt;
So far it may seem like incremental computation frameworks are magical abstractions which allow programmers to write incredibly efficient programs with ease. So why don't we all use them? Well like most things in software, incremental computation frameworks come with a few trade offs. &lt;br&gt;
Pros:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An incremental computation framework provides a simple abstraction around optimizing computations which allow programmers to write more efficiently computable programs with low mental overhead.&lt;/li&gt;
&lt;li&gt;The abstraction provided by these frameworks generalizes well to many different types of problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The frameworks have non negligible overhead both in speed and memory. We need to make sure the computation is slow enough to justify incrementalizing. If not, the overhead of the framework could dwarf the time it would take to recompute the expression from scratch.&lt;/li&gt;
&lt;li&gt;Similar to the above point, the initial computation of the algorithm will be slower. You need to decide if you will be recomputing often enough to justify this slow down.&lt;/li&gt;
&lt;li&gt;There are always limitations to any particular abstraction. Therefore you will likely be able to come up with a custom algorithm for a specific problem that is much faster than the result you get using an incremental computation framework.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those interested in exploring these tradeoffs in detail or wanting to peek behind the curtain will enjoy &lt;a href="https://www.youtube.com/watch?v=G6a5G5i4gQU"&gt;this talk&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How do people use Incremental Computation&lt;/strong&gt;&lt;br&gt;
So where are people actually using incremental computation? As far as I know, there are a few different areas where these ideas are being applied:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Finance, especially to deal with large spreadsheet-like calculations. Most finance companies are a little vague about what they actually do, so I don't know too much about this use case.&lt;/li&gt;
&lt;li&gt;Compliers, the rust compiler explored these techniques when building their incremental compilation features.&lt;/li&gt;
&lt;li&gt;Databases, the company &lt;a href="https://materialize.io/"&gt;Materialize&lt;/a&gt; uses technology based on the &lt;a href="https://cs.stanford.edu/~matei/courses/2015/6.S897/readings/naiad.pdf"&gt;Timely Dataflow Model&lt;/a&gt; developed by Microsoft Research to create a better streaming database.&lt;/li&gt;
&lt;li&gt;User Interfaces, user interfaces are a perfect place for incremental computation because it's important to figure out which components you actually need to re-render when something on the page changes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How people shouldn't use Incremental Computation&lt;/strong&gt;&lt;br&gt;
Now we can get to the fun part. Over the last week, I tried to play around with Incremental (and picked up scraps of OCaml) to get a better idea of how to actually build incremental computations. &lt;/p&gt;
&lt;p&gt;Of course the first thing I did was to &lt;a href="https://github.com/Mr4k/smash-incremental-heap"&gt;break the library&lt;/a&gt;, but after that I decided I wanted to write a small but non trivial project which used it. Since I don't have legions of highly paid quants to create large spreadsheets, I decided that use case was off the table. I felt that building a toy compiler or database would be at least a week long project by itself without incrementalizing it, so I ruled those out as well. I'm also not a huge frontend person, so a ui framework didn't seem appeal to me that much. Instead I decided to try something different:&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/in-one-weekend.jpg" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;I decided to implement (3/4s of) Peter Shirley's &lt;a href="https://www.realtimerendering.com/raytracing/Ray%20Tracing%20in%20a%20Weekend.pdf"&gt;Ray Tracing in One Weekend tutorial&lt;/a&gt; in OCaml and then try to incrementalize a part of the ray tracing step. I will be honest, this experiment was not the most amazing thing in the world, but I think I learned a lot about what not to do with incremental computation. &lt;/p&gt;
&lt;p&gt;Is this a terrible idea? Absolutely! But we can learn a lot but understanding why exactly it's terrible.&lt;/p&gt;
&lt;p&gt;So how does the graph based incremental computation I talked about above even fit in with ray tracing? It turns out shooting light rays into space can be thought of as a graph.&lt;/p&gt;
&lt;p&gt;First of all let's look the process of tracing one ray of light from observer to light source.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/inital-graph.png" width=75%&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;In the above diagram, we can see a ray of light traced backwards from the viewers eye to a light source. In between, it bounces off of both a red and blue sphere.&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/ray-trace-graph.png" width=75%&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;The light blue circles are nodes in an incremental computation graph and the arrows are directed edges between them. Whenever a ray hits an object, a new incremental node is created. This node computes the location of the next bounce by reflecting the incoming ray, and depends on the location and direction of the last bounce. This means that if the direction of a previous ray in the chain changes, all subsequent ray bounces will be recomputed.&lt;/p&gt;
&lt;p&gt;We can also fit additional metadata about our scene into the graph. For example, each object that a light ray hits will have a material associated with it.&lt;/p&gt;
&lt;p&gt;In my model, these materials have color but also a "fuzziness" parameter that represents how reflective the material is. If the material is perfectly reflective, incoming light rays are reflected so that the angle of incedence is exactly equal to the angle of reflection. Otherwise there is a random jitter applied to the outgoing direction of the ray. The size of this jitter is controlled by the "fuzziness" parameter. &lt;/p&gt;
&lt;p&gt;So the material parameters affect the final image color, as well as the direction of the outgoing ray. When the fuzziness of a material changes, we must recast all subsequent rays bouncing off of any objects which use that material. We can represent this dependency in our graph as follows: &lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/render-graph-with-materials.png" width=75%&gt; &lt;/img&gt;
&lt;/p&gt;
&lt;p&gt;In the above graph, if the fuzziness of a material changes, we will recast all subsequent rays.&lt;/p&gt;
&lt;p&gt;Handling changing material parameters will be the focus of our render. The idea is that after an expensive render, an artist could tweak a few material parameters without having to redraw the entire screen.&lt;/p&gt;
&lt;p&gt;But what about moving objects around? For this experiment, I decided not to implement this (fairly important) feature because I could not find a way to make it fit as nicely into the abstraction provided by Incremental. If I really wanted to do this, I'd basically just store all the rays inside a spatial acceleration structure like a octree. Then whenever a sphere's position changed, I'd query the set of rays intersecting it before and after it moved. I'd then recompute each of the nodes associated with these rays.  &lt;/p&gt;
&lt;p&gt;So anyways does this material editing approach actually work? The answer is somewhat.&lt;/p&gt;
&lt;p&gt;Here's a gif of it in action (in real time)!&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/incr-ray-tracer/trace-reload.gif" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;In the above gif, each material's color and fuzziness parameters are being changed one sphere at a time. Instead of doing a full render each time something changes, Incremental figures out which rays need to be recomputed. The image above looks grainy because I'm casting only about 10 rays per pixel (for reference,  Shirley's code, which this is based off, does 100 rays per pixel). To see why I'm only taking 10 samples per pixel, let's look at some performance numbers: &lt;/p&gt;
&lt;table style="width:90%"&gt;
  &lt;tr&gt;
    &lt;th&gt;# Rays Cast (x129600)&lt;/th&gt;
    &lt;th&gt;Non incremental render time (s) &lt;/th&gt;
    &lt;th&gt;Inital incremental render time (s) &lt;/th&gt;
    &lt;th&gt;50th percentile edit time (s)&lt;/th&gt;
    &lt;th&gt;95th percentile edit time (s)&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;1x&lt;/td&gt;
    &lt;td&gt;0.864982&lt;/td&gt;
    &lt;td&gt;2.475083&lt;/td&gt;
    &lt;td&gt;0.010557&lt;/td&gt;
    &lt;td&gt;0.077140&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;2x&lt;/td&gt;
    &lt;td&gt;1.559165&lt;/td&gt;
    &lt;td&gt;5.213949&lt;/td&gt;
    &lt;td&gt;0.015602&lt;/td&gt;
    &lt;td&gt;0.157500&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;5x&lt;/td&gt;
    &lt;td&gt;4.088101&lt;/td&gt;
    &lt;td&gt;12.362720&lt;/td&gt;
    &lt;td&gt;0.032054&lt;/td&gt;
    &lt;td&gt;0.405897&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;10x&lt;/td&gt;
    &lt;td&gt;7.763904&lt;/td&gt;
    &lt;td&gt;24.869927&lt;/td&gt;
    &lt;td&gt;0.088754&lt;/td&gt;
    &lt;td&gt;0.901066&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;20x&lt;/td&gt;
    &lt;td&gt;14.815373&lt;/td&gt;
    &lt;td&gt;121.544599&lt;/td&gt;
    &lt;td&gt;0.840104&lt;/td&gt;
    &lt;td&gt;11.20906&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;30x&lt;/td&gt;
    &lt;td&gt;19.766822&lt;/td&gt;
    &lt;td&gt;311.603921&lt;/td&gt;
    &lt;td&gt;1.917536&lt;/td&gt;
    &lt;td&gt;24.662991&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;/p&gt;
The benchmarks above are all taken on my 2.9 GHz Dual-Core Intel Core i5 2015 Macbook Pro with 8GB of memory. They each used 100 spheres, each with its own unique material. Each sphere's material was changed once and I recorded the time it took to rerender after each sphere's material had changed. Each ray cast bounced a maximum of 10 times through the scene. The non incremental version is my implementation of Peter Shirley's code. Both versions of the code are single threaded.&lt;/p&gt;
&lt;p&gt;Okay let's talk though this data quickly. The first four rows of the table tell a consistent story. The initial render has about a 3x to 4x overhead and editing a sphere's material results is significantly faster than a full redraw. All the numbers seem to scale linearly with the number of rays cast as expected.&lt;/p&gt;
&lt;p&gt;But what about the rows after that? Runtime seems to explode in the incremental version. I was really surprised by this result. I don't have a definitive answer to this question but it did make me rethink the overhead that a library like Incremental brings to a program.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Overhead of Incremental&lt;/strong&gt;&lt;br&gt;
At first glance, accounting for the runtime overhead of Incremental seems like it would be pretty simple. Each node that is fired requires a little bookkeeping on the Incremental side. As far as I know this overhead is typically on the order of ~50-150ns per node on commodity hardware and should grow linearly. The operations we are wrapping are a lot slower than that, so this firing overhead should not be a problem.  &lt;/p&gt;
&lt;p&gt;While the bookkeeping overhead is minimal, there is a second kind of overhead introduced by using this library. This is the memory overhead. Incremental nodes are not super light weight by themselves. Each node weighs &lt;a href="https://github.com/janestreet/incremental/blob/9b1f4da26fb223da43dc874fc797d39c13f14752/doc/tutorial/part7-optimization.mdx"&gt;at least 216 bytes&lt;/a&gt; without counting the data it is pointing to. In our model, we have at least one node per bounce of light. In fact, there were 20,678,306 nodes in the row 5 computation. I didn't think about this memory overhead at first because I was concerned with runtime, not memory usage.  &lt;/p&gt;
&lt;p&gt;Of course, things are always more complex than they appear and I think it's possible that the runtime spike from above is caused by the memory overhead. &lt;strong&gt;As a disclaimer, I'm not an expert in profiling, so what say I could be very wrong.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As far as I understand, the memory that most programs have access to is not real memory, but an abstraction known as virtual memory. That virtual memory is divided into "pages" of about 4KB each (on my computer at least). These pages are typically stored in RAM. But when memory gets tight, the operating system uses a variety of tricks to create the illusion of having more RAM then it really does. These tricks include temporarily storing pages to disk, temporarily swapping entire programs onto disk, and compressing memory in RAM. The drawback of these tricks is a considerable overhead when accessing affected memory.   &lt;/p&gt;
&lt;p&gt;Let's assume that a page is always 4K bytes. In that case, about 20 nodes fit into one page. This means if we read all the program's memory &lt;em&gt;sequentially&lt;/em&gt; we have to read from a different page every 20 nodes, which could incur some kind of extra cost. This is generally not too bad especially. However in the worst case, we could read all the memory in a different order such that we need to read from a different page every time! This could become very expensive if we are low on RAM because we could swap each page in and out of memory up to 20 times (also known as &lt;a href="https://en.wikipedia.org/wiki/Thrashing_(computer_science)"&gt;trashing&lt;/a&gt;)  &lt;/p&gt;
&lt;p&gt;The graph structure of incremental computations means that the nodes we read will likely not be right next to each other in memory, especially in larger graphs. This means that the overhead from swapping memory in and out of RAM could get quite large. This overhead is usually reflected by the number of &lt;a href="https://developer.apple.com/library/archive/documentation/Performance/Conceptual/ManagingMemory/Articles/AboutMemory.html"&gt;page faults&lt;/a&gt; that occur. When I investigated, I saw an explosion in &lt;a href="https://developer.apple.com/library/archive/documentation/Performance/Conceptual/ManagingMemory/Articles/AboutMemory.html"&gt;soft page faults&lt;/a&gt; between rows 4 and 5 of the table. Scaling to even larger numbers of rays (100x the number in row 1), I eventually saw an explosion of hard page faults as well.   &lt;/p&gt;
&lt;p&gt;What about the garbage collector you may ask? In my experiments there was a solid GC overhead but its overall percentage seemed to remain constant. I think that the mark step of the gc was likely dominated by same trashing problem, because it had to walk through the graph structure to check what was reachable.  &lt;/p&gt;
&lt;p&gt;While I'm not 100% percent convinced that the memory overhead is reponsible for all of the slowdown I saw, it was interesting to think about.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Take Aways&lt;/strong&gt;&lt;br&gt;
So was incremental a good fit for ray tracing? It was not the worst idea, but was absolutely not a great idea. For one, ray tracing is better done in high parallel environments, and Incremental is single threaded. A second reason is that ray tracing is a really well studied problem. There are tons of ways to accelerate it, none of which we used. There are even far faster incremental approaches that use of a lot of problem specific domain knowledge.&lt;/p&gt;
&lt;p&gt;So why did I do this project? For me, it was a good way to play around with the limits of incremental computation. I think I learned a lot about structuring these graph computations and some of the specific pain points of the Incremental library. However I'm still pretty new to all of this so if you have any tips for me I'd love to hear from you!  &lt;/p&gt;
&lt;p&gt;Thanks to &lt;a href="https://lord.io/"&gt;Robert Lord&lt;/a&gt; for teaching me everything I know about incremental computation, Ilia Demianenko for helping me profile my code and &lt;a href="https://gs0510.github.io/"&gt;Gargi Sharma&lt;/a&gt; for teaching me OCaml.   &lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="ray tracing, self adjusting computation"></category><category term="ray tracing"></category><category term="self adjusting computation"></category></entry><entry><title>Fooling Around with Foveated Rendering</title><link href="/focused-render.html" rel="alternate"></link><published>2020-10-06T00:00:00-07:00</published><updated>2020-10-06T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-10-06:/focused-render.html</id><summary type="html">&lt;p&gt;Seeing what's right in front of me&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;meta charset="utf-8"/&gt;&lt;/p&gt;
&lt;p&gt;Shadertoy is a wonderful tool which lets users create and share a type of program called a fragment shader online. The true magic of shadertoy is its community of very talented graphics programmers who build incredible works of art despite having access to only a sliver of the traditional graphics pipeline.  &lt;/p&gt;
&lt;p&gt;Some of these shaders are very computationally intensive and even in a small window, they crawl along well below their intended 60 frames per second on my old laptop. Inspired by a technique in the VR community called Foveated Rendering, I decided to try to optimize these shaders by only rendering a fully detailed image within a small focal region. As you move away from the focal point the image quality decreases.   &lt;/p&gt;
&lt;p&gt;This rendering scheme is motivated by biology. It turns out your eye notices more detail in the center of your vision than in the periphery. Some VR graphics programmers realized they could take advantage of this phenomenon to increase the effective resolution of images by increasing image quality towards the center of your vision. An in depth discussion of foveated rendering can be found in the “previous work section” of this &lt;a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr"&gt;paper&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;I did not have the time, equipment or the background necessary to implement a full foveated rendering system but it was fun to fool around with the concept.  &lt;/p&gt;
&lt;p&gt;Before diving into the technical details let’s look at a simple shadertoy fragment shader.   &lt;/p&gt;
&lt;p&gt;&lt;code&gt;
void mainImage(out vec4 fragColor, in vec2 fragCoord)&lt;br&gt;
{&lt;/p&gt;
&lt;div style='margin-left: 5%;'&gt;
    // Normalized pixel coordinates (from 0 to 1)  
    vec2 uv = fragCoord/iResolution.xy;

    // Output the pixel coordinates as a color to screen
    // fragColor is a 4 vector of the form
    // (red, green, blue, transparency)
    fragColor = vec4(uv, 0.0, 1.0);
&lt;/div&gt;
&lt;p&gt;}&lt;br&gt;
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This program runs once for each pixel on the screen. Each time it runs, we receive the input variable &lt;code&gt;fragCoord&lt;/code&gt;. &lt;code&gt;fragCoord&lt;/code&gt; is a 2d vector which contains the x and y coordinates of the pixel being drawn. We normalize those coordinates by dividing by &lt;code&gt;iResolution&lt;/code&gt;, another 2d vector, which contains the width and height of the image. Finally we output a color to the screen, whose red and green channels are proportional to the x and y position of the pixel being drawn. The output of this shader looks like this:  &lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/simple-shader-out.png" width="50%"&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;Side note, why do these shader programs require their own language? Shaders are special because they run on the graphics card instead of the cpu. They are highly parallel. A helpful mental model might be imagining that each pixel is colored simultaneously. Therefore a lot of things that we take for granted in normal program languages such as liberally accessing memory and branching become much more difficult.  &lt;/p&gt;
&lt;p&gt;In shadertoy shaders the bottleneck is always in the pixel rendering step. So to speed them up we want to only render a subset of the all the pixels on the screen. It seems like selectively rendering pixels should be as simple as adding a branch to the per pixel shader code that looks like:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;
void mainImage(out vec4 fragColor, in vec2 fragCoord) &lt;br&gt;
{  &lt;/p&gt;
&lt;div style='margin-left: 5%;'&gt;
    if (fragCoord is in the subset of pixels to render) {  
      &lt;div style='margin-left: 5%;'&gt;
      ... do computationally intensive work 
      &lt;/div&gt; 
    } else {  
      &lt;div style='margin-left: 5%;'&gt;
      // return a black pixel  
      return vec4(0, 0, 0, 1); 
      &lt;/div&gt; 
    } 
&lt;/div&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately we cannot just use an if statement inside of the shader to save us from rendering all the pixels. Unlike normal programming languages, fragment shaders always execute both parts of each branch due to gpu limitations. So while our above code will still have to spend the sample amount of time evaluating compuationally intensive work.  &lt;/p&gt;
&lt;p&gt;Luckily, it turns out that graphics drivers can selectively mark which pixels not to shade by writing their location to a special buffer called the stencil buffer. We can use this stencil buffer to only shade the subset of pixels we are interested in.&lt;/p&gt;
&lt;p&gt;Once I could efficiently render a subset of the pixels, I needed to come up with a pre-generated sampling pattern. Most foveated rendering techniques seem to use a grid, but I decided to try a non uniform approach. Searching for some kind of optimal sampling pattern seemed like an interesting problem and if I was going to devote more time to this I'd explore options like &lt;a href="https://blog.demofox.org/2018/01/30/what-the-heck-is-blue-noise/"&gt;blue noise&lt;/a&gt;. However in the interest of time, I just decided fill in a small circle in the center and then use samples drawn from one low variance and one high variance gaussians centered at the middle of the screen to place the rest of the pixels. The final sampling pattern ended up looking like this:&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/final-sample-pattern.png" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;Next, I needed a way to fill in all the missing pixels in the final image. The approach I took was pretty simple. I started by mapping each pixel in the final screen to its nearest neighbor. Since my sampling pattern was predetermined, I could create this map beforehand and pass it into the shader as a texture. Here's what this mapping looks like:  &lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/nearest-mapping.png" width=50%&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;And here’s a gif of the mapping applied to a &lt;a href="https://www.shadertoy.com/view/3lsSzf"&gt;shadertoy&lt;/a&gt; created by the extremely talented &lt;a href="https://www.iquilezles.org/"&gt;Inigo Quilez&lt;/a&gt;:  &lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/1-neighbor.gif"&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;The above screen is 420x236 pixels and only 1/10th of those pixels are actually rendered. The focal point is directly in the center of the screen. Here's what the full resolution version looks like:&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/original.gif"&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;And here's what it looks like with only our sampling pixels:&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/sample-pixels.gif"&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;One little improvement I tried was to make 4 different maps. The kth map mapped each pixel in the final image to its kth nearest sampled neighbor. I weighted each of neighbors by the inverse of their distance to the pixel in question. I actually even tried using some gradient descent based optimization to fine tune the weights but ended up seeing little improvement. It also seemed that increasing the number of maps beyond 4 did not improve things much either. Here's what the example from above looks like with weighted interpolation between the four closest neighbors of each pixel (we are still rendering only 1/10th of the total pixels):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/4-neighbors.gif"&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;Finally, here's the shader with 1/5th of the total pixels rendered (as opposed to 1/10th shown above):&lt;/p&gt;
&lt;p align="center"&gt;
  &lt;img src="/images/focused-render/1of5pixels.gif"&gt; &lt;/img&gt;
&lt;/p&gt;

&lt;p&gt;Okay that's all cool but does this technique actually increase performance? I did not do a rigerous benchmark, but &lt;a href="https://www.shadertoy.com/view/3l23Rh"&gt;this shader&lt;/a&gt; goes from around 20-25 fps on my plugged in laptop to 60 fps when reduced to 1/5th of the total pixels. &lt;a href="https://www.shadertoy.com/view/Ms2SD1"&gt;Another shader&lt;/a&gt; went from around 15 fps to 60 fps.  &lt;/p&gt;
&lt;p&gt;One last side note is that this method can be used with any 3d scene and is not exclusive to shader toys. I just chose to use them because they are always bottlenecked by the pixel rendering step and they are really pretty!&lt;/p&gt;
&lt;p&gt;Further questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How do we achive better temporal stability? (the &lt;a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr"&gt;paper&lt;/a&gt; I mentioned earlier talks about this)&lt;/li&gt;
&lt;li&gt;Can we dynamically change the sampling pattern to give us better results? For example what if we sampled along edges or areas where large amounts of motion is occuring? Of course to do this we would need to compute our nearest neighbor mappings on the fly (there are actually &lt;a href="https://www.shadertoy.com/view/XtlGDS"&gt;some&lt;/a&gt; &lt;a href="https://www.shadertoy.com/view/ldl3W8"&gt;shadertoys&lt;/a&gt; which already demonstrate capability).&lt;/li&gt;
&lt;li&gt;How could this scheme improve if we had access to the internals of the 3d scene? For example, could we adjust our sampling pattern based on depth information?  &lt;/li&gt;
&lt;li&gt;How does this actually look in VR?  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;
&lt;p&gt;Discussion on &lt;a href="https://news.ycombinator.com/item?id=24695275"&gt;Hacker News&lt;/a&gt;&lt;/p&gt;</content><category term="glsl, shader"></category><category term="glsl"></category><category term="shader"></category></entry><entry><title>Using Bytecode Surgery to Create an Ouroboros</title><link href="/ouroboros.html" rel="alternate"></link><published>2020-09-28T00:00:00-07:00</published><updated>2020-09-28T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-09-28:/ouroboros.html</id><summary type="html">&lt;p&gt;Falling head over heels down the Python rabbit hole&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;meta charset="utf-8"/&gt;&lt;/p&gt;
&lt;p&gt;The code associated with this article can be found &lt;a href="https://github.com/Mr4k/ouroboros"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Consider the following function in Python which sums up the first n numbers:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So sum(1) returns 1, sum(2) returns 3 and sum(3) returns 6. What about sum(10000000)?&lt;br&gt;
Most likely if you call sum(10000000) you will get the following error:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Maximum recursion depth exceeded&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;A quick google shows that we have exceeded a limit that Python has on how deep recursion can go. Why don't we just increase it to 10000001? Let's try it! Now what happens?&lt;br&gt;
Most likely you will see a different error which looks like this:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Segmentation fault: 11&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;What happened here? It turns out that we ran out of memory. This is because every recursive call pushes a new stack frame, containing new variables and function information, onto Python's call stack.  &lt;/p&gt;
&lt;p&gt;But if you are incredibly observant or have taken a functional programming course, you might realize that the final result of this recursion is just the value returned by the base case. This value is then passed up a long chain back to the original call. It turns out in this case we don't need the chain. This observation is at the heart of so-called tail call optimization. The optimization eliminates unnecessary stack frames when calling functions from within functions. Most languages (even some js runtimes) implement tail call optimization, however Python's design committee has always been stubbornly against it.  &lt;/p&gt;
&lt;p&gt;Since I was looking for small projects to do during my first week at the &lt;a href="https://www.recurse.com/"&gt;Recurse Center&lt;/a&gt;, I decided to try to implement a basic version of tail call optimization in Python. Note this is not an original idea and I had already seen some clever hacks which used exceptions to break out of sub calls. I decided to try something different, although after presenting my implementation to the greater RC community I learned that another Recurser had given a &lt;a href="https://www.youtube.com/watch?v=Qk1I6ZxcceU&amp;amp;feature=share"&gt;fantastic talk&lt;/a&gt; which used the same idea back in 2015 (small world!)  &lt;/p&gt;
&lt;p&gt;Before I dive into the details let's look at the prototype in action:&lt;br&gt;
sum.py is a file which contains the same sum calculation from the beginning of this post:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;acc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;n&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;

&lt;span class="nv"&gt;print&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;sum&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1000000&lt;/span&gt;&lt;span class="ss"&gt;))&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If type &lt;code&gt;python sum.py&lt;/code&gt; we will get an error.&lt;br&gt;
Now let's try using my tool:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;python optimize-tail-calls.py sum.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This prints &lt;code&gt;500000500000&lt;/code&gt; as expected.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Identifying Tail Recursive Functions Calls&lt;/strong&gt; &lt;br&gt;
The first thing I did was to come up with a way to identify which function calls can be optimized.   &lt;/p&gt;
&lt;p&gt;Let's say we have a function &lt;code&gt;f&lt;/code&gt; which calls a function &lt;code&gt;g&lt;/code&gt; inside of it (&lt;code&gt;g&lt;/code&gt; could be a recursive call to &lt;code&gt;f&lt;/code&gt; but doesn't have to be). If &lt;code&gt;f&lt;/code&gt; just returns the value of &lt;code&gt;g&lt;/code&gt; without modifying it, then we do not need to remember &lt;code&gt;f&lt;/code&gt; existed in the first place (it does not have to stay on the call stack).  &lt;/p&gt;
&lt;p&gt;Let's see how we can translate that definition into something we can implement with Python.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A Byte Sized Definition&lt;/strong&gt;&lt;br&gt;
It turns out the Python VM does not evaluate python code directly but rather compiles it to an intermediate bytecode. Below is an example of the bytecode generated for our &lt;code&gt;sum&lt;/code&gt; function from above,  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/ouroboros/sum-bytecode.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;This code may look familiar to anyone who has seen assembly language before. Basically it is a set of instructions which must be executed in roughly sequential order. As you can see here, the CALL_FUNCTION instruction comes right before the return statement. In theory, this gives us a pretty good heuristic to tell if a function call is a tail call. That is to say, a function call is tail call optimizable if it comes right before a return statement (or in some cases jumps to a return statement). Note this definition might not capture every case but does a pretty good job overall. It also should not have false positives.  &lt;/p&gt;
&lt;p&gt;✂️ &lt;strong&gt;Bytecode Surgery&lt;/strong&gt; ✂️&lt;br&gt;
Now that we know which calls are tail call optimizable, all we have to do is to remove the unnecessary stack frames right? Unfortunately this is where we hit our first big limitation of Python's VM. We do not have full access to the stack pointer like we do in some assembly languages. Therefore, we really don't have a lot of control over the call stack. This really limits our ability to optimize. Some Python tail call optimization implementations get around this by using the exception system to break out of the current call. I chose not to do this due to the complexity of exceptions.   &lt;/p&gt;
&lt;p&gt;However if we focus our attention on tail recursive calls (where the tail call functions call the parent function) there is another way to hack around our problem. The simplified version is that we can replace the CALL_FUNCTION instruction with the JUMP_ABSOLUTE instruction, which we can use to take us back to the beginning of the current function.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/ouroboros/bytecode-surgery.png" width="99%" &gt; 
&lt;/p&gt;

&lt;p&gt;Of course, reality is a little more complex. We actually have to insert more than one instruction to do things like store the function arguments into the proper variables and pop the initial function reference off the stack. To make things more complicated, Python will sometimes have jump statements elsewhere in the call. If we simply replace one instruction in the middle of the function with several instructions, all the indexes get messed up and things will break in subtle ways. The way I dealt with this problem was to replace CALL_FUNCTION with a jump which goes to the end of the function where we can append the rest of our instructions without having to worry about messing up other indexes. Of course this breaks for enormous functions but that's outside of the scope of this prototype.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;More Complications&lt;/strong&gt;&lt;br&gt;
Unfortunately, there's one more major problem with our clean bytecode definition of a tail recursive function call. The problem is that there is no reliable way to tell from the bytecode which function is being called without actually running the bytecode. This means that in order to really know whether a tail call is tail recursive or not we need more information. I chose to use the AST (Abstract Syntax Tree) form of the code to figure this out.  &lt;/p&gt;
&lt;p&gt;To determine if a function call is tail recursive, I used another heuristic which consists of four criteria: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the call is the sole direct child of the return statement&lt;/li&gt;
&lt;li&gt;the call calls the parent function&lt;/li&gt;
&lt;li&gt;the call and entire return statement must be on one line&lt;/li&gt;
&lt;li&gt;nothing unrelated to the return statement can be on the same line&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This heuristic further narrows the number of calls we can mark as tail recursive. I think it can be improved but I chose it partially for simplicity of implementation. One other quirk about python's bytecode is that it gives us the line where each instruction is based but does not give us any more granular information. This is why I have the same line requirement. &lt;/p&gt;
&lt;p&gt;We can now mark all the lines with tail recursive calls. Then when going through the bytecode, if we see a function call next to a return statement we can check if it is a tail recursive call or not based on the line number.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;An Ouroboros&lt;/strong&gt;  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/ouroboros/ouroboros.jpg" width="40%" &gt; 
&lt;/p&gt;
&lt;p&gt;The Ouroboros is a snake which is eating its own tail. It symbolizes eternal cyclic renewal. In Python I consider this function to represent an Ouroboros,  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;ouroboros&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;:&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;ouroboros&lt;/span&gt;&lt;span class="ss"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now that we can optimize tail recursive function calls, this function will run forever (read as until we send SIGINT), eating it's own stack in an endless cycle.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further Places to Improve&lt;/strong&gt;&lt;br&gt;
I think with a little work the AST based heuristic could be complete (it would not miss any tail call optimizable functions).   &lt;/p&gt;
&lt;p&gt;When I started this project I was wondering about diving into the cpython VM code itself. I think it was neat that I didn't have to but I wonder if being able to make these tail call optimization decisions at runtime would be better. This would allow us to know which function was about to be called at runtime and we could decide whether or not to jump then. We would no longer need any AST based heuristics.  &lt;/p&gt;
&lt;p&gt;Of course if I had full VM access, I could also potentially allow jumping between functions without having to resort to exceptions which would really allow full tail call optimization. That might be an undertaking though.&lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;</content><category term="python, bytecode"></category><category term="python"></category><category term="bytecode"></category></entry><entry><title>Quick Notes on Differentiable Monte Carlo Simulations</title><link href="/differentiable-monte-carlo.html" rel="alternate"></link><published>2020-09-23T00:00:00-07:00</published><updated>2020-09-23T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-09-23:/differentiable-monte-carlo.html</id><summary type="html">&lt;p&gt;Reversing Expectations&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;br&gt;
If you haven't read my &lt;a href="https://www.peterstefek.me/differentiable-dithering.html"&gt;last post&lt;/a&gt; and the next paragraph sounds like gibberish, don't worry! None of it is required.  &lt;/p&gt;
&lt;p&gt;In my &lt;a href="https://www.peterstefek.me/differentiable-dithering.html"&gt;last post&lt;/a&gt;, I used variance as a proxy for image quality in the loss function. The nice thing about using variance, is that the sum of independent pixel variances is simple to compute (it's just the sum of the individual variances). However, I mentioned one could try using the expected value of a real image quality metric like &lt;a href="https://en.wikipedia.org/wiki/Structural_similarity"&gt;SSIM&lt;/a&gt; instead. Unfortunately computing the expectation of a function like SSIM (or something crazier like &lt;a href="https://ai.googleblog.com/2017/12/introducing-nima-neural-image-assessment.html"&gt;NIMA&lt;/a&gt;) is not so trivial. One way to compute the expectation of these crazier metrics, would be to use a Monte Carlo techinque. But it was not obvious to me how to get useful gradients out of that procedure.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;br&gt;
Suppose we want to compute a complex expectation. This problem pops in up machine learning in a few places (some ELBO losses for example). Often these problems can be solved using Monte Carlo Sampling.  &lt;/p&gt;
&lt;p&gt;The basic idea behind using Monte Carlo Sampling to compute expectations is to take:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(E_{p}[f(x)]\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;and approximate it as follows:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(E_{p}[f(x)]\)&lt;/span&gt; &lt;span class="math"&gt;\(\approx\)&lt;/span&gt; &lt;span class="math"&gt;\(\frac{1}{N} \sum_{i=1}^N f(\overline{\mathbf{x}}_i); \overline{\mathbf{x}}_i\)&lt;/span&gt; ~ &lt;span class="math"&gt;\(p\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;where the &lt;span class="math"&gt;\(x_i\)&lt;/span&gt;'s are drawn from the distribution you are sampling over.&lt;/p&gt;
&lt;p&gt;If we want to including Monte Carlo estimations inside a differentiable system (such as a neural network) we need a way to differentiate through the simulation. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Easy Mode&lt;/strong&gt;  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-monte-carlo/angel-dice.png" width="30%" &gt; 
&lt;/p&gt;
&lt;p&gt;Let's start with something simple. If the shape of the probability distribution we are taking the monte carlo estimate over is not a parameter, then differentiating through a Monte Carlo simulation is simple. No adjustments at all have to be made. Mathematically this looks like the following:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_p[f(x, \theta)]\)&lt;/span&gt; &lt;span class="math"&gt;\(\approx\)&lt;/span&gt; &lt;span class="math"&gt;\(\frac{d}{d\theta} \frac{1}{N} \sum_{i=1}^N f(\overline{\mathbf{x}}_i, \theta); \overline{\mathbf{x}}_i\)&lt;/span&gt; ~ &lt;span class="math"&gt;\(p\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hard Mode&lt;/strong&gt; &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-monte-carlo/demon-dice.png" width="30%" &gt; 
&lt;/p&gt;
&lt;p&gt;However often some parameters will affect the shape of the sampling distribution. For example, in my previous post the probabilities of each palette color being chosen per pixel are variables.&lt;br&gt;
Mathemtically this looks like:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_{p(\theta)}[f(x, \theta)]\)&lt;/span&gt; &lt;span class="math"&gt;\(\approx\)&lt;/span&gt; &lt;span class="math"&gt;\(\frac{d}{d\theta} \frac{1}{N} \sum_{i=1}^N f(\overline{\mathbf{x}}_i, \theta); \overline{\mathbf{x}}_i\)&lt;/span&gt; ~ &lt;span class="math"&gt;\(p(\theta)\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;This is where things get a little trickier. I generally found two common ways of approaching this problem.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Score Function Gradient Estimator (aka REINFORCE)&lt;/strong&gt;&lt;br&gt;
The idea here is to format the gradient as a second Monte Carlo problem over the same distribution (assuming &lt;a href="https://en.wikipedia.org/wiki/Leibniz_integral_rule"&gt;certain conditions&lt;/a&gt; are met). We also make use of the log derivative trick.   &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_{p(\theta)}[f(x, \theta)]=\frac{d}{d\theta} \int_{\Omega} p(\overline{\mathbf{x}}_i; \theta)f(\overline{\mathbf{x}}_i, \theta)\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_{p(\theta)}[f(x, \theta)]= \int_{\Omega} \frac{d}{d\theta}p(\overline{\mathbf{x}}_i; \theta)f(\overline{\mathbf{x}}_i, \theta)\)&lt;/span&gt; + &lt;span class="math"&gt;\(\int_{\Omega} p(\overline{\mathbf{x}}_i; \theta)\frac{d}{d\theta}f(\overline{\mathbf{x}}_i, \theta)\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_{p(\theta)}[f(x, \theta)]= \int_{\Omega} \frac{\frac{d}{d\theta}p(\overline{\mathbf{x}}_i; \theta)}{p(\overline{\mathbf{x}}_i; \theta)}f(\overline{\mathbf{x}}_i, \theta)p(\overline{\mathbf{x}}_i; \theta)\)&lt;/span&gt; + &lt;span class="math"&gt;\(\int_{\Omega} p(\overline{\mathbf{x}}_i; \theta)\frac{d}{d\theta}f(\overline{\mathbf{x}}_i, \theta)\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_{p(\theta)}[f(x, \theta)]= \int_{\Omega} \frac{d}{d\theta}\log(p(\overline{\mathbf{x}}_i; \theta))\)&lt;/span&gt;&lt;span class="math"&gt;\(f(\overline{\mathbf{x}}_i, \theta)p(\overline{\mathbf{x}}_i; \theta)\)&lt;/span&gt; + &lt;span class="math"&gt;\(\int_{\Omega} p(\overline{\mathbf{x}}_i; \theta)\frac{d}{d\theta}f(\overline{\mathbf{x}}_i, \theta)\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\frac{d}{d\theta}E_{p(\theta)}[f(x, \theta)]= E_{p(\theta)}[\frac{d}{d\theta}\log(p(\overline{\mathbf{x}}_i; \theta))\)&lt;/span&gt;&lt;span class="math"&gt;\(f(\overline{\mathbf{x}}_i, \theta)]\)&lt;/span&gt; + &lt;span class="math"&gt;\(E_{p(\theta)}[\frac{d}{d\theta}f(\overline{\mathbf{x}}_i, \theta)]\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Pros&lt;/em&gt;&lt;br&gt;
- Incredibly simple. Fairly general.&lt;br&gt;
&lt;em&gt;Cons&lt;/em&gt;&lt;br&gt;
- Several people seem to agree that high variance is a problem with this method. &lt;a href="https://timvieira.github.io/blog/post/2019/04/20/the-likelihood-ratio-gradient/"&gt;Tim Vieria&lt;/a&gt; calsl the basic method "useless on top of noisy". It seems like controlling the variance is an active area of research.&lt;br&gt;
- You need to be able to represent the derivative of &lt;span class="math"&gt;\(p(\overline{\mathbf{x}}_i; \theta)\)&lt;/span&gt; analytically (which rules out categorical variables for example).
From what I've seen this approach does not easily fit into an auto differentiation framework  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Reparameterization Trick&lt;/strong&gt;&lt;br&gt;
As far as I can tell, the reparameterization trick was established by Kingma et al in their paper about Variational Auto Encoders.  &lt;/p&gt;
&lt;p&gt;The insight here is that some families of distributions can be defined in terms of a differentiable transformation applied to constant underlying distribution. What does that mean?  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-monte-carlo/reparam-vae.png" width="65%" &gt; 
&lt;/p&gt;

&lt;p&gt;Let's consider the family of normal distributions parameterized by mean &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and variance &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;. Let's say we wanted to differentiate through a function which includes samples drawn from the normal distribution parameterized by the variables &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt;. If we approached this directly, we'd have to resort to something like the likelihood trick.  &lt;/p&gt;
&lt;p&gt;Alternatively, if we draw samples from &lt;span class="math"&gt;\(Normal(0,1)\)&lt;/span&gt; then multiply the result by &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; and add &lt;span class="math"&gt;\(\mu\)&lt;/span&gt;, we can differentiate with respect to &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; and &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; directly through auto differentiation without having to deal with any randomness. This trick works because the normal distribution parameterized by &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; and &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; is equal to the scaled / translated unit normal distribution. Not all distributions have nice properties like this, but for the ones that do reparametrization tricks can be quite nice. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Pros&lt;/em&gt;&lt;br&gt;
- Easy to use with existing autodiff frameworks&lt;br&gt;
- At least empirically less variance&lt;br&gt;
&lt;em&gt;Cons&lt;/em&gt;&lt;br&gt;
- Not generalizable because you need a specific "trick" per distribution. Not many distributions have one.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Gumbel Softmax Trick&lt;/strong&gt;&lt;br&gt;
In my previous post, the random variables I was dealing with were categorical. After learning about the reparameterization trick for normal distributions, I was immediately curious if there was a trick for categorical variables. It turns out there is an approximate one called the &lt;a href="https://arxiv.org/pdf/1611.01144.pdf%20http://arxiv.org/abs/1611.01144.pdf"&gt;Gumbel Softmax Trick&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;To understand the Gumbel Softmax Trick we will first talk about the non-differentiable version called the Gumbel Max Trick.  &lt;/p&gt;
&lt;p&gt;The Gumbel Max trick says that sampling from a categorical distribution with n classes (with probabilities &lt;span class="math"&gt;\(p_{1}, ..., p_{n}\)&lt;/span&gt;) is equivalent to:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(argmax_{i \in \{1,..,n\}}\)&lt;/span&gt;  &lt;span class="math"&gt;\(x_i + log(p_i)\)&lt;/span&gt;    &lt;/p&gt;
&lt;p&gt;where the &lt;span class="math"&gt;\(x_i\)&lt;/span&gt;'s are drawn from a standard Gumbel Distribution. I'm not going to post the derivation of this trick but a walk through can be found &lt;a href="https://lips.cs.princeton.edu/the-gumbel-max-trick-for-discrete-distributions/"&gt;here&lt;/a&gt;.    &lt;/p&gt;
&lt;p&gt;The problem with this trick of course is that it's still not differentiable. However we can use a common deep learning trick and replace the discontinuous max with the approximate but continuous softmax function.  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(softmax([(x_0 + log(p_0))/t, ...\)&lt;/span&gt;&lt;span class="math"&gt;\(, (x_n + log(p_n))/t])\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(t\)&lt;/span&gt; is an tempreture parameter, which controls how smooth the softmax is. I coded up a &lt;a href="https://gist.github.com/Mr4k/fbb096baf20354b3fdcbd082a00e20d6"&gt;quick example of this trick&lt;/a&gt; in Jax here if you want to see it in action. &lt;/p&gt;
&lt;p&gt;This post is a high level overview but if you're curious, here is some &lt;a href="http://gregorygundersen.com/blog/2018/04/29/reparameterization/"&gt;good&lt;/a&gt; &lt;a href="https://timvieira.github.io/blog/post/2019/04/20/the-likelihood-ratio-gradient/"&gt;further&lt;/a&gt; &lt;a href="https://casmls.github.io/general/2017/02/01/GumbelSoftmax.html"&gt;reading&lt;/a&gt;. &lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="jax, gradient descent, statistics"></category><category term="jax"></category><category term="gradient descent"></category><category term="statistics"></category></entry><entry><title>Differentiable Dithering</title><link href="/differentiable-dithering.html" rel="alternate"></link><published>2020-09-09T00:00:00-07:00</published><updated>2020-09-09T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-09-09:/differentiable-dithering.html</id><summary type="html">&lt;p&gt;Coloring with calculus&lt;/p&gt;</summary><content type="html">&lt;p&gt;Colab source code can be found &lt;a href="https://gist.github.com/Mr4k/1f1b7ecaf30de073a50cbedd0da4dc82"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;&lt;br&gt;
Let's say we want to reduce the number of colors in an image. For example consider the picture of fruit below:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit.jpg" width="50%" &gt; 
&lt;/p&gt;
&lt;p&gt;If we run a count of how many colors are in the above image we get a whopping 157376 (for a 900 x 450 pixel image). Are all those colors really necessary?&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit-16-final.png" width="50%" &gt; 
&lt;/p&gt;
&lt;p&gt;The image above has 16 colors and the one below only has 8.&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit-8-final.png" width="50%" &gt; 
&lt;/p&gt;
&lt;p&gt;The problem of color palette reduction has been studied extensively and the typical approach works roughly as follows:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Build a reduced color palette of size N by dividing the color space up into N distinct regions where each region is represented by one color. This is usually accomplished by one of several &lt;a href="https://en.wikipedia.org/wiki/Color_quantization"&gt;popular approaches&lt;/a&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Dither"&gt;Dither&lt;/a&gt; the image. The process of dithering eliminates color banding and creates the illusion of more colors through a stippling like effect. If you are not familar with dithering we will explore it in more detail later. Given a fixed color palette there are specialized algorithms for dithering such as &lt;a href="https://research.cs.wisc.edu/graphics/Courses/559-s2004/docs/floyd-steinberg.pdf"&gt;Floyd Stienberg&lt;/a&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Instead of the usual approach, we are going to solve both of these problems at the same time using gradient descent.  &lt;/p&gt;
&lt;p&gt;First of all let's define a palette of N colors. For this article the colors will be 3 component vectors in rgb space. A quick warning to graphics nerds, for portability and simplicity we do not take &lt;a href="http://xahlee.info/img/what_is_gamma_correction.html"&gt;gamma correction&lt;/a&gt; into account. Our palette can be thought of as a Nx3 matrix where the rows represent colors in the palette and the columns represent the r,g,b weights of each of those colors. This entries of this matrix are variables in our optimization problem.&lt;/p&gt;
&lt;p&gt;Now how do we assign our palette colors to pixels in a differentiable way? I decided to do this using probability distributions. Each pixel is represented by a vector containing the probabilities of each palette color being chosen for that pixel. When actually generating an image we just sample each pixel's color from it's distribution.  &lt;/p&gt;
&lt;p&gt;The above formulation is pretty general. Importantly both the colors in the palette and the mapping of image pixels to palette colors are variables which we can optimize over simultaneously. Now all we need to do is attach any one of a number of loss functions.   &lt;/p&gt;
&lt;p&gt;The loss function I chose to use at first was just the squared difference between the original image and the expected value of the output image:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(loss(output, target)=\sum_{i\in pixels}(target_i\)&lt;/span&gt; &lt;span class="math"&gt;\(-\)&lt;/span&gt; &lt;span class="math"&gt;\(E[output_i])^2\)&lt;/span&gt; (equation 1)  &lt;/p&gt;
&lt;p&gt;So what's the idea here? Basically the expected output allows our image to pretend it has more colors than it really does.   &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/dither-grey.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;For example let's pretend our palette has only two colors, black and white. Also suppose our target image is a 50% gray square. Consider the following three possible representations of the image. One is an all black image, one is all white and the third has 50% black and 50% white pixels randomly distributed across the image. If we look from far away the third image will look better. This is because the black and white pixels will blur together and appear gray. This effect is called dithering.   &lt;/p&gt;
&lt;p&gt;By the above reasoning we want to make sure that the dithered pixel assignment (each pixel has a 50% chance of being black or white) should appear more desirable than the other two candidates to our loss function. Taking the squared error between the target image and the expected color of each pixel does exactly this.   &lt;/p&gt;
&lt;p&gt;You might be asking, why not take the expected value of the whole squared error? This would look like:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(loss(output, target) = E[\sum_{i\in pixels}(target_i\)&lt;/span&gt; &lt;span class="math"&gt;\(-\)&lt;/span&gt; &lt;span class="math"&gt;\(output_i)^2]\)&lt;/span&gt; (equation 2)   &lt;/p&gt;
&lt;p&gt;This actually does not work. To see why, let's look at the same setup as above and consider the expectation of an individual pixel (for math sticklers we can do this because expectation is linear). The loss function for a pixel denoted by the random variable &lt;span class="math"&gt;\(X\)&lt;/span&gt; that always chooses black is: &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(E[(0.5 - X)^2] = (0.5 - 0)^2 = 0.25\)&lt;/span&gt;   &lt;/p&gt;
&lt;p&gt;And the loss function for a pixel denoted by the random &lt;span class="math"&gt;\(X\)&lt;/span&gt; which is 50% black and 50% white is:&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(E[(0.5-X)^2] = (0.5-0)^2 * 0.5\)&lt;/span&gt; &lt;span class="math"&gt;\(+\)&lt;/span&gt; &lt;span class="math"&gt;\((0.5-1)^2 * 0.5 = 0.25\)&lt;/span&gt;  &lt;/p&gt;
&lt;p&gt;Unfortunately the values here are the same in both cases which rules out this loss function.  &lt;/p&gt;
&lt;p&gt;Let's try using the loss from equation 1 with a palette of two colors:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit-2-final.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;Hey! Not too bad! As we can see, different shades are captured by different densities of darker pixels. For a starker example let's try this image of a vertical black and white gradient:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/differentiable-dithering/bw-grad.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/differentiable-dithering/bw-grad-2.png" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;Now let's try 16 colors:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit-16-noisy.png" width="50%" &gt; 
&lt;/p&gt;
&lt;p&gt;The above image highlights one weakness of our current loss function. It's very noisy, even when it doesn't have to be.   &lt;/p&gt;
&lt;p&gt;To give an extreme example, consider an image with three colors red, blue and purple (a mix of 50% red and 50% blue). Let's say we have room for 3 colors in our palette. In the eyes of equation 1 both of the following solutions would have the same loss:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The red pixels are red, the blue pixels are blue and the purple pixels are purple. We are using all three colors in our palette to the best of our ability and the image is reproduced perfectly.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Each red pixel is red, each blue pixel is blue, each purple pixel has a &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; chance of being red and a &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; chance of being blue. Notice here we only use two out of three possible colors and the final image is clearly lower quality.   &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To control for this weakness, I added an additional term to the loss function which penalizes the sum of the pixel variances with a coeffcient given below by &lt;span class="math"&gt;\(c\)&lt;/span&gt;. The new loss function looks like this:  &lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(loss(output, target)=\sum_{i\in pixels}(target_i\)&lt;/span&gt; &lt;span class="math"&gt;\(-\)&lt;/span&gt; &lt;span class="math"&gt;\(E[output_i])^2 + cVar(output_i)\)&lt;/span&gt; (equation 3) &lt;/p&gt;
&lt;p&gt;Right now I just hand tune the coefficient of the variance penalty. A good rule of thumb seems to be larger palettes should weigh variance more heavily. Applying this penalty (variance coefficient = 0.25) gives us the 16 color image from the top of this post:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit-16-final.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;The tradeoff is that too little variance removes too much noise which, due to the absence of dithering, makes the final image appear to contain fewer colors and also creates &lt;a href="https://en.wikipedia.org/wiki/Colour_banding"&gt;banding effects&lt;/a&gt;. The image below has 16 colors and variance coefficient = 1.0. It demonstrates both of these problems:  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/differentiable-dithering/fruit-16-saturated.png" width="50%" &gt; 
&lt;/p&gt;
&lt;p&gt;In fact when the variance coefficent = 1.0, a little algebra shows equation 3 is equal to our rejected equation 2.&lt;/p&gt;
&lt;p&gt;Note there are many valid choices of loss function here and I'm not claiming mine is perfect at all. For example &lt;a href="https://blog.demofox.org/2017/12/23/c-differentiable-programming-searching-for-an-optimal-dither-pattern/"&gt;this article&lt;/a&gt; on creating optimal dither patterns blurs both images and takes the difference between those. We could try to use this idea or search for something else to replace our simple squared error. It would also be interesting to try to use a real image quality metric like &lt;a href="https://www.cns.nyu.edu/~lcv/ssim/"&gt;SSIM&lt;/a&gt; to measure image quality instead of using variance as a proxy.   &lt;/p&gt;
&lt;p&gt;Another place for improvement is that our approach is sloooow (up to several minutes). It also does not scale well memory wise to large palettes (when I try using more than 200 colors for the 900x450 pixel fruit image my colab notebook runs out of ram). This is because in that case there are more than 200x950x450 variables to optimize over. We could potentially tackle these problems in two ways. To address speed we could try to break the image up into mini batches. To address memory usage we could try to use a neural network to output probabilities at each pixel location instead of storing them all explicitly.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why do I think this approach is interesting?&lt;/strong&gt;&lt;br&gt;
Although this approach is not state of the art by any means in either speed or quality I think it's interesting that we can optimize both the palette selection and dithering at the same time.  &lt;/p&gt;
&lt;p&gt;As far as I know dithering and palette selection aren't really part of state of the art lossy compression today. However it would be neat if these same concepts could be applied to something like the color space transform, discrete cosine transform and weight quantization steps of &lt;a href="http://pi.math.cornell.edu/~web6140/TopTenAlgorithms/JPEG.html"&gt;jpeg compression&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;A pipedream would be an entirely differentiable image compression pipeline where all the steps can be fine tuned together to optimize a particular image with respect to any differentiable loss function.&lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;
&lt;p&gt;Discussion on &lt;a href="https://news.ycombinator.com/item?id=24477913"&gt;Hacker News&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="colors, jax, gradient descent"></category><category term="colors"></category><category term="jax"></category><category term="gradient descent"></category></entry><entry><title>Art Class With Leibniz</title><link href="/art-class-with-leibniz.html" rel="alternate"></link><published>2020-09-01T00:00:00-07:00</published><updated>2020-09-01T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-09-01:/art-class-with-leibniz.html</id><summary type="html">&lt;p&gt;Doodling with derivatives&lt;/p&gt;</summary><content type="html">&lt;p align="center"&gt;
    &lt;img class='artpic' src="/images/art-class/mona-progress.gif" width="20%" &gt; 
&lt;/p&gt;

&lt;p&gt;Recently I decided to try out Jax, Google's new library for differentiable programming. Essentially Jax allows you to take arbitrary derivatives of python. It claims to be simpler and more flexible than competing frameworks such as pytorch or tensorflow. It uses a fancy just in time compiler and auto parallelization to make your code faster. Since the easiest way for me to learn is by working, I thought about problems I could tackle with Jax.  &lt;/p&gt;
&lt;p&gt;Inspired by impressionist painting I decided to try to answer the question, "how well can I represent an image with a fixed number of circles?" To give a more exact definition suppose we have n colored circles each having 7 parameters: x position, y position, radius, red, green, blue and alpha (transparency). Each circle also has a (non adjustable) depth which is used to determine which circle occludes another should they overlap. Here's a picture of 100 of these circles whose parameters have been randomly initialized rendered against a black background.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img class='artpic' src="/images/art-class/random-init-mattjj.png" width="25%" &gt; 
&lt;/p&gt;

&lt;p&gt;The goal of this project is to find values for these parameters which minimize the squared error between the image made of circles and a target image. Throughout most of this project that target image happened to be frequent jax contributor &lt;a href="https://github.com/mattjj"&gt;Mattjj&lt;/a&gt;'s avatar because I was seeing it in every github issue.   &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/art-class/goal.png" width="80%" &gt; 
&lt;/p&gt;
&lt;p&gt;So how do we tackle this complex optimization problem? That's right, we're just going to use gradient descent by differentiating through the rendering process.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Okay so what does that actually mean?&lt;/strong&gt;&lt;br&gt;
Let's say we have a function which takes in our circles and draws them onto an image:  &lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/a1d5dc553c4cafdd7f2835f995a61771.js"&gt;&lt;/script&gt;
&lt;p&gt;We can make a loss function which takes in circles and outputs the loss between the rendered image and our target image:  &lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/01dca39b7f950e565d7414f52e6d26d1.js"&gt;&lt;/script&gt;

&lt;p&gt;With the magic of Jax we can create a function which gives us the gradient of our loss function with respect to its parameters (the circles) by simply saying:  &lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/70f421c3052da727abd153776d20767c.js"&gt;&lt;/script&gt;

&lt;p&gt;This line of thought is an extremely simplified version of &lt;a href="https://nerf-w.github.io/"&gt;differential&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=tGJ4tEwhgo8"&gt;rendering&lt;/a&gt; &lt;a href="https://www.youtube.com/watch?v=cdwLJCb45Kk"&gt;techniques&lt;/a&gt; but instead of writing a &lt;a href="https://blog.evjang.com/2019/11/jaxpt.html"&gt;fully functioning 3d differential renderer from scratch&lt;/a&gt; we're just gonna approximate some guy's face with circles. &lt;/p&gt;
&lt;p&gt;Now we just need to fill in our render function from above with a way to get from circles to pixels. The rendering technique that I used was pretty simple. All I did was start with a blank canvas then I looped over each pixel and looped through all the circles in back to front order. If a circle intersected the pixel in question I would blend it with the current r,g,b values of that pixel which came from the circles behind it. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Jax the Sharp Bits&lt;/strong&gt;&lt;br&gt;
The jax documentation has a section called "Jax the Sharp Bits" which I ended up visiting very frequently during this project. Inspired by that, instead of just presenting the final method I'm gonna to dig through my memories (and git history) to tell the tale of how I fought with Jax to build this over the last week. If you don't want to see jax specific details, I'd skip to &lt;strong&gt;Math the Sharp Bits&lt;/strong&gt; or &lt;strong&gt;Results&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;First Attempt&lt;/strong&gt;&lt;br&gt;
As stated above I took a very simple approach for the render function you can take. I used python's for loops to iterate over the width and height of the canvas and at each pixel I checked if the pixel in question intersected each circle (in back to front order). If it did I modified the pixel's color according to linear alpha blending rules: (1 - alpha) *previous color + alpha*new color.   &lt;/p&gt;
&lt;p&gt;The code looked like this:&lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/c0bb02a713dab4a463fd239f52a081d7.js"&gt;&lt;/script&gt;
&lt;p&gt;Unfortunately as many people who have tried to use python for computationally intensive tasks can tell, this code was extremely slow (about 10s for one render call on my 2015 Macbook Pro).  &lt;/p&gt;
&lt;p&gt;Luckily, Jax claims to address these problems for repeatedly called routines through it's jit (a special kind of code optimization process). In theory one can just call jit(render) to get a jitted version of the render function. However translating the render code to fast jit-able jax code was not exactly that straight forward.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pitfall 1&lt;/strong&gt;&lt;br&gt;
The code above will actually throw an error when I try to run it through Jax's jit function. This is due to the conditional in the &lt;code&gt;get_color&lt;/code&gt; function. It turns out Jax's jit cannot handle python's if statements so they provide their own &lt;code&gt;jax.lax.cond&lt;/code&gt; function which you can use instead.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pitfall 2&lt;/strong&gt;&lt;br&gt;
After getting the function to jit I noticed it was actually slower than the original function. This was really disappointing, however I learned it is because jax unrolls python loops. Mattjj and hawkinsp both have detailed explanations of behavior &lt;a href="https://github.com/google/jax/issues/402"&gt;here&lt;/a&gt; and &lt;a href="https://github.com/google/jax/issues/1776"&gt;here&lt;/a&gt;. Basically Jax does not understand a python loop is a loop and treats each iteration as a distinct logical element producing a giant computation graph. Jax provides jitable functions such as &lt;code&gt;vmap&lt;/code&gt; and &lt;code&gt;scan&lt;/code&gt; which help prevent this problem.  &lt;/p&gt;
&lt;p&gt;After fixing these problems the code became pretty usable. Here's what the render function looked like at this point:&lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/e7f4f5aef6556996ff8fc851bcbef402.js"&gt;&lt;/script&gt;
&lt;p&gt;I'm not claiming this is the most efficient form of the code but it was now fast enough for me (especially when I discovered I could use a tpu on google colab). If we wanted to make it even faster we could probably implement an intersection acceleration structure like a grid or quad tree so we don't have to check every circle for every pixel. However that would probably also make the code a lot more complex and brittle.  &lt;/p&gt;
&lt;p&gt;Now I was finally able to generate a real image:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img class='artpic' src="/images/art-class/init-mattjj-attempt.png" width="40%" &gt; 
&lt;/p&gt;

&lt;p&gt;Mattjj approximated with 1000 circles (loss ~4800). I'd recommend stepping back, squinting or viewing these images from an angle to really appreciate some of the blending tricks that are going on.  &lt;/p&gt;
&lt;p&gt;Looking at the image, 1000 circles seemed like a few too many so I decided to try to push the technique by seeing what it could do with 100 circles.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Math the Sharp Bits&lt;/strong&gt;&lt;br&gt;
Before I started trying to generate images with fewer than 1000 circles I needed to fix the last few problems with the code that I had been putting off.  &lt;/p&gt;
&lt;p&gt;First of all, the circles were not moving or changing their size. Even though I was taking the gradient with respect to those parameters as well as the color and alpha values, the gradient of the loss function with respect to position and radius was always zero.  &lt;/p&gt;
&lt;p&gt;Technically you've already seen the source of this error in my description of the rendering algorithm. However it would have been very hard to catch this error because it was less of a code problem and more of a basic calculus dilemma. The simple way we render circles with a hard cutoff at the edge is not fully differentiable with respect to the position or size.   &lt;/p&gt;
&lt;p&gt;To see why, let's look at a circle's influence on three different pixel positions. For a pixel outside of the circle's radius, the derivative is zero because the circle has no effect on it's color. For a pixel on the inside the circle's effect on the color of the pixel is constant with respect to its size and position so the derivative is still zero. For a pixel at the edge of the circle the derivative is actually undefined. This is a classic example of a &lt;a href="https://en.wikipedia.org/wiki/Heaviside_step_function"&gt;heaviside step function&lt;/a&gt;. A picture of a radial cross section of the circle's influence on the pixels around below shows the discontinuity. &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/art-class/heaviside.png" width="40%" &gt; 
&lt;/p&gt;

&lt;p&gt;It turns out some very smart people have put a lot of effort into tackling this problem with &lt;a href="https://people.csail.mit.edu/tzumao/diffrt/diffrt.pdf"&gt;edge sampling&lt;/a&gt;, &lt;a href="https://baileymiller-personal-page.s3.us-east-2.amazonaws.com/papers/zhang20-paper.pdf"&gt;fluid mechanics&lt;/a&gt; and &lt;a href="https://arxiv.org/pdf/1901.05567.pd"&gt;approximation&lt;/a&gt; based approaches.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/art-class/sigmoid.png" width="40%" &gt; 
&lt;/p&gt;

&lt;p&gt;For our purposes it's easiest to take the approximation path and make our circle's influence fall off with a differentiable function like &lt;a href="https://en.wikipedia.org/wiki/Sigmoid_function"&gt;sigmoid&lt;/a&gt; (pictured above) instead of the hard step function. The side effect of this is that our circles get a little blurrier. We also have to introduce a new "softness" parameter that defines how fast our sigmoid function falls off.&lt;/p&gt;
&lt;p&gt;So for our purposes we can just replace hard conditional in the line:&lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/cab2968aea526b7d33eaa6fbe13b84dc.js"&gt;&lt;/script&gt;
&lt;p&gt;with:&lt;/p&gt;
&lt;script src="https://gist.github.com/Mr4k/fe4156ddf6a36a0604dbd43473be2edd.js"&gt;&lt;/script&gt;

&lt;p&gt;Now our renderer is fully differentiable with respect to all the circle parameters.  &lt;/p&gt;
&lt;p&gt;The last little loose end we have is that currently the red, green, blue and alpha parameters are technically unbounded as well. When you have a sigmoid shaped hammer everything looks like a differentiable nail so I decided to just wrap these parameters in a sigmoid, for example a would become sigmoid(a), which would bound their outputs to [0, 1].  &lt;/p&gt;
&lt;p&gt;Now I was able to render my first 100 circle image. The gif below shows the optimization process. Notice how all of the circle parameters are being adjusted.&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img class='artpic' src="/images/art-class/mattjj-first-100.gif" width="25%" &gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Minibatching&lt;/strong&gt;&lt;br&gt;
One final optimization I implemented was minibatching (also known as stochastic gradient descent). For our purposes mini batching means only rendering and comparing a random fixed size subset of the pixel at each gradient descent step. I was able to achieve quality results using about 10% of the total samples from before (which greatly sped up the program).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;br&gt;
Here are some results generated by this process. All of them can be found in the attached &lt;a href="https://gist.github.com/Mr4k/2155d55e379f00235086de7d3c45402b"&gt;colab notebook&lt;/a&gt; where you can see the code and the hyperparameters used to generate them. All final images are rendered with softness = 10.  &lt;/p&gt;
&lt;p&gt;Also note that we are not optimizing over human perception loss, merely approximating it with the sum of square differences which is not perfect by any means. It seems to me that squinting or viewing the image from other angles makes some of the images (especially the 100 circle ones) look dramatically better. My guess is that this is because our brain stops focusing on the circles allowing us to see the bigger picture. Of course I'm know nothing about the human visual system so take that with a huge grain of salt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mattjj&lt;/strong&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;p align="center"&gt;Mattjj 100 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/mattjj/mattjj-s-10-c-100-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/mattjj/mattjj-s-10-c-100-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p align="center"&gt;
    &lt;p align="center"&gt;Mattjj 1000 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/mattjj/mattjj-s-10-c-1000-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/mattjj/mattjj-s-10-c-1000-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Mona Lisa&lt;/strong&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;p align="center"&gt;Mona 100 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/mona/mona-s-10-c-100-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/mona/mona-s-10-c-100-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p align="center"&gt;
    &lt;p align="center"&gt;Mona 500 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/mona/mona-s-10-c-500-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/mona/mona-s-10-c-500-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Barack Obama&lt;/strong&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;p align="center"&gt;Obama 100 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/obama/obama-s-10-c-100-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/obama/obama-s-10-c-100-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p align="center"&gt;
    &lt;p align="center"&gt;Obama 300 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/obama/obama-s-10-c-300-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/obama/obama-s-10-c-300-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Walter White&lt;/strong&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;p align="center"&gt;Walt 200 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/walt/walt-s-10-c-200-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/walt/walt-s-10-c-200-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p align="center"&gt;
    &lt;p align="center"&gt;Walt 500 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/walt/walt-s-10-c-500-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/walt/walt-s-10-c-500-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Golden Gate Bridge&lt;/strong&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;p align="center"&gt;Golden Gate 200 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/goldy/goldy-s-10-c-200-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/goldy/goldy-s-10-c-200-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p align="center"&gt;
    &lt;p align="center"&gt;Golden Gate 400 Circles&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/results/goldy/goldy-s-10-c-400-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/results/goldy/goldy-s-10-c-400-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Mastercard Effect&lt;/strong&gt;&lt;br&gt;
Honestly I have not had time to do too much analysis of this algorithm (check future questions / ideas for a list of things I wish I had time to do). However I did want to show off one interesting edge case I came across. Inspired by the &lt;a href="https://commons.wikimedia.org/wiki/File:Mastercard-logo.svg"&gt;Mastercard logo&lt;/a&gt; this effect demonstrates the optimizer getting stuck in a local minimum.  &lt;/p&gt;
&lt;p&gt;We will try to approximate the following image with just two circles:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/mastercard/circle-overlap.png" width="25%" &gt; 
    &lt;/div&gt; 
&lt;/p&gt;
&lt;p&gt;Let's look at the output of our algorithm under two different random seeds:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;p align="center"&gt;Seed 1&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/mastercard/mastercard-s-10-c-2-f1-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/mastercard/mastercard-s-10-c-2-f1-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p align="center"&gt;
    &lt;p align="center"&gt;Seed 2&lt;/p&gt;
    &lt;div align="center"&gt;
        &lt;img class='artpic' src="/images/art-class/mastercard/mastercard-s-10-c-2-f2-final.png" width="25%" &gt; 
        &lt;img class='artpic' src="/images/art-class/mastercard/mastercard-s-10-c-2-f2-progress.gif" width="25%" &gt;
    &lt;/div&gt; 
&lt;/p&gt;

&lt;p&gt;So what went wrong in the bottom run? It appears that the optimizer colors one circle red and one circle green but the red one is in front of the green one. Unfortunately the algorithm cannot change the order the circles are drawn in so the best solution here would be to recolor the circles. However it appears gradient descent cannot plan far ahead enough to go back and change the colorings. This is because although changing the colorings would lower the loss in the long run it would increase it in the short term. Another way to say this is our optimizer got stuck in a local minimum.  &lt;/p&gt;
&lt;p&gt;If we had an commutative blend mode like &lt;a href="https://www.learnopengles.com/tag/additive-blending/#:~:text=Additive%20blending%20is%20the%20type,three%20different%20primary%20colors%20together"&gt;additive blending&lt;/a&gt; this would not be a problem. However I think this would limit the amount of colors that could be produced by many overlapping circles which would hurt the algorithm overall.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Future Questions / Ideas&lt;/strong&gt;&lt;br&gt;
How do the hyperparameters affect image quality?  &lt;/p&gt;
&lt;p&gt;How does the choice of parameter initalization of the circles affect image quality?  &lt;/p&gt;
&lt;p&gt;What other loss functions could be used besides L2 (squared error) and how would they affect human perception of images (maybe use the &lt;a href="https://arxiv.org/abs/1508.06576"&gt;neural style&lt;/a&gt; loss)?  &lt;/p&gt;
&lt;p&gt;Is this method more efficient than simpler hill climbing based approaches?  &lt;/p&gt;
&lt;p&gt;What if we let the background color be optimized?  &lt;/p&gt;
&lt;p&gt;What if we used a weighted error function so users could highlight important areas?&lt;/p&gt;
&lt;p&gt;What if we attached a neural network to this system and had it learn to place circles in one shot like &lt;a href="https://github.com/jcjohnson/fast-neural-style"&gt;fast neural style&lt;/a&gt;?&lt;/p&gt;
&lt;p&gt;What if we used different shapes? What if we let the algorithm choose the shape?&lt;/p&gt;
&lt;p&gt;What if we did it in 3d?  &lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;&lt;/p&gt;</content><category term="algorithms, jax, gradient descent"></category><category term="algorithms"></category><category term="jax"></category><category term="gradient descent"></category></entry><entry><title>Optimizing an Open Source Texture Synthesis Library</title><link href="/texture-optimization.html" rel="alternate"></link><published>2020-07-26T00:00:00-07:00</published><updated>2020-07-26T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2020-07-26:/texture-optimization.html</id><summary type="html">&lt;p&gt;Adventures in learning to profile.&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;br&gt;
Near the end of 2019 I stumbled across this &lt;a href="https://www.youtube.com/watch?v=fMbK7PYQux4&amp;amp;t=6m57s"&gt;talk&lt;/a&gt; by procedural generation researcher &lt;a href="https://www.anastasiaopara.com/"&gt;Anastasia Opara&lt;/a&gt;. In the talk she presents a novel algorithm for example based texture synthesis. The goal of example based texture synthesis is to take one or more example textures and synthesize a new visually similar output texture.    &lt;/p&gt;
&lt;p&gt;Here's an example from the project README:
&lt;br&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/texture-optimization/readme-example.jpeg" width="70%" &gt; 
&lt;/p&gt;
&lt;/p&gt;
&lt;p&gt;I was really curious about this algorithm and wanted to see if I could make it run faster as an exercise in profiling.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Embarking on a Journey&lt;/strong&gt;&lt;br&gt;
While I'm not going to go into great detail about how the algorithm works (see Anastasia's talk if you're curious!) it's helpful to understand the basic idea.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/texture-optimization/synthesis-diagram.png" width="80%" &gt; 
&lt;/p&gt;
&lt;p&gt;We start with an empty output image and seed it with a few random pixels from our example images.&lt;br&gt;
Then repeat the following procedure until the output image is filled: &lt;br&gt;&lt;br&gt; 
1. Choose an empty pixel in the output image. We will call this the center pixel.&lt;br&gt;
2. Find the k closest non empty pixels to the center in the output image. Note in the first few steps there might be fewer than k pixels in the entire output image. The locations of these k pixels relative to the center pixel define a neighborhood.&lt;br&gt;
3. Come up with a list of the most promising neighborhoods in the example image(s)&lt;br&gt;
4. Compare the most promising candidate neighborhoods in the example image(s) to the neighborhood around the center pixel and pick the most similar one.&lt;br&gt;
5. Fill the center pixel in the output image with the color of the center pixel in the best matching neighborhood.  &lt;/p&gt;
&lt;p&gt;One last important detail is that the algorithm works on filling multiple empty pixels in parallel to take full advantage of multi core cpus.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missteps and Micro optimizations&lt;/strong&gt;&lt;br&gt;
Now it was time to optimize. The first thing I did was to run the program on a few sample inputs with the xcode instruments profiler (partly because it was new to me). I even found a cool &lt;a href="https://www.reddit.com/r/rust/comments/b20eca/introducing_cargoinstruments_zerohassle_profiling/"&gt;library&lt;/a&gt; which made it easier to use instruments with rust. Using instruments I was able to see how much each instruction contributed to the overall runtime of the program.  &lt;/p&gt;
&lt;p&gt;Being able to see time per instruction was perfect for me because I was looking for micro optimizations. I'm using the term micro optimization here to mean a very small change which has a relatively large impact compared to its size. Even though they are not always a good idea, micro optimizations seemed like the best place to start because they would be less of an investment on my end. I also didn't know if the project maintainers would be excited about large code changes.  &lt;/p&gt;
&lt;p&gt;Looking at the profiler output I was drawn to this line which looked like an unnecessary array resize operation nested within our once per pixel loop.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/texture-optimization/first-profile.png" width="90%" &gt; 
&lt;/p&gt;

&lt;p&gt;An important note about interpreting the numbers above is that this algorithm runs in several passes and is divided among multiple threads. The image above only shows one pass which accounts for about 12.6% of the runtime of the entire program. However each pass contains the highlighted instruction and behaves similarly. To get a rough estimate of the true impact of this instruction these percentages should be multiplied by a factor of about 8 (100/12.6). So the highlighted instruction really accounts for about 9.5% of the total program runtime.&lt;/p&gt;
&lt;p&gt;After I eliminated the unnecessary array resize instruction I ran the program through the profiler again which seemed to confirm that it had gotten about 10% faster which I figured was pretty good for a first try. Of course, the profiler adds some overhead to the program, so to truly confirm that my optimization worked I needed to run it on a couple of examples without any profiling. When I did this I was shocked to see no improvement. &lt;/p&gt;
&lt;p&gt;So what was happening? It turns out the cargo-instruments command I was running compiled the program in &lt;a href="https://users.rust-lang.org/t/why-does-cargo-build-not-optimise-by-default/4150"&gt;debug mode by default&lt;/a&gt; which turned off significant optimizations. When I built the program in release mode the unnecessary array resize was automatically removed. I learned two very important lessons from this: First, of all when you benchmark you have to think carefully about what exactly you're benchmarking. Secondly, the compiler is smart and makes some micro optimizations for you.  &lt;/p&gt;
&lt;p&gt;A little embarrassed and somewhat defeated, I went back to the drawing board.  &lt;/p&gt;
&lt;p&gt;I grabbed a couple more profiles making sure this time to use release mode. After poking around some more I found that a significant amount of time was being spent loading pixels from the source images into intermediate buffers which were later used for neighborhood comparisons step of the algorithm.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/texture-optimization/second-profile.png" width="90%" &gt; 
&lt;/p&gt;

&lt;p&gt;Again using the same runtime adjustment from the last profiling section this function seemed to take about 37.6% of the total runtime. I suspected cache misses were a significant contributor here, but regardless of the actual problem source I knew that reading the neighborhood pixels for each candidate was expensive.   &lt;/p&gt;
&lt;p&gt;Of course the algorithm still needed to do the candidate neighborhood comparisons so I couldn't completely eliminate reading each candidate's neighborhood pixels. Luckily for me there was already a related optimization in the project,&lt;/p&gt;
&lt;p&gt;This related optimization targeted the actual comparison step when finding a best candidate neighborhood. In the comparison step each candidate neighborhood was assigned a score by summing up the differences (always positive) between it's pixels and the target's neighborhood pixels. It turned out that often you could stop summing up these differences early if you already knew this current candidate's score was going to be higher than the best candidate's score so far.   &lt;/p&gt;
&lt;p&gt;Once I understood this I just extended the idea to avoid reading the pixels needed for the unnecessary comparisons by removing the intermediate buffers and reading pixels only as they were needed which seemed to greatly reduce the average number of reads. I tested my optimization on a few different laptops with several output sizes using references images from the repository as inputs. It seemed like I had improved performance by around 15-25% depending on the output texture size, reference images and the computer I was using.  &lt;/p&gt;
&lt;p&gt;Quantifying performance impact was a lot harder than I thought it would be. There were so many different parameters to the program that could affect performance: size of the reference image(s), size of the output images, number of threads. Hardware differences were also a huge factor. If I were really being rigorous I would have tried to put together a large collection of images and output sizes to benchmark off of. Due to time and budget constraints I did not assemble a super rigorous benchmark but my appreciation for the problem of performance testing has grown tremendously.  &lt;/p&gt;
&lt;p&gt;Once I was confident that my micro optimization worked I made my &lt;a href="https://github.com/EmbarkStudios/texture-synthesis/pull/69"&gt;first pull request&lt;/a&gt;. It was accepted but to my surprise the performance gains that the reviewers saw were not nearly as good as the ones I did. When one of them benchmarked it on an AMD Threadripper (with 64 virtual cores) the speed up was so small it might have just been noise.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blocking And Locking&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;At this point I decided to use some Google Cloud free trial credits I had lying around to spin up some larger machines to test on. Using a 64 core machine I noticed that just like on the thread ripper I didn't see much of a performance improvement from my micro optimization. I tried multiple tests with different numbers of threads (from 0 up to 64) and saw that as the number of threads increased the performance gain from my optimization dropped.  &lt;/p&gt;
&lt;p&gt;So in my mind there were two explanations. First was that my optimization didn't save as much time when there were multiple threads. Second was that there was another source of latency which increased with the number of threads and that simply got so big it drowned out any noticeable effects of my optimization. It turned out this second explanation was correct.  &lt;/p&gt;
&lt;p&gt;The additional source of latency turned out to be thread contention. To get the k nearest neighbors for each candidate pixel the algorithm was using a data structure called an r*tree. An r*tree provides a way to efficiently store points for nearest neighbor lookups. Exactly how an r*tree works is not actually super important here. The problem was that there was only one r*tree shared across the entire image. To prevent race conditions the r*tree had been wrapped in a read-write lock. This type of lock allows parallel reads but writes must happen in series. Reads also cannot occur while a write is in progress. With large numbers of threads, writing became a large bottleneck. Looking at a graph of program runtime versus number of cores also helps illustrate this effect.  &lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/texture-optimization/before-graph.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;What I realized is that after a few pixels had been filled in the chance that one of the k nearest neighbors would be super far away from the candidate pixel was negligible. So I broke the images in to a grid of r*trees. The basic idea was that writes in two close cells could still block but writes in two far away cells could now be done in parallel. More details can be dound in &lt;a href="https://github.com/EmbarkStudios/texture-synthesis/pull/70"&gt;my second pull request&lt;/a&gt;. To see the improvement from this change we can look at this graph below of synthesis speeds before / after:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/texture-optimization/after-graph.png" width="50%" &gt; 
&lt;/p&gt;

&lt;p&gt;An important note here is that the improved version does not scale linearly either. In an ideal world maybe it would but there are several complicating factors that are at play here. First of all the program has some initialization costs as well as having to synthesize the first few pixels in series. Both of these steps cannot be parallelized. Secondly contention is complicated and can crop up in many places. I believe I did eliminate a large source of contention but I'm sure there is more that could be done. Finally this algorithm is not &lt;a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel"&gt;embarrassingly parallel&lt;/a&gt; and will ultimately have to have some amount of informtion shared between threads.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tricks and Trade Offs&lt;/strong&gt;&lt;br&gt;
Overall I was pretty excited by how this project turned out. However I think it's worth noting that there are often some tradeoffs which are made during optimizations. A common one that I saw in this project was trading speed for flexibility. Austin Jones, a previous contributor, had also made some significant speedups. &lt;a href="https://github.com/EmbarkStudios/texture-synthesis/pull/14"&gt;One of them&lt;/a&gt; was to replace some function evaluations with a lookup table. This resulted in a large speed up but it came at the cost of limiting the range of input values to 8 bits per pixel because larger ranges of numbers would cause the size of the lookup table to explode. My tree grid optimization was somewhat similar in the fact the structure was two dimensional. Although I think it could be extended to three dimensions, it would have to change at least a little if Embark wanted the library to generate voxel models or something. So the lesson here is to wait until your functionality is set in stone before you try to heavily optimize it.  &lt;br&gt;&lt;br&gt;
&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;br&gt;
While I said many things above about optimization and profiling I am no expert and always looking to learn more so if you think something is incorrect or have any suggestions feel free to get in touch!&lt;br&gt;
Also a big thanks to the people at &lt;a href="https://www.embark-studios.com/"&gt;Embark Studios&lt;/a&gt; who were nice enough to take the time to review my code / ideas!    &lt;/p&gt;
&lt;p&gt;Have questions / comments / corrections?&lt;br&gt;
Get in touch: &lt;a href="mailto:pstefek.dev@gmail.com"&gt;pstefek.dev@gmail.com&lt;/a&gt;   &lt;/p&gt;</content><category term="algorithms"></category><category term="probability"></category><category term="algorithms"></category><category term="image processing"></category><category term="optimization"></category></entry><entry><title>A Note on Ray Marching with Heightfields</title><link href="/ray-marching-heightfields.html" rel="alternate"></link><published>2019-10-18T00:00:00-07:00</published><updated>2019-10-18T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2019-10-18:/ray-marching-heightfields.html</id><summary type="html">&lt;p&gt;Short stepping to avoid collisions&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;span class="math"&gt;\(\newcommand{\norm}[1]{\lvert \lvert #1 \rvert \rvert}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ray marching is a technique for testing ray intersections with a scene.
If you are new to ray marching, I highly recommend reading one of these &lt;a href="https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm"&gt;great&lt;/a&gt; &lt;a href="http://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/"&gt;introductions&lt;/a&gt;
to the technique.
The central idea in raymarching is that the scene is represented by a distance field function &lt;span class="math"&gt;\(D(pos)\)&lt;/span&gt;
which gives the distance to the closest surface at each point. This distance field function for a scene is usually built by combining the distance fields of many primitives such as spheres, cubes and planes. Usually the distance field of each primitive can be analytically defined. A simple example of one of these primitives is a sphere at the origin
with radius r whose distance field function is defined as follows in glsl:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;distSphere&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;vec3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;pos&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;float&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;mag&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pos&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;r&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On thing you might notice here is that if you are inside the sphere the distance field is negative. This is called a signed distance field. While we don't use the signed part in this article you can find more information about them &lt;a href="https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm"&gt;here&lt;/a&gt;. &lt;br&gt;&lt;br&gt;
People often tend to use heightfields as primitives in raymarching. A heightfield is
a function &lt;code&gt;h(vec2 pos)&lt;/code&gt; that takes a 2d coordinate and returns the height
at that point. They can be thought of as topographical maps. Heightfields are useful because they allow artists to easily define bumpy surfaces such as waves or terrain. 
Common analytic heightfields include simplex noise, and sin / cosine waves.
Typically people use a function like the one below for the heightfield's distance field function:  &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;distHeightfield&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;vec3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;pos&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;{&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;h&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;pos&lt;/span&gt;.&lt;span class="nv"&gt;xz&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;pos&lt;/span&gt;.&lt;span class="nv"&gt;y&lt;/span&gt;&lt;span class="c1"&gt;;&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
}&lt;span class="w"&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code&gt;h(vec2 pos)&lt;/code&gt; is the heightfield function. However this function is really not a distance field. To see why we can look at the image below.&lt;br&gt;
&lt;img alt="A ray can overshoot the closest surface when using heightfield distance" src="images/ray-marching-heightfields/heightfield-problem.png"&gt;&lt;br&gt;
Let's say we are at point P and we shoot a ray to the right (represented by the red ray in the picture). If we use our &lt;code&gt;distHeightfield&lt;/code&gt; function we will think that the closest surface is &lt;span class="math"&gt;\(a\)&lt;/span&gt; away. However in the direction our red ray is going, the closest point is really &lt;span class="math"&gt;\(b\)&lt;/span&gt; away which is smaller than &lt;span class="math"&gt;\(a\)&lt;/span&gt;. So if we took a step of size &lt;span class="math"&gt;\(a\)&lt;/span&gt; along the red ray we would overshoot the heightfield. &lt;br/&gt;&lt;br/&gt;
One way to solve this problem is to use a smaller step size. In fact it turns out we can just 
down scale our step size by a constant multiple. So instead of taking a step of size &lt;code&gt;D(pos)&lt;/code&gt; as 
usual we could take a step of size &lt;code&gt;D(pos)*shrinkFactor&lt;/code&gt;. One way to find the shrink factor is to just try plugging in small constants 
until we get good results. In practice, there is absolutely nothing wrong with this approach. But if we want we can apply a more principled approach to finding a shrink factor.  &lt;br/&gt;&lt;br/&gt;
&lt;strong&gt;Obtaining a shrink factor&lt;/strong&gt;:&lt;br&gt;
Let's start by just trying to obtain a safe distance which gives us a lower bound on how far we can go in any direction without hitting anything. A really simple
way to do that is by creating a surface that will always be between our point P and the heightfield and finding the closest distance to that surface.&lt;br&gt;
A cone (more of a v shape in 2d) whose bottom starts on the heightfield directly under P is a good choice. Here is a picture:&lt;br&gt;
&lt;img alt="A safety cone" src="images/ray-marching-heightfields/safety-cone.png"&gt;&lt;br&gt;
Now we need is to chose a slope &lt;code&gt;c&lt;/code&gt; for the sides of the cone such that the it's edges will always lie between the heighfield and our point. If our heighfield function
is continuous and its derivative is bounded everywhere it is defined then &lt;code&gt;c&lt;/code&gt; could be the lowest upper bound on the absolute value of the derivative.  &lt;br/&gt;&lt;br/&gt;
Finally we have to find the closest distance from P to the edges of the cone. This distance will be our conservative bound.  &lt;br/&gt;&lt;br/&gt;
Note while the math below is in 2d, the 3d case is basically identical:&lt;br&gt;
&lt;img alt="A picture to set up our derivation" src="images/ray-marching-heightfields/derivation-diagram.png"&gt;&lt;br&gt;
Let &lt;span class="math"&gt;\(O\)&lt;/span&gt; be the bottom of the cone and &lt;span class="math"&gt;\(N\)&lt;/span&gt; be the closest point on one of the edges of the cone to &lt;span class="math"&gt;\(P\)&lt;/span&gt;. For consistency we will choose the right edge although it doesn't matter.&lt;br&gt;
First define &lt;span class="math"&gt;\(\hat{C}\)&lt;/span&gt; as the normalized vector pointing from &lt;span class="math"&gt;\(O\)&lt;/span&gt; along the right edge of the cone.&lt;br&gt;
&lt;span class="math"&gt;\(\norm{\overrightarrow{ON}}\)&lt;/span&gt; is given by &lt;span class="math"&gt;\(\overrightarrow{OP}\cdot \hat{C}\)&lt;/span&gt;.&lt;br&gt;
Given that &lt;span class="math"&gt;\(\overrightarrow{OP} = (0, h(P))\)&lt;/span&gt; we can say, &lt;span class="math"&gt;\(\norm{\overrightarrow{ON}} = \frac{h(P)c}{\sqrt{1+c^2}}\)&lt;/span&gt;.&lt;br&gt;
Finally using the pythagorean theorem we can find &lt;span class="math"&gt;\(\norm{\overrightarrow{PN}} = \norm{\overrightarrow{OP} } - \norm{\overrightarrow{ON}}\)&lt;/span&gt; which is &lt;span class="math"&gt;\(\frac{1}{\sqrt{c^2+1}}h(p)\)&lt;/span&gt;. &lt;br&gt; &lt;span class="math"&gt;\(\norm{\overrightarrow{PN}}\)&lt;/span&gt; is our conservative lower bound. This also means we can use &lt;span class="math"&gt;\(\frac{1}{\sqrt{c^2+1}}\)&lt;/span&gt; as our shrink factor.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="graphics"></category><category term="raymarching"></category><category term="graphics"></category></entry><entry><title>Optimal Stopping Policies</title><link href="/optimal-stopping.html" rel="alternate"></link><published>2018-10-06T00:00:00-07:00</published><updated>2019-10-15T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2018-10-06:/optimal-stopping.html</id><summary type="html">&lt;p&gt;Theoretical Recruiting&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;The Recruiter Problem&lt;/strong&gt;&lt;br&gt;
Pretend for a minute that you are a recruiter who's looking for people to fill a position. Maybe you're reading this post because I have applied for a position at your company and you're vetting me. Anyways the point is I'm one candidate among many. Even if you interview me and like me how do you know there's not someone better out there to fill the position? &lt;br&gt;&lt;br&gt;
More formally, you are going to interview &lt;span class="math"&gt;\(N\)&lt;/span&gt; candidates for a job. The order in which they come is random, with all orderings equally likely. After each interview with a candidate you will come up with a quality score (a real number between 0 and 1) for them and then you have to choose whether to hire them on the spot or reject them and hope a better fit comes along. Your goal is to hire the best of the best (the candidate who has the highest score among all N candidates) but you have no idea what the applicant pool looks like (no information about the distribution from which these candidates are drawn). What is the probability that you succeed in your task given that you use the optimal hiring strategy? &lt;br&gt;&lt;br&gt;
This problem is know sometimes as the best choice problem or the secretary problem. We will call it the Recruiter Problem. It is a very famous and well studied problem because of its very surprising solution: &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt; $\lim_{N \to \infty}Pr(\mbox{best is selected out of N candidates}) \to \frac{1}{e}$ &lt;/div&gt;
&lt;p&gt;&lt;br&gt;
This is a really cool result for several reasons. First of all it's not even clear that there should be any kind of one fits all strategy. Secondly, &lt;span class="math"&gt;\(\frac{1}{e} = 0.367879...\)&lt;/span&gt; which seems absurdly high. If have a million candidates, you have around a one third chance of choosing &lt;strong&gt;the&lt;/strong&gt; very best one. Here is a graph showing the probability of success using this strategy for different numbers of candidates,&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/optimal-stopping/cutoff.png" width="100%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br&gt; The strategy is also fairly simple and seemingly bizarre.&lt;br&gt;&lt;br&gt;
&lt;strong&gt;Strategy&lt;/strong&gt;&lt;br&gt; For every N there is an &lt;span class="math"&gt;\(r_N^*\)&lt;/span&gt; such that the following strategy is optimal. Reject the first &lt;span class="math"&gt;\(r_N^* - 1\)&lt;/span&gt; percent of the candidates then choose the next candidate who is better all of then them. &lt;br&gt;&lt;br&gt;
This type of strategy is called a cutoff rule. The final surprising fact is that &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt; $$\lim_{N \to \infty} r_N^* \to \frac{1}{e}$$ &lt;/div&gt;
&lt;p&gt;This means that you see less than half of the many candidates while making your decision. &lt;br&gt;&lt;br&gt;
&lt;strong&gt;Analysis&lt;/strong&gt;&lt;br&gt;
Analyzing the cutoff rule approach to this problem is fairly straightforward. Consider the cutoff rule with a variable &lt;span class="math"&gt;\(r\)&lt;/span&gt; which defines the cutoff point. The probability of finding the max can be though as follows, &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt; $$P(\mbox{success}) = \sum_{i=1}^N P(\mbox{applicant i is selected} \cap \mbox{applicant i is the best})$$ &lt;/div&gt;
&lt;div style="text-align:center;"&gt; $$P(\mbox{success}) = \sum_{i=1}^N P(\mbox{applicant i is selected} \vert \mbox{applicant i is the best}) \times P(\mbox{applicant i is the best})$$ &lt;/div&gt;
&lt;p&gt;The probability of any applicant being the best if &lt;span class="math"&gt;\(\frac{1}{n}\)&lt;/span&gt; because our candidates are equally likely to appear in any order. So&lt;/p&gt;
&lt;div style="text-align:center;"&gt; $$P(\mbox{success}) = \sum_{i=1}^N(\mbox{applicant i is selected} \vert \mbox{applicant i is the best}) \times \frac{1}{n}$$ &lt;/div&gt;
&lt;p&gt;&lt;br&gt;
The probability of success is clearly zero if when the best candidate is in the first r candidates since we reject them all. So we can simplify the above expression as follows: &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt; $$P(\mbox{success}) = \sum_{i=r}^N(\mbox{applicant i is selected} \vert \mbox{applicant i is the best}) \times \frac{1}{n}$$ &lt;/div&gt;
&lt;p&gt;&lt;br&gt;
Finally we have one last key insight. We can observe that for &lt;span class="math"&gt;\(i \geq r\)&lt;/span&gt;, &lt;span class="math"&gt;\(P(\mbox{applicant i is selected} \vert \mbox{applicant i is the best})\)&lt;/span&gt; is the same as saying that the best of the first &lt;span class="math"&gt;\(i - 1\)&lt;/span&gt; candidates is in first r - 1 candidates. &lt;/p&gt;
&lt;div style="text-align:center;"&gt; $$P(\mbox{success}) = \sum_{i=r}^N \frac{r-1}{i-1} \times \frac{1}{n} = \frac{r-1}{n}\sum_{i=r}^N \frac{1}{i-1}$$ &lt;/div&gt;
&lt;p&gt;&lt;br&gt;
We can observe as &lt;span class="math"&gt;\(n \to \infty\)&lt;/span&gt; that our probability becomes:&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(x)=x\int_x^1 \frac{1}{t}dt$$&lt;/div&gt;
&lt;p&gt;&lt;br&gt;
Maxmimizing this function in terms of x gives us &lt;span class="math"&gt;\(x^*=\frac{1}{e}\)&lt;/span&gt; and &lt;span class="math"&gt;\(P(x) = \frac{1}{e}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;
&lt;strong&gt;A Savvier Recruiter&lt;/strong&gt;&lt;br&gt;
It turns out that in the case where we know nothing about the distribution, the cutoff rule is optimal. But what if we do know something? This time let's pretend we know our distribution is uniform on &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;. We will call this problem the Savvy Recruiter Problem. Now let's try to come up with an optimal strategy for the Savvy Recruiter Problem. After each interview we have to accept or reject the candidate we just interviewed (candidate i). To gain some insight we can take a look at the following statement, &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{best candidate was in past}) + P(\mbox{candidate i is best}) + P(\mbox{best candidate is in future}) = 1$$&lt;/div&gt;
&lt;p&gt;Now we don't have control over the past but we do have the choice between hiring i and rejecting i. Therefore we choose the option which has the highest probability of giving us the best candidate. Let's make a few observations about these probabilities. &lt;br&gt;&lt;br&gt;
If candidate i's score is less than any of the previous candidates we know that:&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{candidate i is best}) = 0$$&lt;/div&gt;
&lt;p&gt;In this case we would always choose to move on because no matter what our chance of finding the best candidate in the future is we know it is greater than 0. &lt;br&gt;&lt;br&gt;
Now what if candidate i is better than all the other candidates we've seen so far? Off the bat we know that, &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{best candidate was in past}) = 0$$&lt;/div&gt;
&lt;p&gt;This means that,&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{candidate i is best}) + P(\mbox{best candidate is in future}) = 1$$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{best candidate is in future}) = 1 - P(\mbox{candidate i is best})$$&lt;/div&gt;
&lt;p&gt;&lt;br&gt;
Let &lt;span class="math"&gt;\(q_i\)&lt;/span&gt; denote candidate i's quality score. What we want now is the probability that we will not find a better candidate in our last &lt;span class="math"&gt;\(N-i\)&lt;/span&gt; interviews. Since our candidate scores are drawn from a uniform distribution on &lt;span class="math"&gt;\([0,1]\)&lt;/span&gt;,&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ P(\mbox{candidate j's score } \leq q_i) = q_i, \forall j $$ &lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$ P(\mbox{last N-i candidates are all } \leq q_i) = \prod_{j = i+1}^{N}P(\mbox{candidate j's score } \leq q_i) = q_i^{N-i} $$ &lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$ P(\mbox{best candidate in future}) = 1 - P(\mbox{last N-i candidates are all } \leq q_i) = 1 - q_i^{N-i} $$ &lt;/div&gt;
&lt;p&gt;So when is it optimal to choose to accept candidate i? It is when,&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{candidate i is best}) \geq P(\mbox{best candidate is in future})$$&lt;/div&gt;
&lt;p&gt;Equivalently this when,&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$P(\mbox{best candidate is in future}) \leq \frac{1}{2}$$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$1 - q_i^{N-i} \leq \frac{1}{2}$$&lt;/div&gt;
&lt;p&gt;Using this information we can solve for the threshold &lt;span class="math"&gt;\(q^*_i\)&lt;/span&gt; such that if &lt;span class="math"&gt;\(q_i \geq q^*_i\)&lt;/span&gt; our best option is to choose candidate i.&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$1 - {q^*_i}^{N-i} = \frac{1}{2}$$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$${q^*_i}^{N-i} = \frac{1}{2}$$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$q^*_i = \frac{1}{2}^\frac{1}{N-i}$$&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So how much better is a savvy recruiter than a regular recruiter? Below is a graph comparing the probabilities that each type of recruiter will choose the best candidate. &lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/optimal-stopping/cutoff-vs-knowing.png" width="100%"/&gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;details&gt;
    &lt;summary&gt;(details)&lt;/summary&gt;
    The probability of success of the savvy recruiter strategy is a little more difficult to calculate then that of the basic recruiter strategy. However we will follow the same basic idea. First we break the probability into the sum of the probabilities of succeeding at each step (we can do this because the events are mutually exclusive),
    &lt;div style="text-align:center;"&gt; $$P(\mbox{success}) = \sum_{i=1}^N P(\mbox{we pick the max at step i})$$ &lt;/div&gt; 
    However this is where it gets a little tricky. Remember that we pick a candidate if they are both larger than the threshold for that step $q_i$ and they are the max we have seen so far. Furthermore the sequence optimal thresholds $(q_i)$ is decreasing. This means that there are situations where a candidate i can be larger than than the ith threshold $q_i$ but still be passed over because there was already a larger candidate that did not exceed a larger previous threshold. 
    &lt;p align="center"&gt;
        &lt;img src="/images/optimal-stopping/threshold-not-selected.png" width="40%" &gt; 
    &lt;/p&gt;&lt;br&gt;
    In the above image the current candidate (red) will not be selected even though it is larger than its threshold. To help us out with this problem we will define the true threshold $t_i$. The true threshold $t_i$ is the max of the threshold $q_i$ and the last $i - 1$ candidate values. If the candidate at step $i$ is above the true threshold then they we be picked. So at step i we can condition on the true threshold.
    &lt;div style="text-align:center;"&gt;$$P(\mbox{success at step i}) = P(\mbox{success at step i} | t_i = q_i)P(t_i=q_i) + P(\mbox{success at step i } | q_i &lt; t_i \leq 1)P(q_i&lt;t_i\leq 1)$$&lt;/div&gt;
    We can compute this larger term in two parts,
    &lt;br&gt;&lt;b&gt;Unchanged Threshold&lt;/b&gt;
    &lt;div style="text-align:center;"&gt;$$P(\mbox{success at step i} | t_i = q_i)P(t_i=q_i)$$&lt;/div&gt;
    We know that we are successful at step i if and only if candidate i is larger than $t_i$ (so we pick them) and candidate i is the max. We can write this as,
    &lt;div style="text-align:center;"&gt;$$P(\mbox{success at step i | t_i = q_i}) = \int_{q_i}^1 F_{X+1}(x)...F_{X+n}(x)f_{X_i}(x)$$&lt;/div&gt;
    Because all the candidates are drawn i.i.d from a uniform distribution we can further simplify,
    &lt;div style="text-align:center;"&gt;$$P(\mbox{success at step i | t_i = q_i}) = \int_{q_i}^1 x^{n-i}dx$$&lt;/div&gt;
    Next let's look at
    &lt;div style="text-align:center;"&gt;$$P(t_i = q_i)$$&lt;/div&gt;
    We know this happens only when no previous candidate was larger than $q_i$ so we can express this as,
    &lt;div style="text-align:center;"&gt;$$P(t_i = q_i) = q_i^{i-1}$$&lt;/div&gt;
    Combining these two terms we get
    &lt;div style="text-align:center;"&gt;$$P(\mbox{success at step i} | t_i = q_i)P(t_i = q_i) = q_i^{i-1}\int_{q_i}^1 x^{n-i}dx$$&lt;/div&gt;
    &lt;b&gt;Modified Threshold&lt;/b&gt;
    &lt;div&gt; $$P(\mbox{success at step i } | q_i &lt; t_i \leq 1)P(q_i&lt;t_i\leq 1) $$&lt;/div&gt;
    &lt;div&gt; $$P(\mbox{success at step i } | q_i &lt; t_i \leq 1)P(q_i&lt;t_i\leq 1) = \sum_{k=1}^{i}P(\mbox{success at step i } | q_{k}\leq t_i \leq q_{k-1})P(q_{k}\leq t_i \leq q_{k-1}) $$(where $q_0 := 1$ for notational convience)&lt;/div&gt;
    &lt;div&gt; $$P(\mbox{success at step i } | q_i &lt; t_i \leq 1)P(q_i&lt;t_i\leq 1) = \sum_{k=1}^{i}\int_{q_{k}}^{q_{k - 1}}P(\mbox{success at step i } |  q_{k}\leq t_i \leq q_{k-1})f_{t_i}(x)dx $$&lt;/div&gt;
    &lt;div&gt; $$P(\mbox{success at step i } | q_i &lt; t_i \leq 1)P(q_i&lt;t_i\leq 1) = \sum_{k=1}^{i}\int_{q_{k}}^{q_{k - 1}}P(\mbox{success at step i } |  q_{k}\leq t_i \leq q_{k-1})f_{t_i}(x)dx $$&lt;/div&gt;
    Now after combinining both the unchanged and modified thresholds in a few more brutal algebrabic simplications we end up with the following:
    $$P(\mbox{success at step i}) = \bigg(\frac{1}{n-i+1}\bigg)\bigg[t_i^{i-1}-t_i^n+\sum_{j=1}^{i - 1}j \bigg(\frac{x^{i-1}}{i-1}-\frac{x^n}{n-1}\bigg)\bigg\rvert_{t_{j+1}}^{t_j}\bigg]$$
    $$P(\mbox{success with n candidates}) = \sum_{i=1}^n\bigg(\frac{1}{n-i+1}\bigg)\bigg[t_i^{i-1}-t_i^n+\sum_{j=1}^{i - 1}j \bigg(\frac{x^{i-1}}{i-1}-\frac{x^n}{n-1}\bigg)\bigg\rvert_{t_{j+1}}^{t_j}\bigg]$$

&lt;/details&gt;
&lt;/p&gt;
&lt;p&gt;So the savvy recruiter strategy is clearly better for a uniform distribution. This shouldn't be suprising because the savvy recruiter has more information than the basic recruiter. But just to be thorough we want to know if our results would be different if our underlying distribution was not uniform. It turns out it doesn't matter. We can actually transform any distribution into a uniform distribution by looking at percentiles then apply both strategies for a uniform to it. This works in our specific case because we care about finding the best candidate and the transformation into percentiles preserves the order of the candidate values. It's important to note that this type of transformation does not work if we care about maxmimizing other statistics such as expected value.  &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So clearly we have a much better chance of picking the max if we know the underlying distribution from which our candidates are drawn. However in most situations the true distribution isn't usually known (some people would even say that the idea of a single true distribution is ridiculous but we will not address that here for simplicities sake). But what if we could use the information we see during our interviews to appoximate the true distribution? Then we could use the savvy recruiter strategy with the our best guess of the true distribution. Seems kind of cool right? Let's look at an example. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/optimal-stopping/apartments.jpg" width="100%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Let's say that you have decided to get a house. However you live in a competitive market so housing tends to go fast. You need a house with in the next month so not a lot of new houses will come onto the market (let's say that you would be able to see a maximum of &lt;span class="math"&gt;\(n\)&lt;/span&gt; houses). Once you've seen a house, you basically have to decide whether or not to buy it on the spot. By the time you've seen another the first house will probably already be gone. You also want to find the best house for yourself. We will assume we can model the distribution of house qualities around the area with a gaussian distribution but you do not know its parameters (the mean or the variance). So how do you find the best house for yourself?
&lt;br&gt;&lt;br&gt;
As we view houses we attempt to learn the true underlying distribution of house qualities. The simplest way to do this is to use a technique called Maximum Likelihood Estimation. Maximum Likelihood Estimation operates on the assumption that each draw from the distribution is independent. It finds the parameters of a distribution (in our case the mean and the variance) which maximize the likelihood of seeing our observed data points. &lt;br&gt;&lt;br&gt;
For a Gaussian distribution the likelihood function is given observed points &lt;span class="math"&gt;\(x_1,...x_n\)&lt;/span&gt; is defined as follows:&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ L(\mu, \sigma^2) = p(X_1=x_1,...X_n=x_n \vert \mu, \sigma^2) = p(X_1 = x_1 \vert \mu, \sigma^2)...p(X_n = x_n \vert \mu, \sigma^2) $$&lt;/div&gt;
&lt;p&gt;Notice that because each draw is independent the probability of seeing all of them is just the products of the probabilities of seeing each one individually! It turns out that the parameters (&lt;span class="math"&gt;\(\mu, \sigma^2\)&lt;/span&gt;) which maximize the likelihood of seeing n data points are given by, &lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$\mu =  \frac{1}{n}\sum_{i=1}^n x_i = \bar x  $$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$ \sigma^2 =  \frac{1}{n}\sum_{i=1}^n (x_i - \bar x)^2  $$&lt;/div&gt;
&lt;details&gt;
    &lt;summary&gt;(details)&lt;/summary&gt; Remember that we are looking for the parameters $\mu, \sigma^2$ which maximize our likelihood function. Now generally products are pretty gross to deal. One common trick when dealing with maximizing products is to maximize the sum of the logs instead. Because log is monotonically increasing function on its domain (and we know the maximum of likelihood function is greater than zero) finding the parameters which maximize the likelihood is equivalent to finding parameters which maximize the log likelihood. For a gaussian distribution our log likelihood function can be derived as follows: &lt;br&gt;
    &lt;div style="text-align:center;"&gt;$$ L(\mu, \sigma^2) = p(X_1=x_1,...X_n=x_n \vert \mu, \sigma) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x_i - \mu)^2}{2\sigma^2}} $$&lt;/div&gt;
    The taking the log of both sides gives us the log likelihood: &lt;br&gt;
    &lt;div style="text-align:center;"&gt;$$ \mbox{ln}(L(\mu, \sigma^2)) = \sum_{i=1}^n \mbox{ln}(\frac{1}{\sqrt{2\pi\sigma^2}}) - \frac{(x_i - \mu)^2}{2\sigma^2} $$&lt;/div&gt;
    &lt;div style="text-align:center;"&gt;$$ \mbox{ln}(L(\mu, \sigma^2)) = n\mbox{ln}(\frac{1}{\sqrt{2\pi\sigma^2}}) - \sum_{i=1}^n \frac{(x_i - \mu)^2}{2\sigma^2} $$&lt;/div&gt;
    &lt;div style="text-align:center;"&gt;$$ \mbox{ln}(L(\mu, \sigma^2)) = -\frac{n}{2}\mbox{ln}(\pi)-\frac{n}{2}\mbox{ln}(\sigma^2) - \sum_{i=1}^n \frac{(x_i - \mu)^2}{2\sigma^2} $$&lt;/div&gt;
    Now we can take partial derivatives with respect to both $\mu$ and $\sigma^2$ (the mean and the variance). &lt;br&gt;
    &lt;div style="text-align:center;"&gt;$$ \frac{\mbox{ln}(L(\mu, \sigma^2))}{\partial \mu} =  \sum_{i=1}^n \frac{x_i - \mu}{\sigma^2}  $$&lt;/div&gt;
    &lt;div style="text-align:center;"&gt;$$ \frac{\mbox{ln}(L(\mu, \sigma^2))}{\partial \sigma^2} =  -\frac{n}{\sigma^2} + \sum_{i=1}^n \frac{(x_i - \mu)^2}{\sigma^4}  $$&lt;/div&gt;
    Setting the partial derivatives to zero we get the following system of equations. &lt;br&gt;
    &lt;div style="text-align:center;"&gt;$$ \sum_{i=1}^n \frac{x_i - \mu}{\sigma^2} = 0 $$&lt;/div&gt;
    &lt;div style="text-align:center;"&gt;$$ -\frac{n}{\sigma^2} + \sum_{i=1}^n \frac{(x_i - \mu)^2}{\sigma^4} = 0 $$&lt;/div&gt;
    From the first equation we obtain: &lt;br&gt;
    &lt;div style="text-align:center;"&gt;$$ \mu =  \frac{1}{n}\sum_{i=1}^n x_i = \bar x  $$&lt;/div&gt;
    Plugging that into the second equation we get: &lt;br&gt;
    &lt;div style="text-align:center;"&gt;$$ \sigma^2 =  \frac{1}{n}\sum_{i=1}^n (x_i - \bar x)^2  $$&lt;/div&gt;
&lt;/details&gt;

&lt;p&gt;We can now use these MLE estimates to approach our stopping problem with the optimal strategy for a known distribution. For each candidate house i, we first come up with an estimate of our parameters using all of the houses we have seen so far. Then we use this estimated distribution to calculate the percentile of the candidate house. Finally we check to see if the current candidate is the max we have seen. If so the probability that our candidate house is the best is greater than &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; we choose it (we can do this the same way as in the thresholding strategy for a known distribution). Here are several graphs demonstrating results of this approach:&lt;/p&gt;
&lt;details style="display:inline;"&gt;
    &lt;summary&gt;(details)&lt;/summary&gt;
    We run simulations 10000 times (for each n) then average together to get the final probability of success for each n. Each time we run we pick our "true" parameters of underlying normal distribution from two different uniform random distributions. $\mu$ ~ $Unif(0, 1000)$, $\sigma$ ~ $Unif(0, 15)$. 
&lt;/details&gt;

&lt;p align="center"&gt;
    &lt;img src="/images/optimal-stopping/learning-250.png" width="100%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Zooming in we can see that the cutoff policy is on par with the learned policy until there are around 14 houses on the market.&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/optimal-stopping/learning-35.png" width="100%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Finally if we look at a much larger number of available houses we can see that the learning strategy gets much better over time.&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/optimal-stopping/learning-2000.png" width="100%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Limitations&lt;/strong&gt;&lt;br&gt;
So this is cool little fact but what kinds of problems can we apply it too besides that contrived housing example? Could we use it to made the best stock market trades or decide when to bid on ebay? Unfortunately the answer is no. One large underlying assumption in our model is that the candidate qualities are each drawn independently from an underlying distribution. Many types of time series like the stock market or the price of ebay bids are highly correlated. For example if one tech stock goes down its likely others will have gone down with it. Under these conditions our model would mostly likely work very poorly. &lt;br&gt; &lt;br&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="probability"></category><category term="probability"></category><category term="algorithms"></category></entry><entry><title>The PCP Theorem and the Hardness of Approximation</title><link href="/pcp-theorem.html" rel="alternate"></link><published>2018-04-29T02:50:00-07:00</published><updated>2019-08-14T09:30:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2018-04-29:/pcp-theorem.html</id><summary type="html">&lt;p&gt;An introduction to the applications of the PCP theorem&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Preamble&lt;/strong&gt;&lt;br&gt;
This post uses a lot of computational complexity terms and is fairly dense. I've included some defintions of frequently used terminology below. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Complexity classes: A complexity class is a set of problems that can all be solved with an upper bounded constraint on a resource based on input size. In this article our constrained resource will usually be algorithmic runtime. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;P and NP: P is the complexity class made up of problems that can be solved in polynomial time by a deterministic Turing machine. NP is the class of problems that can be solved in polynomial time by a non-deterministic Turing machine. A major problem in computer science is proving whether or not P=NP. In this post most of the work will be built on the assumption that P &lt;span class="math"&gt;\(\neq\)&lt;/span&gt; NP. If this assumption is false many of our theorems will be irrelevant. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reductions: A reduction is an algorithm which transforms one problem into another. In this post we will mostly focus on reductions that can be done in polynomial time. A problem is NP-hard if any problem in NP can be reduced to it in polynomial time. Showing that a problem is NP-hard by reducing another NP-hard (or NP Complete) problem to it is a common proof strategy. Notice that showing that a problem is NP-hard does not mean that it is in NP (it could be harder)&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NP-Complete: An NP-Complete problem is an NP-hard problem that is also in NP. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Strings and Languages: We can also talk about complexity classes (such as P and NP) in terms of languages which accept certain strings. A language is a collection of strings. For example one language is the language of all strings which contain an odd number of 0s. A more complex example of a language is the set of all strings which represent bipartite graphs (the way we represent graphs as strings is not usually important). Determining whether or not a string is in a given language is now the problem we have to solve. For example we can say that a language &lt;span class="math"&gt;\(L\)&lt;/span&gt; is in P if and only if for any string &lt;span class="math"&gt;\(x\)&lt;/span&gt; we can determine if &lt;span class="math"&gt;\(x \in L\)&lt;/span&gt; in polynomial time. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Probabilistic Checkable Proofs&lt;/strong&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Probabilistic checkable proofs are a type of complexity class. The basic idea is this, consider a theorem and a lazy student. The lazy student has to decide whether or not the proof is true but does not want to read all of it. In fact the student only wants to read q bits of the proof before going back to sleep. The student also has r quarters (for laundry) next to them on their desk which they can flip (one time per coin) to help make random decisions. Given these r quarters and q bits the student must decide quickly whether or not the proof is true with a high probability. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/pcp-theorem/pcp_verifier.png" width="80%" &gt; 
&lt;/p&gt;

&lt;p&gt;More formally we will first define a probabilistic polynomial time verifier for a language L as follows: &lt;br&gt;
The verifier takes a string x and a proof (that x is in L) as input. The verifier gets to read &lt;span class="math"&gt;\(q\)&lt;/span&gt; bits of the proof and &lt;span class="math"&gt;\(r\)&lt;/span&gt; random bits (drawn from a uniform distribution). Using these two pieces of information the verifier must then decide in polynomial time whether or not x is in L. &lt;br&gt;&lt;br&gt;
Define the complexity class PCP(r, q) as follows: &lt;br&gt;
Let L be a language and v be a probabilistic polynomial time verifier which can read q bits of a proof and has access to string of r random bits drawn from a uniform distribution. Then language L is in &lt;span class="math"&gt;\(PCP(r,q)\)&lt;/span&gt; if and only if &lt;br&gt;
Completeness: For every &lt;span class="math"&gt;\(x \in L\)&lt;/span&gt;, there exists a proof that &lt;span class="math"&gt;\(x \in L\)&lt;/span&gt; which v accepts with probability 1 &lt;br&gt;
Soundness: For every &lt;span class="math"&gt;\(x \not\in L\)&lt;/span&gt;, v accepts all proofs that &lt;span class="math"&gt;\(x \in L\)&lt;/span&gt; with probability at most &lt;span class="math"&gt;\(\frac{1}{2}\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;
What does this mean? To gain a basic understanding lets look at some simple edge cases:&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(PCP(0,0) = P\)&lt;/span&gt; (Claim 1)&lt;br&gt;&lt;br&gt;
Notice &lt;span class="math"&gt;\(P \subseteq PCP(0,0)\)&lt;/span&gt; Let L be any language in P. Since our verifier has polynomial arbitrary steps of computation we can verify that any &lt;span class="math"&gt;\(x \in P\)&lt;/span&gt; with probability 1 without a proof or any randomness by replicating the polynomial time solver for L. Also notice &lt;span class="math"&gt;\(PCP(0,0) \subseteq P\)&lt;/span&gt; because there is no randomness or proof to use. If we could accept any language &lt;span class="math"&gt;\(L' \not\in P\)&lt;/span&gt; then we would have a deterministic polynomial time algorithm which told us if any &lt;span class="math"&gt;\(x\)&lt;/span&gt; was in &lt;span class="math"&gt;\(L'\)&lt;/span&gt;. This algorithm creates a contradiction because by definition of &lt;span class="math"&gt;\(L'\)&lt;/span&gt; there is no polynomial time algorithm to determine if any arbitrary string &lt;span class="math"&gt;\(x\)&lt;/span&gt; is in &lt;span class="math"&gt;\(L'\)&lt;/span&gt;. &lt;span class="math"&gt;\(\square\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(PCP(0, O(1)) = P\)&lt;/span&gt; (Claim 2)&lt;br&gt;&lt;br&gt;
To show &lt;span class="math"&gt;\(P \subseteq PCP(0, O(1))\)&lt;/span&gt; we can use claim 1 and notice that &lt;span class="math"&gt;\(P \subseteq PCP(0, 0) \subseteq PCP(0, O(1))\)&lt;/span&gt;. Now all we have to show is that &lt;span class="math"&gt;\(PCP(0, O(1)) \subseteq P\)&lt;/span&gt;. We will use a similar strategy to last time but with a few tweaks. Let's pretend there is a language &lt;span class="math"&gt;\(L' \not\in P\)&lt;/span&gt; but &lt;span class="math"&gt;\(L' \in PCP(0,O(1))\)&lt;/span&gt;. In this case we know there is a way to check deterministically in polynomial time whether any &lt;span class="math"&gt;\(x \in L'\)&lt;/span&gt; by only reading a constant number of bits of the proof. Let's call this constant c. One important fact is that c is the same for every &lt;span class="math"&gt;\(x\)&lt;/span&gt;. Therefore we can run our polynomial time algorithm on each of the &lt;span class="math"&gt;\(2^c\)&lt;/span&gt; possible bits of the proof in polynomial time (with respect to the size of &lt;span class="math"&gt;\(x\)&lt;/span&gt;). If one of these combinations of bits gets accepted then we know &lt;span class="math"&gt;\(x \in L'\)&lt;/span&gt; (completeness) otherwise we know &lt;span class="math"&gt;\(x \not\in L'\)&lt;/span&gt; (soundness). Therefore we have just built a polynomial time algorithm to check if &lt;span class="math"&gt;\(x\)&lt;/span&gt; is in &lt;span class="math"&gt;\(L'\)&lt;/span&gt;. This algorithm creates a contradiction because by definition &lt;span class="math"&gt;\(L'\)&lt;/span&gt; there is no polynomial time algorithm to determine if any arbitrary string &lt;span class="math"&gt;\(x\)&lt;/span&gt; is in &lt;span class="math"&gt;\(L'\)&lt;/span&gt;. &lt;span class="math"&gt;\(\square\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;span class="math"&gt;\(PCP(O(\mbox{log n}), 0) = P\)&lt;/span&gt; (Claim 3) &lt;br&gt;&lt;br&gt;
As with the claim 2, we can show  &lt;span class="math"&gt;\(P \subseteq PCP(0, O(1)\)&lt;/span&gt; by observing that, &lt;span class="math"&gt;\(P \subseteq PCP(0,0) \subseteq PCP(O(\mbox{log n}), 0)\)&lt;/span&gt;. To show &lt;span class="math"&gt;\(PCP(O(\mbox{log n}),0) \subseteq P\)&lt;/span&gt; we will have to again tweak our strategy from before. As before consider an &lt;span class="math"&gt;\(L' \not\in P\)&lt;/span&gt; but &lt;span class="math"&gt;\(L' \in PCP(O(\mbox{log n},0)\)&lt;/span&gt;. Unlike last time our verifier's algorithm is not deterministic. However we can make it deterministic by running our verifier's algorithm on every possible random string of r bits. We know that r is &lt;span class="math"&gt;\(O(\mbox{log n})\)&lt;/span&gt; so there are &lt;span class="math"&gt;\(2^{r}\)&lt;/span&gt; combinations which is at most &lt;span class="math"&gt;\(2^{O(\mbox{log n})} = O(n)\)&lt;/span&gt;. So we just have to run our polynomial verifier algorithm on a linear number of different random bit strings which gives us a deterministic polynomial time algorithm to check if any &lt;span class="math"&gt;\(x \in L'\)&lt;/span&gt;. &lt;span class="math"&gt;\(\square\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So after looking at all of these cases, what do we think &lt;span class="math"&gt;\(PCP(O(log n), O(1))\)&lt;/span&gt; equals?&lt;/p&gt;
&lt;p&gt;PCP Theorem: &lt;span class="math"&gt;\(PCP(O(log n), O(1)) = NP\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This means that for any decision problem in NP, we can construct a small probabilistic polynomial time verifier which can solve the decision problem up to soundness by at most looking at constant bits of an argument about what the answer is far faster than we could solve the problem deterministically.
Seems surprising, right? We will not prove this theorem in this post but we will use it to show some results about how hard it is to approximate certain NP-Complete problems.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MAX-3SAT&lt;/strong&gt;&lt;br&gt;
3SAT is a famous NP-Complete Problem. It goes like this: &lt;br/&gt;
Take a set of m variables and n clauses. Each clause has exactly three literals (variables which may be negated) in it all of them are or'ed together. We then take the conjunction of all of the clauses together. This expression is said to be in 3 conjunctive normal form (3CNF). Here is an example of a 3CNF expression, &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$(x_1 \lor x_2 \lor x_3) \land (\bar x_4 \lor x_1 \lor x_3) \land (\bar x_3 \lor \bar x_2 \lor x_4)$$&lt;/div&gt;
&lt;p&gt;&lt;br&gt;
 The classical 3SAT problem asks if all of the clauses can be simultaneously satisfied.  &lt;br/&gt;
However sometimes we can't satisfy all of the clauses. MAX-3SAT an optimization problem in which we are given an 3CNF expression and we try to find the maximum number of clauses which can all be satisfied together. &lt;br/&gt;&lt;br/&gt;
Since MAX-3SAT is NP-Complete we know that we cannot solve it exactly in polynomial time unless P=NP. But what if we could get close? &lt;br /&gt;&lt;br /&gt;
We say that an problem has a polynomial time approximation scheme (PTAS) if for all &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; we can approximate the problem in polynomial time within a factor of &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; of the optimal solution. It is important to note however that the runtime of a PTAS must only be polynomial in terms of n (the size of the input) and could be different for different epsilons. For example &lt;span class="math"&gt;\(O(n^\frac{1}{\epsilon})\)&lt;/span&gt; is still polynomial in terms of n. Polynomial time approximation schemes are the only way forward for some NP-Hard problems such as Knapsack and Load Balancing. Sadly, MAX-3SAT has no PTAS. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; &lt;span class="math"&gt;\(NP \subseteq PCP(log(n), O(1))\)&lt;/span&gt; (PCP Theorem) implies that MAX-3SAT is inapproximable in polynomial time within some &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; unless P=NP. &lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Assume we have a polynomial time approximation scheme for MAX-3SAT. We will show that using this PTAS for MAX-3SAT and a fixed $\epsilon$ we can solve &lt;b&gt;any&lt;/b&gt; NP complete decision problem in polynomial time. Let $L$ be the language of strings which satisfy your favorite NP- Complete decision problem. Let $x$ be a string of any size n. We want to know if $x$ is in $L$. Since $L \in PCP(log(n), O(1))$ there is an verifier which takes $x$, log n bits of randomness and a proof that $x \in L$. The verifier reads c (a constant) bits of the proof and then decides whether or not $x$ is in $L$. The completeness property of the verifier says that if $x \in L$ then there is a proof that we can give the verifier so that it will always return true. The soundness property says that if $x \not \in L$ then for every proof the verifier will return true less than half of the time. &lt;br&gt; &lt;br&gt;
 For any random string of $O(log(n))$ bits r we can figure out in polynomial time which bits of the proof our verifier will check. Let $Q_r$ be a set of variables corresponding to the locations of each bit our verifier will check. Also define a set of 3CNF clauses $C_r$ with $Q_r$ as its variables. Together the clauses $C_r$ will mimic the output of our verifier (with random string r) when it reads the bits represented by the variables in $Q_r$. It's important that the number of clauses in any $C_r$ does not depend on the size of our input.
&lt;details&gt;
    &lt;summary&gt;(details)&lt;/summary&gt;
    &lt;br&gt;PCP says our verifier only needs to read a c bits of the proof no matter what the size of the input is. In the worst case we could write a CNF formula that maps every possible configuration of the c bits to true or false. In this case we have $2^c$ clauses with c variables per clause. It turns out that we can also translate every CNF instance into a 3CNF instance in polynomial time which means that we may end up with more clauses, but the the number of clauses will still only depend on c not n the size of the input. Therefore this construction is constant in time and space with respect to n. 
&lt;/details&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
Now define &lt;span class="math"&gt;\(Q\)&lt;/span&gt; to be the union of all sets &lt;span class="math"&gt;\(Q_r\)&lt;/span&gt; for every possible r and &lt;span class="math"&gt;\(C\)&lt;/span&gt; to be the union of &lt;span class="math"&gt;\(C_r\)&lt;/span&gt;. One important fact is that the size of &lt;span class="math"&gt;\(Q\)&lt;/span&gt; and &lt;span class="math"&gt;\(C\)&lt;/span&gt; is linear with respect to n. This is because the size of each &lt;span class="math"&gt;\(Q_r\)&lt;/span&gt; and &lt;span class="math"&gt;\(C_r\)&lt;/span&gt; is a constant and the total number of possible strings r = &lt;span class="math"&gt;\(2^{O(log(n))} = O(n)\)&lt;/span&gt;. So the size of &lt;span class="math"&gt;\(Q,C\)&lt;/span&gt; is at most &lt;span class="math"&gt;\(O(n)\)&lt;/span&gt;.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Finally create a 3CNF instance whose set of variables is &lt;span class="math"&gt;\(Q\)&lt;/span&gt;, and whose set of clauses is the conjunction of all the clauses in &lt;span class="math"&gt;\(C\)&lt;/span&gt;. Together all the variables in &lt;span class="math"&gt;\(Q\)&lt;/span&gt; represent a proof &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; (or at least all the parts that our verifier could ever read) that &lt;span class="math"&gt;\(x \in L\)&lt;/span&gt;. Each set of clauses &lt;span class="math"&gt;\(C_r\)&lt;/span&gt; represents the output of the verifier with a certain random string r given access to our proof &lt;span class="math"&gt;\(\pi\)&lt;/span&gt;. Due to completeness, if &lt;span class="math"&gt;\(x\)&lt;/span&gt; is satisfiable then there is a proof &lt;span class="math"&gt;\(\pi\)&lt;/span&gt; such than all of the clauses will be satisfied. &lt;details&gt;
    &lt;summary&gt;(details)&lt;/summary&gt;
    &lt;br&gt;Now this is not technically true since we may have broken our larger clauses in small 3CNF clauses. So for example if we broke one clause with 11 terms into 4 different 3CNF clauses then only one of those would have to be satisfied. In cases like this we count all these clauses as one (if one is satisfied then we are happy).&lt;br&gt;&lt;br&gt;
&lt;/details&gt; If the proof is incorrect then due to soundness, less than half of the clauses will be satisfied for every proof. If &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; is small enough our PTAS have to satisfy more than half of the &lt;span class="math"&gt;\(C_r\)&lt;/span&gt;s if and only if our &lt;span class="math"&gt;\(x\)&lt;/span&gt; is in &lt;span class="math"&gt;\(L\)&lt;/span&gt;. Notice the same &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt; works no matter what &lt;span class="math"&gt;\(x\)&lt;/span&gt; is because the size of our construction did not depend on the n. Therefore, a PTAS for MAX-3SAT would give us a polynomial time algorithm to solve any NP Complete decision problem. &lt;span class="math"&gt;\(\square\)&lt;/span&gt;&lt;/p&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;In short what we just did was assume that there was a PTAS for MAX-3SAT. Then we used this PTAS to construct a polynomial time deterministic solver for any NP-Complete decision problem. Because our PTAS takes polynomial time we know that its existence would prove P = NP which in our case is a contradiction (we assume P &lt;span class="math"&gt;\(\neq\)&lt;/span&gt; NP). Part of what makes this proof so cool is that the reduction doesn't change depending on what NP Complete decision problem we use. For maximum confusion I recommend using 3SAT. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;!--&lt;br /&gt;
**MAXSNP and Immediate consequences of our theorem**
One interesting and immediate consequence of our above theorem can be observed by looking at the class of problems MAXSNP. MAXSNP are NP-Hard optimization problems with the property that if there is an approximation for one of the problems, it can be used to approximate any of the other problems in the class. Many problems such as Independent Set and MAXCUT are in MAXSNP. Coincidently MAX-3SAT is also in MAXSNP. This is really interesting because from our above proof we have inadvertently just shown that everything else in MAXSNP has no PTAS.
&lt;br&gt;&lt;br&gt;!--&gt;

&lt;p&gt;&lt;strong&gt;The Hardness of Approximating Max Clique&lt;/strong&gt; &lt;br/&gt;
A clique is a set of vertices in a graph which are all connected to each other. The size of a clique is the number of vertices it contains. Here's an example of a clique of size 4 &lt;br/&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/pcp-theorem/clique_4.png" width="30%" &gt; 
&lt;/p&gt;
&lt;p&gt;Given a graph G the Max Clique problem is to find the largest clique in G. Max Clique is NP-Complete, which means that it cannot be solved exactly in polynomial time unless P=NP. But can we get close to the optimal solution? In a surprising twist just like MAX-3SAT, Max Clique does not have a PTAS. &lt;br/&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; Max Clique is inapproximable in polynomial time within some &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; unless P=NP. &lt;br&gt;&lt;br&gt;
To prove this statement we will show that Max Clique on a certain graph corresponds to MAX-3SAT so closely that if we had a PTAS for Max Clique we would have a PTAS for MAX-3SAT. Heres how we construct this graph. Given a set of &lt;span class="math"&gt;\(m\)&lt;/span&gt; clauses in 3CNF form, we can construct a graph G as follows. For each clause &lt;span class="math"&gt;\(c_k\)&lt;/span&gt; add 3 vertices each one representing a literal in that clause. For every vertex v connect v to every other vertex which is not part of the same clause and that does not represent a negation of the literal v represents. Here is an example of this construction with two clauses, &lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/pcp-theorem/sat-to-mclique.png" width="65%" &gt; 
&lt;/p&gt;
&lt;p&gt;Let's say we find a clique of size k in this graph.  Consider what would happen if we set the variables corresponding to each vertex in our clique to true (or false if they are negations) and all the other variables to false (or true if they are negations). We can do this with no conflicts because by our construction no two vertices in the clique are negations of each other. Also by construction each vertex is in a different clause so at least k different clauses are satisfied. &lt;br&gt;
Now consider &lt;span class="math"&gt;\(x\)&lt;/span&gt; an instance of MAX-3SAT. We know since MAX-3SAT has no PTAS &lt;span class="math"&gt;\(\exists \delta &amp;gt; 0\)&lt;/span&gt; such that we cannot approximate MAX-3SAT within &lt;span class="math"&gt;\(\delta\)&lt;/span&gt;. Now choose let our PTAS be an &lt;span class="math"&gt;\(1+\epsilon\)&lt;/span&gt; approximation where &lt;span class="math"&gt;\(\epsilon &amp;lt; \delta\)&lt;/span&gt;. We can turn our &lt;span class="math"&gt;\(x\)&lt;/span&gt; into a graph following our construction above. Notice that a &lt;span class="math"&gt;\(1 - \epsilon\)&lt;/span&gt; approximation of max clique gives us a &lt;span class="math"&gt;\(1 - \epsilon\)&lt;/span&gt; approximation for MAX-3SAT. This is a problem because we have just created a PTAS for MAX-3SAT.&lt;span class="math"&gt;\(\square\)&lt;/span&gt; &lt;br&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Okay, we can't do construct a PTAS, so we can't get as close as we want. What about approximating MAX Clique within some constant factor? Plenty of NP-Complete problems have a constant factor approximation including MAX-3SAT. As you may have guessed we won't be so lucky with Max Clique. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; Max Clique has no constant factor approximation unless P = NP. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Before we prove this theorem we have to build up some machinery on graphs. We will do this by defining the strong graph product. &lt;br&gt;&lt;br&gt;
&lt;strong&gt;Definition&lt;/strong&gt; The (strong) graph product on graphs &lt;span class="math"&gt;\(G = G_1 \bigotimes G_2\)&lt;/span&gt; is defined as follows: &lt;br&gt;
&lt;span class="math"&gt;\(V_G = V_{G_1} \times V_{G_2}\)&lt;/span&gt; (where &lt;span class="math"&gt;\(\times\)&lt;/span&gt; is the Cartesian product) &lt;br&gt;
&lt;span class="math"&gt;\(E_G = \\{(u_1,v_1), (u_2,v_2)\\}\)&lt;/span&gt; such that &lt;span class="math"&gt;\((u_1, u_2) \in E_{G_1}\)&lt;/span&gt; or &lt;span class="math"&gt;\(u_1 = u_2, (v_1, v_2) \in E_{G_2}\)&lt;/span&gt; or &lt;span class="math"&gt;\(v_1 = v_2\)&lt;/span&gt; &lt;br&gt;
Here's an example,&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/pcp-theorem/strong-graph-product.png" width="80%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
While this definition may seem daunting one can visualize it by imagining that we are putting a copy of &lt;span class="math"&gt;\(G_1\)&lt;/span&gt; at every vertex of &lt;span class="math"&gt;\(G_2\)&lt;/span&gt; then connecting the edges according to our edge rules. 
Look at the max clique size &lt;span class="math"&gt;\(\omega(G)\)&lt;/span&gt; for each graph in the drawing above: &lt;/p&gt;
&lt;div class="math"&gt;$$\omega(G_1) = 2, \omega(G_2) = 2, \omega(G_1 \bigotimes G_2) = 4$$&lt;/div&gt;
&lt;p&gt; &lt;br&gt;&lt;br&gt;
What can we make of this? It turns out that an important fact about graph products is,&lt;/p&gt;
&lt;p style="display:inline;"&gt;
    &lt;div style="text-align:center;"&gt;$\omega(G_1 \bigotimes G_2) = \omega(G_1)\omega(G_2)$&lt;/div&gt;
&lt;details style="display:inline;"&gt;
    &lt;summary&gt;(details)&lt;/summary&gt;
    &lt;br&gt;Take the two largest cliques $C_1 \in G_1, C_2 \in G_2$. When we take the graph product $G'$ we place a copy of $G_1$ (including $C_1$) at each vertex in $G_2$. Now consider subgraph $G'$ made of the copies of $C_1$ placed at vertices that make up $C_2$. Consider any edge in G' between two vertices $\\{(u_1,v_1), (u_2,v_2)\\}$. Since $C_1$ and $C_2$ are cliques, $(u_1, u_2) \in E_{G_1}$ or $u_1 = u_2$. The same goes for $v_1$ and $v_2$. So our subgraph is entirely connected. The size of this subgraph is $\lvert C_1 \rvert \lvert C_2 \rvert$. Since this subgraph is a clique the max clique has size at least $\lvert C_1 \rvert \lvert C_2 \rvert = \omega(G_1)\omega(G_2)$.&lt;br&gt;&lt;br&gt; Finally how do we know there is not a larger clique? Well let's reverse our logic. Suppose there is a clique $C' \in G'$ which is larger than $\omega(G_1)\omega(G_2)$. Then we can decompose this clique into one clique in $G_1$ and one in $G_2$. We must be able to do this decomposition because each of if one of the set of vertices that is part of this clique was not a clique itself then we would have a contradiction. 
    &lt;br&gt;&lt;br&gt;
&lt;/details&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Now we return to showing that Max Clique has no constant approximation. Assume we have an &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;-approximation for Max Clique. Now we know there &lt;span class="math"&gt;\(\exists \beta &amp;gt; 0\)&lt;/span&gt; such that Max Clique cannot be approximated within any factor larger than &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; in polynomial time (Max Clique has not PTAS). Choose a &lt;span class="math"&gt;\(k\)&lt;/span&gt; such that &lt;span class="math"&gt;\(\beta^k &amp;lt; \alpha\)&lt;/span&gt;. Take in a graph G. Compute &lt;span class="math"&gt;\(G^k\)&lt;/span&gt; by taking the repeated graph product. Now use our alpha approximation algorithm on &lt;span class="math"&gt;\(G^k\)&lt;/span&gt;. Remember our fact from earlier, &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$\omega(G^k) = \omega(G)^k$$&lt;/div&gt;
&lt;p&gt;Let &lt;span class="math"&gt;\(C'\)&lt;/span&gt; denote the clique we found. Then we can say: &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ \lvert C' \rvert = \alpha \omega(G^k) $$&lt;/div&gt;
&lt;p&gt;This implies that there is a clique &lt;span class="math"&gt;\(C\)&lt;/span&gt; in our original graph such that:&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ \lvert C \rvert = \sqrt[k]{(\lvert C' \rvert)} = \sqrt[k]{(\alpha w(G^k))} = \sqrt[k]{(\alpha)}w(G)$$&lt;/div&gt;
&lt;p&gt;We know by our definition of k that:&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ \sqrt[k]{(\alpha)}w(G) &gt; \beta w(G) $$&lt;/div&gt;
&lt;p&gt;Therefore we have just created a polynomial approximation for Max Clique within &lt;span class="math"&gt;\(\epsilon\)&lt;/span&gt;. Unless P=NP this is a contradiction. &lt;span class="math"&gt;\(\square\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;
So it turns out that Max Clique is really bad. In fact the best results on the hardness of Max Clique indicate the the only approximation one can make is a clique of size one (i.e choosing a single vertex). &lt;br&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Getting better hardness guarantees&lt;/strong&gt; &lt;br&gt;
So far, our results with the standard PCP Theorem have been quite cool. We have used a powerful tool to show that some NP-Complete Problems aren't just hard to solve exactly but are hard to approximate up to a certain point. One question is could we be more specific? It is simple to come up with a &lt;span class="math"&gt;\(\frac{7}{8}\)&lt;/span&gt;-approximation algorithm for MAX-3SAT but can we do better? After the PCP Theorem was introduced, researchers have become less interested in proving that there is no PTAS for certain problems and more interested in optimal inapproximability. &lt;br&gt;
&lt;br&gt; &lt;strong&gt;Definition&lt;/strong&gt; An optimal inapproximability result for a problem says there is both an algorithm which is an &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; approximation that problem as well as a proof that the problem cannot be approximated within a factor of &lt;span class="math"&gt;\(\alpha + \epsilon\)&lt;/span&gt; for any &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;.&lt;br&gt;&lt;br&gt;
While our classic PCP Theorem was enough to show many problems had no PTAS, it is not quite as simple to use for specific lower bounds. One way to get around this limitation is to define new versions of the PCP Theorem. One such theorem was posed by Johan Hastad: &lt;br&gt;&lt;br&gt;
&lt;strong&gt;Theorem (Hastad's 3 Bit PCP):&lt;/strong&gt;
For every &lt;span class="math"&gt;\(\delta &amp;gt; 0\)&lt;/span&gt; and &lt;span class="math"&gt;\(L \in NP\)&lt;/span&gt;, there exists a PCP verifier (with &lt;span class="math"&gt;\(\mbox{log n}\)&lt;/span&gt; bits of randomness) such that L can be verified in three queries with completeness &lt;span class="math"&gt;\((1 - \delta)\)&lt;/span&gt; and soundness at most &lt;span class="math"&gt;\(\frac{1}{2}+\delta\)&lt;/span&gt;. Furthermore the tests are of the following form. Our verifier chooses a parity bit &lt;span class="math"&gt;\(b \in \\{0,1\\}\)&lt;/span&gt; and then takes the three bits it queries &lt;span class="math"&gt;\(q_1,q_2,q_3\)&lt;/span&gt; and returns true if:&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ q_1 + q_2 + q_3 = b \quad (\mbox{mod } 2)$$&lt;/div&gt;
&lt;p&gt;&lt;br&gt;
A full proof of this theorem is beyond the scope of this post. However we will use this theorem to show optimal inapproxibility results for MAX-3SAT as well as a more specific approximation for Vertex Cover. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MAX-3LIN&lt;/strong&gt;&lt;br&gt;
The MAX-3LIN problem is defined as follows: &lt;br&gt;
Given a system of integral linear equations (mod 2) with a most 3 variables what is the maximum number of them which can be satisfied simultaneously? It's immediately apparent that this problem is closely related to Hastad's variant of the PCP Theorem. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We can consider Hastad's PCP equivalent to the statement:&lt;br&gt;&lt;/p&gt;
&lt;p style="display:inline;"&gt;For any $\epsilon &gt; 0$ determining between two instance of MAX-E3LIN, one where at least $(1 - \epsilon)$ of the equations are satisfied and one where at most $\frac{1}{2}+\epsilon$ of the equations are satisfied is NP-Hard.&lt;details style="display:inline;"&gt;
    &lt;summary&gt;(Details)&lt;/summary&gt;
    If we had a polynomial time algorithm to tell the difference we use it to deterministically test if any string $x$ is in your favorite NP-Complete language L by building a system of equations (one for each possible random string) that mimic our Hastad PCPs output given that string. If we know we satisfied more than $\frac{1}{2}$ of the equations, by soundness we know $x$ must be in $L$, if we don't we know $x$ is not in $L$ by completeness. This argument is very similar to our proof that MAX-3SAT has no PTAS. 
&lt;/details&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Now we will use this formulation to prove better approximation bounds for MAX-3SAT and Vertex Cover. We will call this problem, GAP-3LIN. The GAP part comes from the fact that the domain of all possible numbers of mutually solvable equations has a gap in the middle. In the two proofs we will exploit this gap to give better lower bounds than we would be able to obtain with just vanilla PCP.&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; MAX-3SAT cannot be approximated by a factor of &lt;span class="math"&gt;\(1 - (\frac{7}{8}+\epsilon)\)&lt;/span&gt; for any &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;. &lt;br&gt;
To show this result we will reduce our gap GAP-E3LIN to MAX-3SAT. Given an equation:&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ a+b+c = 0 $$&lt;/div&gt;
&lt;p&gt;We create the following four clauses:&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ (\bar a\lor b \lor c) $$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$ (a\lor \bar b \lor c) $$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$ (a\lor b \lor \bar c) $$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$ (\bar a\lor \bar b \lor \bar c) $$&lt;/div&gt;
&lt;p&gt;These clauses are important because all four are only satisfied if and only if &lt;span class="math"&gt;\(a+b+c = 0\)&lt;/span&gt; (we can do the same thing if the equation should sum to 1). Otherwise at most &lt;span class="math"&gt;\(\frac{3}{4}\)&lt;/span&gt; of the clauses are satisfiable. From our previous result we know that it is NP-Hard to distinguish between an instance of MAX-E3LIN where &lt;span class="math"&gt;\(\frac{1}{2}+\delta\)&lt;/span&gt; the equations are satisfied versus one where &lt;span class="math"&gt;\(1-\delta\)&lt;/span&gt; of the equations are satisfied for any &lt;span class="math"&gt;\(\delta &amp;gt; 0\)&lt;/span&gt;. Consider a polynomial time algorithm Max-3SAT with an approximation ratio of &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;. Take an instance &lt;span class="math"&gt;\(x\)&lt;/span&gt; of MAX-E3LIN and creates a 3CNF expression from it by doing the following. For each equation in &lt;span class="math"&gt;\(x\)&lt;/span&gt; create four clauses following our above model and then combine all of them into one large 3CNF instance. If we could satisfy a fraction of more than &lt;span class="math"&gt;\(1 - (\frac{1}{2} - \delta)\frac{1}{4}\)&lt;/span&gt; of the clauses we could determine between the two different types of GAP-E3LIN instances. Since this is true for all &lt;span class="math"&gt;\(\delta &amp;gt; 0\)&lt;/span&gt;, we know that the largest valid value of &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; is 0 (Unless P=NP). This gives us the following lower bound for MAX-3SAT: &lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$1 - \frac{1}{8} = \frac{7}{8}$$&lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\square\)&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;It turns out that the Hastad PCP Theorem is useful for more than just MAX-3SAT. Another problem which gives a specific constant bound with this theorem is vertex cover. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vertex Cover&lt;/strong&gt;
Given a graph G we say that a vertex cover of G is a set of the vertices such that every vertex in the graph is directly connected to one of these vertices via and edge, The vertex cover problem is to find a minimum such vertex cover on G. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Independent Set&lt;/strong&gt;
It is useful to talk about independent set whenever we talk about vertex cover. Given a graph G, an Independent Set is a set of vertices which are not connected to each other. The Independent Set problem is to find the largest independent set in G. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fact&lt;/strong&gt; One reason why these two problems are often presented together is because one is the complement of the other. That is to say let &lt;span class="math"&gt;\(I\)&lt;/span&gt; the maximum independent set in a graph and let &lt;span class="math"&gt;\(C\)&lt;/span&gt; the minimum vertex cover. &lt;span class="math"&gt;\(G - I = C\)&lt;/span&gt; (or the other way around). &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; Vertex Cover cannot be approximated within a factor of &lt;span class="math"&gt;\(\frac{7}{6} - \epsilon\)&lt;/span&gt; for any &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; unless P=NP. &lt;br&gt;&lt;br&gt;
We again use the fact that GAP-3LIN is NP-Hard. Our goal is to use a &lt;span class="math"&gt;\(\frac{7}{6} - \epsilon\)&lt;/span&gt; approximation of Vertex Cover to solve GAP-3LIN. We just need a way to translate equations to graphs. We will do this using the following construction: &lt;br&gt;
Look at an equation of the form &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$x_1 + x_2 + x_3 = 0 \quad \mbox{mod } 2$$&lt;/div&gt;
&lt;p&gt;The first thing we can notice about it is that it has eight possible choices of values. Notice that half of them will satisfy the equation and half of them will not. Therefore for any equation of this form there are 4 ways to satisfy it. &lt;br&gt;
Now in our graph for each equation in our MAX-E3LIN instance we will create four different vertices, one for each of the valid solutions to the equation. We will connect all of them together as well as connecting them to each other vertex in the graph representing a logically incompatible solution to a different equation. When we are done there will be &lt;span class="math"&gt;\(4m\)&lt;/span&gt; vertices. Here's an example with two equations&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/pcp-theorem/e3lin-to-vertex-cover.png" width="65%" &gt; 
&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Observation 1&lt;/strong&gt; If at least &lt;span class="math"&gt;\((1-\epsilon)m\)&lt;/span&gt; of the equations of our GAP-E3LIN instance are satisfiable then our independent set is at least of size &lt;span class="math"&gt;\((1-\epsilon)m\)&lt;/span&gt;. This is because by construction of our graph, each satisfiable equation does not have an edge to any other mutually satisfiable equations because neither of them are different variable choices for the same equation and neither contradict each other. So since the maximum independent set is at least of size &lt;span class="math"&gt;\((1 - \epsilon)m\)&lt;/span&gt;, the minimum vertex cover will be at most of size &lt;span class="math"&gt;\((3 + \epsilon)m\)&lt;/span&gt;. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observation 2&lt;/strong&gt; If at most &lt;span class="math"&gt;\((\frac{1}{2} + \epsilon)m\)&lt;/span&gt; equations are mutually satisfiable, then our maximal independent set will be of size at most &lt;span class="math"&gt;\((\frac{1}{2} + \epsilon)m\)&lt;/span&gt;. To show this is true consider we will pretend we could have a larger independent set. Take &lt;span class="math"&gt;\(v\)&lt;/span&gt; a vertex in this independent set which does not represent one our our satisfiable equations. By the rules of our construction &lt;span class="math"&gt;\(v\)&lt;/span&gt; would also not conflict with any of the &lt;span class="math"&gt;\((\frac{1}{2} + \epsilon)m\)&lt;/span&gt; mutually satisfiable equations of the other equations represented in the independent set. Therefore the existence of &lt;span class="math"&gt;\(v\)&lt;/span&gt; would imply there is another equation which could be mutually satisfied. This would contradict our assume that only &lt;span class="math"&gt;\((\frac{1}{2} + \epsilon)m\)&lt;/span&gt; are mutually satisfiable. So we know that the maximum independent set size is at most &lt;span class="math"&gt;\((\frac{1}{2} + \epsilon)m\)&lt;/span&gt;. This implies that the minimum vertex cover size will be at least &lt;span class="math"&gt;\((\frac{7}{2} - \epsilon)m\)&lt;/span&gt;. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The two observations we have just made help define the gap between vertex cover instances associated with each of the two cases. This means that if we can approximate the upper bound of the smaller case within a factor that is tight enough so our approximation does not overlap with the lower bound of the larger case then we can distinguish between the two cases. To formalize this assume that we have an algorithm which can approximate vertex cover to a factor of &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;. For any &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; we know that unless we can solve GAP-3LIN in polynomial time: &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$\alpha (3 + \epsilon) &gt; \frac{7}{2} - \epsilon$$&lt;/div&gt;
&lt;div style="text-align:center;"&gt;$$\alpha &gt; \frac{\frac{7}{2} - \epsilon}{(3 + \epsilon)}$$&lt;/div&gt;
&lt;p&gt;This is to say that if &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; is too small than our smaller case and our larger case still be distinguished in our approximation. 
Because this is true for all &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt; we can take the limit as &lt;span class="math"&gt;\(\epsilon \to 0\)&lt;/span&gt; to find an &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; that works for all cases: &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$\alpha = \frac{\frac{7}{2}}{3} = \frac{7}{6}$$ &lt;/div&gt;
&lt;p&gt;&lt;span class="math"&gt;\(\square\)&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Let's Play a Game&lt;/strong&gt; &lt;br&gt;
Now we have seen some basic ideas such as gaps and simple graph operations as ways to prove hardness. One more common set of tools to show hardness of approximations is 2 Prover 1 Round Games. This last section aims to give some background on this problem. &lt;br&gt;&lt;br&gt;
&lt;strong&gt;Definition:&lt;/strong&gt; A 2 Prover 1 Round Game is a game played by two provers (players) with the following parameters: &lt;br&gt;
Two sets of questions: (one for each player) &lt;span class="math"&gt;\(X,Y\)&lt;/span&gt; &lt;br&gt;
A probability distribution: &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; over &lt;span class="math"&gt;\(X \times Y\)&lt;/span&gt; &lt;br&gt;
A set of answers: &lt;span class="math"&gt;\(A\)&lt;/span&gt; &lt;br&gt;
A verifier (acceptance predicate): &lt;span class="math"&gt;\(V:X\times Y \times A \times A\)&lt;/span&gt; &lt;br&gt;
A strategy for each player: &lt;span class="math"&gt;\(f_1:X \to A, f_2:Y \to A\)&lt;/span&gt; &lt;br&gt;&lt;br&gt;
The rules of the game are as follows: &lt;br&gt;
The verifier picks two questions &lt;span class="math"&gt;\((x, y) \in X \times Y\)&lt;/span&gt; from the distribution and asks x to player 1 and y to the player 2. &lt;br&gt;
Each player thinks of an answer to their respective questions &lt;span class="math"&gt;\((a_1,a_2)\)&lt;/span&gt; by computing &lt;span class="math"&gt;\(a_1 = f_1(x), a_2 = f_2(y)\)&lt;/span&gt;. &lt;br&gt;
The verifier takes both answers and the original questions &lt;span class="math"&gt;\(v(x,y,a_1,a_2)\)&lt;/span&gt; and returns either true or false. &lt;br&gt;&lt;br&gt;
The goal of both players is to maximize &lt;span class="math"&gt;\(\omega(G)\)&lt;/span&gt; to be the optimal win probability for the game G. &lt;br&gt;&lt;br&gt;
Also it is important that the two players cannot communicate during the game. &lt;br&gt;&lt;/p&gt;
&lt;p&gt;You might be thinking, what kind of stupid game is this? Why don't computer scientists at least play something cool like fortnite?
Well here's something kind of cool. We can formulate many problems as 2 Prover 1 Round Games. Let's give an example using good old 3SAT. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Given a set of clauses &lt;span class="math"&gt;\(x\)&lt;/span&gt; in 3CNF form, consider the following 2P1R game: &lt;br&gt;
Let &lt;span class="math"&gt;\(X\)&lt;/span&gt; be the set of all clauses in &lt;span class="math"&gt;\(x\)&lt;/span&gt;. &lt;br&gt;
Let &lt;span class="math"&gt;\(Y\)&lt;/span&gt; be the set of all variables in &lt;span class="math"&gt;\(x\)&lt;/span&gt;. &lt;br&gt;
Let &lt;span class="math"&gt;\(\lambda\)&lt;/span&gt; be such the variable we draw from &lt;span class="math"&gt;\(Y\)&lt;/span&gt; will be in the clause drawn from &lt;span class="math"&gt;\(X\)&lt;/span&gt; (it will be one of the three of them with uniform probability). &lt;br&gt;
Our first prover will return an assignment &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt; of variables satisfying the clause &lt;span class="math"&gt;\(c_j\)&lt;/span&gt; it was given. The second prover will return an assignment &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; of &lt;span class="math"&gt;\(x_i\)&lt;/span&gt; the variable it was given. The verifier will return true if and only if &lt;span class="math"&gt;\(\beta\)&lt;/span&gt; matches the assignment given to the same variable in &lt;span class="math"&gt;\(\alpha\)&lt;/span&gt;. &lt;br&gt;&lt;br&gt; 
Observation 1: If &lt;span class="math"&gt;\(x\)&lt;/span&gt; is fully satisfiable then both players just pick according to the satisfying assignment. In some cases there may be more than one satisfying assignment in which case both players can agree some sort of ordering scheme beforehand and pick the first one. &lt;br&gt;&lt;br&gt;
Observation 2: If no satisfying assignment exists then every assignment fails to satisfy a certain factor of the clauses (let's call it &lt;span class="math"&gt;\(p\)&lt;/span&gt;). Then the probability of failure will be at least &lt;span class="math"&gt;\(\frac{p}{3}\)&lt;/span&gt;. &lt;br&gt;&lt;br&gt;
Now there are several things that are interesting about this 2 prover round 1 game reduction. One is that we turned 3SAT which is a decision problem into a gap decision problem. The second thing which is related is that we can now start to talk about this game in terms of completeness and soundness. In a way this is starting to sound like the PCP Theorem. &lt;br&gt;&lt;br&gt;
Another thing we could try is to play some kind of repeated game. One way we could do this is asking a series of questions, one after another. However it turns out to be more interesting to ask a bunch of questions at the same time (in parallel). We define a parallel n-repeated game &lt;span class="math"&gt;\(G^n\)&lt;/span&gt; for some 2P1R game G to be similar to G but each player reads a tuple of n questions and then outputs a tuple of n answers. The verifier accepts if and only if all the individual answers would be accepted by the verifier for G. So what can we say about these repeated games?&lt;br&gt;&lt;br&gt; 
&lt;strong&gt;Theorem (Parallel Repetition Theorem):&lt;/strong&gt; For all games &lt;span class="math"&gt;\(G\)&lt;/span&gt; if &lt;span class="math"&gt;\(\omega(G) = 1 - \delta\)&lt;/span&gt; then, &lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$ \omega(G^n) \leq 2^{-\Omega(\delta^3 n)} $$&lt;/div&gt;

&lt;p&gt;While we will not go talk about this theorem much it is interesting because it can be used to decrease the size of gaps. In our 3-SAT game it is NP-Hard to distinguish between cases where we succeed with probability 1 and probability &lt;span class="math"&gt;\(1-\frac{p}{3}\)&lt;/span&gt;. But what if we could make our gap smaller? This could potentially make it easier to show different approximations are hard. &lt;br&gt;&lt;br&gt;&lt;br&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;&lt;br&gt;
In this post I have summarized my findings after researching the a few basic concepts surrounding the PCP Theorem. Throughout this post there are a few big ideas. First we looked at the PCP Theorem itself and the ideas of completeness and soundness. We played with a few toy cases to get a feel for what the statement was saying. Next we used the PCP Theorem to shows MAX-3SAT had no PTAS. In this proof we turned our random PCP verifier in to a deterministic instance of MAX-3SAT. Then we showed that using MAX-3SAT we could search for a proof that our statement was correct or not. We then used graphs and the self improvement property of the graph product to prove that Max Clique had no constant approximation. After that we looked at Hastad's 3 bit PCP and used it to get a few more specific bounds on MAX-3SAT and Vertex Cover. The most important part of these proofs were the gap preserving reduction from our GAP-MAX-E3LIN decision problem. Finally we looked at a totally different way of viewing everything as a game. These general proof strategies give us some tools to tackle inapproximability arguments. &lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exercises to the Reader&lt;/strong&gt; &lt;br&gt;&lt;br&gt; &lt;/p&gt;
&lt;p&gt;1) Show &lt;span class="math"&gt;\(PCP(log(n), 1) = P\)&lt;/span&gt;&lt;/p&gt;
&lt;details style="display:inline;"&gt;
    &lt;summary&gt;Hint&lt;/summary&gt;
    Think about our proof that MAX-3SAT has no PTAS.
&lt;/details&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;/p&gt;
&lt;details style="display:inline;"&gt;
    &lt;summary&gt;Answer&lt;/summary&gt;
    &lt;br&gt; As a proof of this consider our reduction in the proof for MAX-3SAT having no PTAS. We constructed a MAX-3SAT instance which checked if there was a (the bits of the proof were the variables) proof which could satisfy every one of the O(n) possible combinations of our O(log(n)) bits of randomness. The key was that we only had to have a constant number of variables because we only read a constant number of bits of the proof. Furthermore the size of our clauses was based on the number of bits we read. If we do this same construction here we will end up with an instance of MAX-1SAT which is solvable in polynomial time.
    &lt;br&gt;&lt;br&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;2) We talked about MAX-E3LIN but never proved any hardness results for it. Use Hastad's PCP Theorem prove the following: &lt;br&gt; 
&lt;strong&gt;Theorem:&lt;/strong&gt; MAX-3LIN cannot be approximated by a factor of &lt;span class="math"&gt;\(\frac{1}{2}+\epsilon\)&lt;/span&gt; for any &lt;span class="math"&gt;\(\epsilon &amp;gt; 0\)&lt;/span&gt;. &lt;br&gt;&lt;/p&gt;
&lt;details style="display:inline;"&gt;
    &lt;summary&gt;Answer&lt;/summary&gt;
    &lt;br&gt; Reduce the optimization version of MAX-E3LIN to the decision version using a gap preserving reduction.
    &lt;br&gt;&lt;br&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;3) When the repeated version 2 Prover 1 Round Game was originally conceived it was conjectured that&lt;br&gt;&lt;/p&gt;
&lt;div style="text-align:center;"&gt;$$\omega(G^k) = \omega(G)^k$$&lt;/div&gt;
&lt;p&gt;Give a 2P1R Game which shows that this is false (i.e. &lt;span class="math"&gt;\(\omega(G^k) &amp;gt; \omega(G)^k\)&lt;/span&gt;)  &lt;/p&gt;
&lt;details style="display:inline;"&gt;
    &lt;summary&gt;Answer&lt;/summary&gt;
    We define the Feige Game defined as follows:&lt;br&gt; Each player gets a bit as input. They must output a bit and a player. The players win if their bits are the same and that player did get that bit. Because they can't communicate $\omega(G) = \frac{1}{2}$. The best strategy is to agree upon a player in advance. That player will pick themselves and their bit and the other player will guess their bit. However if the players play the two round version they can double down on their original bets which would mean $\omega(G^2) = \frac{1}{2}$ as well.
    &lt;br&gt;&lt;br&gt;
&lt;/details&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
Sources (and great references for learning more): &lt;br&gt;
http://www.cs.jhu.edu/~scheideler/courses/600.471_S05/lecture_9.pdf&lt;br&gt;
http://people.seas.harvard.edu/~madhusudan/courses/Spring2016/scribe/lect18.pdf&lt;br&gt;
http://pages.cs.wisc.edu/~shuchi/courses/880-S07/scribe-notes/lecture29.pdf&lt;br&gt;
http://www.cs.princeton.edu/~zdvir/apx11slides/guruswami-slides.pdf&lt;br&gt;
https://cstheory.stackexchange.com/questions/18360/multi-prover-verifier-games-and-pcp-theorem&lt;br&gt;
http://theory.cs.princeton.edu/complexity/ab_hastadchap.pdf
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="algorithms"></category><category term="algorithms"></category><category term="theory"></category></entry><entry><title>The Alias Method for Fast Weighted Random</title><link href="/alias-method.html" rel="alternate"></link><published>2017-06-25T00:00:00-07:00</published><updated>2019-10-15T00:00:00-07:00</updated><author><name>Peter Stefek</name></author><id>tag:None,2017-06-25:/alias-method.html</id><summary type="html">&lt;p&gt;Constant time draws from a discrete distribution.&lt;/p&gt;</summary><content type="html">&lt;style&gt;
thick.thicker {
    font-weight: 900;
}
&lt;/style&gt;

&lt;p&gt;&lt;strong&gt;&lt;text class = "thick"&gt;Lets say you have a bag with 2 orange marbles, 2 blue marbles and 2 green marbles&lt;/text&gt;.&lt;/strong&gt; You draw one marble out of the bag. The probability of drawing any color marble is 1/3. This is called a uniform discrete distribution. It's easy to draw from this distribution with a computer. Computers can generate uniform pseudo random numbers in constant time so all you would have to do is generate a number from 1 to 3 and map it to a color of marble depending on the result. This can be done in constant time for any arbitrary number of colors as long as there are the same number of each color of marble.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;But now let's try a slightly different problem.&lt;/strong&gt; Let's take a bag with 1 orange marble, 2 blue marbles and 4 green marbles. This distribution is a general discrete distribution. Clearly we can't tackle this exactly the same way as before. One simple adjustment we could make is to generate a random number between 1 and 7 and map it to 7 boxes. We could put a marble in each box and assign a orange marble to one box, blue marbles to two boxes and green marbles to four boxes. We then lookup the box which corresponds to the number we generate and check which kind of marble it has. This generates the correct distribution.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Finally now let's look at a different general discrete distribution.&lt;/strong&gt; For example, the distribution of orange, blue and green marbles with weights: p(orange) = 251/1000, p(blue) = 479/1000 and p(green) = 270/1000. We cannot use the first technique because there is no easy way to simplify these numbers. The second technique would require us to create 1000 boxes, so it also seems pretty bad. The weakness of our second technique is that the setup time depends on the weights, so the messier the numbers are the longer (and more space) it takes. This is not ideal. &lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Now we can talk about a simple algorithm which solves our problem.&lt;/strong&gt; The plan is to partition the interval [0,1] into n different parts based on the probabilities of each event. In our above example we could partition the interval into three sections with sizes orange = 0.251, blue = 0.479 and green = 0.27. Below is an O(n) algorithm to do this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;weightedRandom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Draw from a general discrete distribution.&lt;/span&gt;
&lt;span class="sd"&gt;    :param weights: A dictionary of weights which sum to one.&lt;/span&gt;
&lt;span class="sd"&gt;    :return: A random sample from it the distribution defined by the weights.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="c1"&gt;#generate a uniform random number from 0 - 1&lt;/span&gt;
    &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; 

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iteritems&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weight&lt;/span&gt;
        &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;remainder&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;color&lt;/span&gt;

&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;6.0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;orange&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;6.0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;6.0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;green&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;orange&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;green&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;600000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;weightedRandom&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;br&gt;
&lt;strong&gt;So can we do better?&lt;/strong&gt; The answer is sort of. It depends on what we want to do. It turns out if we want to sample from the same distribution multiple times, then we can. We will do just one preprocessing step (which will be the same time/space complexity for any set of n weights) and after that each sample will be O(1). So the more times we want to sample from the same distribution, the better the performance will be.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;How does this work?&lt;/strong&gt;
I'm going to go over the preprocessing step in a later section but first I'm going to describe how we do the O(1) lookups. Consider a general discrete probability distribution with n weights. We are going to divide it up into n boxes such that each box will contain pieces of either one or two different different weights and the pieces of these weights will sum to 1/n. From our definition the sum of all the pieces of all the weights in the boxes is 1 (the size of the entire distribution).&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;The description can be difficult.&lt;/strong&gt; I think a picture can really help. In this example we have three colored balls with weights p(blue) = 1/6, p(orange) = 3/6, p(green) = 2/6:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="/images/alias-method/alias_diag.png" width="56%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Once we have this partitioning, our algorithm is very simple:&lt;/strong&gt; &lt;br&gt;
First we pick one of the 3 boxes. Then we choose a uniform random number between 0 and 1. We see which side of our chosen box it falls on and we return that color marble.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Now we need to find these partitions.&lt;/strong&gt; First of you might be asking yourself, why can we always partition the distribution like this? To answer that we will first provide an algorithm to construct these partitions then prove it always works.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;The basic idea of this algorithm is about filling up these boxes.&lt;/strong&gt; First a quick observation. If we look at all the weights in a normalized (the sum of all the weights is one) probability distribution at least one of them must be less than or equal to 1/n where n is the total number of weights. Why is this important? This means that we can always fit one of these weights into a box of size 1/n possibly with some left over space.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Our partitioning algorithm is as follows:&lt;/strong&gt;&lt;br&gt;
1) Sort the weights from least to greatest.&lt;br&gt;
2) Choose the smallest weight and put it into a box. Then if there is any space left over, fill in the extra room with some of the largest weight.&lt;br&gt;
3) Repeat steps 1 and 2 until all of the boxes have been filled.&lt;br&gt;
Here's a visualization of the algorithm:&lt;/p&gt;
&lt;p align="center"&gt;
    &lt;img src="images/alias-method/alias_anim.gif" width="56%" &gt; 
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Now why can we always do this?&lt;/strong&gt; Now that we have the algorithm we can use induction to give a formal proof. Our claim is a little more general than what we have been saying earlier but it will make the proof easier.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Claim:&lt;/strong&gt; Given a set of n non-zero real numbers (called weights) we can partition them into n boxes of size s/n (where s is the sum of all n weights) such that each box only contains pieces of at most 2 weights using our algorithm.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;For the base case:&lt;/strong&gt; Clearly if we have just one weight we can just put it in a single box by itself.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Now comes our inductive step:&lt;/strong&gt; Suppose that we know our claim is true for n - 1 weights. Now we must show it is true for n weights.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Let's do the first step of our algorithm:&lt;/strong&gt; We put the smallest weight in a box of size s/n. We know that it must fit because if it did not our weights would sum to more than s. Now if there is any left over space we fill it with some of our largest weight (by similar logic to the previous sentence this is also always possible). Finally we are left with one filled box and n - 1 unfilled boxes. We know by the inductive hypothesis (our assumption) that we can split whatever is remaining into those n - 1 boxes. Therefore we are done.&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Now finally what is the running time of the preprocessing step?&lt;/strong&gt; First we need to sort all the weights which is O(nlog n). Now we need to do n steps where we get rid of the smallest weight and restart. However the key here is that only the largest weight needs to considered for sorting because its the only value let in the partition that is changed besides the one removed. We can do this in log n time with a binary search (because we have already sorted our weights). Therefore the rest of the algorithm is also O(n log n) so the whole algorithm is O(n log n).&lt;br&gt;
&lt;br&gt;
&lt;strong&gt;Here is an implementation of our algorithm:&lt;/strong&gt;&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bintrees&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AVLTree&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;partitionWeights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    The preprocessing step.&lt;/span&gt;
&lt;span class="sd"&gt;    :param weights: A dictionary of weights which sum to one.&lt;/span&gt;
&lt;span class="sd"&gt;    :return: A partition used to draw quickly from the distribution&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;epsilon&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.00001&lt;/span&gt; &lt;span class="c1"&gt;# for floating point precision issues&lt;/span&gt;
    &lt;span class="n"&gt;boxes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;numWeights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="c1"&gt;# We use a AVLTree to make our pull/push operations O(log n)&lt;/span&gt;
    &lt;span class="n"&gt;tree&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AVLTree&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;numWeights&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;smallestValue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;smallestColor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop_min&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# O(log n)&lt;/span&gt;
        &lt;span class="n"&gt;overfill&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;numWeights&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;smallestValue&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;overfill&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;largestValue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;largestColor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop_max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# O(log n)&lt;/span&gt;
            &lt;span class="n"&gt;largestValue&lt;/span&gt; &lt;span class="o"&gt;-=&lt;/span&gt; &lt;span class="n"&gt;overfill&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;largestValue&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;epsilon&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;insert&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;largestValue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;largestColor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# O(log n)&lt;/span&gt;
            &lt;span class="n"&gt;boxes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;smallestValue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;smallestColor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;largestColor&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;boxes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;smallestValue&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;smallestColor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;none&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;boxes&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;drawFromPartition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    The draw step.&lt;/span&gt;
&lt;span class="sd"&gt;    :param partition: partition A partition of a distribution into boxes.&lt;/span&gt;
&lt;span class="sd"&gt;    :return: A sample from the distribution represented by the partition.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;numBoxes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;numBoxes&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;color2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;numBoxes&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;color1&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;color2&lt;/span&gt;

&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="mf"&gt;3.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;6.0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;orange&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;6.0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;6.0&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;green&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="n"&gt;partition&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partitionWeights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;orange&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;blue&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;green&amp;quot;&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;600000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;drawFromPartition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;One final note on runtime.&lt;/strong&gt; If you run our example code you'll notice the "slow" function is almost twice as fast as the "fast" one. Have I been lying this whole time? No. This is because in our example we used a small number of weights. In a &lt;a href="https://gist.github.com/Mr4k/eabaca318499bd54e5e18431efbc6622"&gt;separate speed test&lt;/a&gt; I use 1000 weights and draw from the distributions 100000 times each. In this case the fast algorithm runs in 0.35 seconds on my computer while the slow algorithm takes about 15 seconds.&lt;/p&gt;</content><category term="algorithms"></category><category term="probability"></category><category term="algorithms"></category></entry></feed>